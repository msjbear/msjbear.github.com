<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>BigBear&#39;s Blog</title>
  <subtitle>Do The Right Thing!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-08-17T03:07:52.536Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>sj_mei</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用xgboost4j-spark进行模型训练</title>
    <link href="http://yoursite.com/2017/08/17/xgboost4j-spark-demo/"/>
    <id>http://yoursite.com/2017/08/17/xgboost4j-spark-demo/</id>
    <published>2017-08-17T14:00:00.000Z</published>
    <updated>2017-08-17T03:07:52.536Z</updated>
    
    <content type="html"><![CDATA[<h3 id="代码说明"><a href="#代码说明" class="headerlink" title="代码说明"></a>代码说明</h3><p>xgboost作为数据挖掘类比赛的必备算法，之前参加jdata比赛时，也学着使用了下xgboost4j-spark，觉得很好用，既支持分布式，同时效果和速度都比spark自带的gbdt,rf算法效果要好。<br>模型代码包含:<br>    -train：训练<br>    -train_cv：训练带交叉验证进行参数选择<br>    -predict_eval：预测并在验证集上验证准确率<br>    -predict：预测<br>    -train_leaf_lr：gbdt+lr集成训练<br><a href="http://deepspark.cn/2017/06/10/jdata/" target="_blank" rel="external">京东JData算法大赛小结(公司内部赛)</a></p>
<h3 id="编译xgboost"><a href="#编译xgboost" class="headerlink" title="编译xgboost"></a>编译xgboost</h3><p><a href="http://deepspark.cn/2017/05/05/xgboost-install/" target="_blank" rel="external">xgboost4j编译安装笔记</a></p>
<h3 id="源码地址"><a href="#源码地址" class="headerlink" title="源码地址"></a>源码地址</h3><p><a href="https://github.com/msjbear/jdata-spark.git" target="_blank" rel="external">jdata-spark代码地址</a></p>
<h3 id="jdata-xgboost4j-spark代码示例"><a href="#jdata-xgboost4j-spark代码示例" class="headerlink" title="jdata xgboost4j-spark代码示例"></a>jdata xgboost4j-spark代码示例</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div><div class="line">336</div><div class="line">337</div><div class="line">338</div><div class="line">339</div><div class="line">340</div><div class="line">341</div><div class="line">342</div><div class="line">343</div><div class="line">344</div><div class="line">345</div><div class="line">346</div><div class="line">347</div><div class="line">348</div><div class="line">349</div><div class="line">350</div><div class="line">351</div><div class="line">352</div><div class="line">353</div><div class="line">354</div><div class="line">355</div><div class="line">356</div><div class="line">357</div><div class="line">358</div><div class="line">359</div><div class="line">360</div><div class="line">361</div><div class="line">362</div><div class="line">363</div><div class="line">364</div><div class="line">365</div><div class="line">366</div><div class="line">367</div><div class="line">368</div><div class="line">369</div><div class="line">370</div><div class="line">371</div><div class="line">372</div><div class="line">373</div><div class="line">374</div><div class="line">375</div><div class="line">376</div><div class="line">377</div><div class="line">378</div><div class="line">379</div><div class="line">380</div><div class="line">381</div><div class="line">382</div><div class="line">383</div><div class="line">384</div><div class="line">385</div><div class="line">386</div><div class="line">387</div><div class="line">388</div><div class="line">389</div><div class="line">390</div><div class="line">391</div><div class="line">392</div><div class="line">393</div><div class="line">394</div><div class="line">395</div><div class="line">396</div><div class="line">397</div><div class="line">398</div><div class="line">399</div><div class="line">400</div><div class="line">401</div><div class="line">402</div><div class="line">403</div><div class="line">404</div><div class="line">405</div><div class="line">406</div><div class="line">407</div><div class="line">408</div><div class="line">409</div><div class="line">410</div><div class="line">411</div><div class="line">412</div><div class="line">413</div><div class="line">414</div><div class="line">415</div><div class="line">416</div><div class="line">417</div><div class="line">418</div><div class="line">419</div><div class="line">420</div><div class="line">421</div><div class="line">422</div><div class="line">423</div><div class="line">424</div><div class="line">425</div><div class="line">426</div><div class="line">427</div><div class="line">428</div><div class="line">429</div><div class="line">430</div><div class="line">431</div><div class="line">432</div><div class="line">433</div><div class="line">434</div><div class="line">435</div><div class="line">436</div><div class="line">437</div><div class="line">438</div><div class="line">439</div><div class="line">440</div><div class="line">441</div><div class="line">442</div><div class="line">443</div><div class="line">444</div><div class="line">445</div><div class="line">446</div><div class="line">447</div><div class="line">448</div><div class="line">449</div><div class="line">450</div><div class="line">451</div><div class="line">452</div><div class="line">453</div><div class="line">454</div><div class="line">455</div><div class="line">456</div><div class="line">457</div><div class="line">458</div><div class="line">459</div><div class="line">460</div><div class="line">461</div><div class="line">462</div><div class="line">463</div><div class="line">464</div><div class="line">465</div><div class="line">466</div><div class="line">467</div><div class="line">468</div><div class="line">469</div><div class="line">470</div><div class="line">471</div><div class="line">472</div><div class="line">473</div><div class="line">474</div><div class="line">475</div><div class="line">476</div><div class="line">477</div><div class="line">478</div><div class="line">479</div><div class="line">480</div><div class="line">481</div><div class="line">482</div><div class="line">483</div><div class="line">484</div><div class="line">485</div><div class="line">486</div><div class="line">487</div><div class="line">488</div><div class="line">489</div><div class="line">490</div><div class="line">491</div><div class="line">492</div><div class="line">493</div><div class="line">494</div><div class="line">495</div><div class="line">496</div><div class="line">497</div><div class="line">498</div><div class="line">499</div><div class="line">500</div><div class="line">501</div><div class="line">502</div><div class="line">503</div><div class="line">504</div><div class="line">505</div><div class="line">506</div><div class="line">507</div><div class="line">508</div><div class="line">509</div><div class="line">510</div><div class="line">511</div><div class="line">512</div><div class="line">513</div><div class="line">514</div><div class="line">515</div><div class="line">516</div><div class="line">517</div><div class="line">518</div><div class="line">519</div><div class="line">520</div><div class="line">521</div><div class="line">522</div><div class="line">523</div><div class="line">524</div><div class="line">525</div><div class="line">526</div><div class="line">527</div><div class="line">528</div><div class="line">529</div><div class="line">530</div><div class="line">531</div><div class="line">532</div><div class="line">533</div><div class="line">534</div><div class="line">535</div><div class="line">536</div><div class="line">537</div><div class="line">538</div><div class="line">539</div><div class="line">540</div><div class="line">541</div><div class="line">542</div><div class="line">543</div><div class="line">544</div><div class="line">545</div><div class="line">546</div><div class="line">547</div><div class="line">548</div><div class="line">549</div><div class="line">550</div><div class="line">551</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.sjmei.jdata.xgboost</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.sjmei.jdata.utils.&#123;<span class="type">AlgoUtils</span>, <span class="type">DataLoadUtils</span>, <span class="type">SubmissionEvalUtils</span>&#125;</div><div class="line"><span class="keyword">import</span> ml.dmlc.xgboost4j.scala.<span class="type">Booster</span></div><div class="line"><span class="keyword">import</span> ml.dmlc.xgboost4j.scala.spark.&#123;<span class="type">XGBoost</span>, <span class="type">XGBoostEstimator</span>, <span class="type">XGBoostModel</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.examples.mllib.<span class="type">AbstractParams</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.classification.<span class="type">LogisticRegression</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.evaluation.<span class="type">MulticlassClassificationEvaluator</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.feature.<span class="type">VectorIndexer</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.linalg.&#123;<span class="type">DenseVector</span>, <span class="type">Vectors</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.tuning.&#123;<span class="type">CrossValidator</span>, <span class="type">CrossValidatorModel</span>, <span class="type">ParamGridBuilder</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.&#123;<span class="type">Pipeline</span>, <span class="type">PipelineStage</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.util.<span class="type">MLUtils</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql._</div><div class="line"><span class="keyword">import</span> scopt.<span class="type">OptionParser</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> scala.collection.mutable</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkXgboostWithDataFrame</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> sep = <span class="type">AlgoUtils</span>.<span class="type">FIELD_SEP</span></div><div class="line">  <span class="keyword">val</span> numPartitions = <span class="type">AlgoUtils</span>.<span class="type">NUM_PARTITIONS</span></div><div class="line"></div><div class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Params</span>(<span class="params"></span></span></div><div class="line">                     inputPath: <span class="type">String</span> = null,</div><div class="line">                     modelPath: <span class="type">String</span> = null,</div><div class="line">                     resultPath: <span class="type">String</span> = null,</div><div class="line">                     taskType: <span class="type">String</span> = null,</div><div class="line">                     initDate: <span class="type">String</span> = "2016-04-06",</div><div class="line">                     dataFormat: <span class="type">String</span> = "orc",</div><div class="line">                     resultType: <span class="type">String</span> = "xgb_predict_eval",</div><div class="line">                     nWorkers: <span class="type">Int</span> = 20,</div><div class="line">                     numRound: <span class="type">Int</span> = 100,</div><div class="line">                     isCvModel: <span class="type">Boolean</span> = false,</div><div class="line">                     fracTest: <span class="type">Double</span> = 0.1) <span class="keyword">extends</span> <span class="title">AbstractParams</span>[<span class="type">Params</span>]</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> defaultParams = <span class="type">Params</span>()</div><div class="line">    <span class="comment">// create SparkSession</span></div><div class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"SparkXgboostWithDataFrame"</span>)</div><div class="line">      .set(<span class="string">"spark.serializer"</span>, <span class="string">"org.apache.spark.serializer.KryoSerializer"</span>)</div><div class="line">    sparkConf.registerKryoClasses(<span class="type">Array</span>(classOf[<span class="type">Booster</span>]))</div><div class="line">    <span class="keyword">val</span> spark = <span class="type">AlgoUtils</span>.getSparkSession(sparkConf)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> parser = <span class="keyword">new</span> <span class="type">OptionParser</span>[<span class="type">Params</span>](<span class="string">"SparkXgboostWithDataFrame"</span>) &#123;</div><div class="line">      head(<span class="string">"Trainmodel with Xgboost"</span>)</div><div class="line">      opt[<span class="type">String</span>](<span class="string">"initDate"</span>)</div><div class="line">        .text(<span class="string">"initDate of predict"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(initDate = x))</div><div class="line">      opt[<span class="type">String</span>](<span class="string">"resultType"</span>)</div><div class="line">        .text(<span class="string">s"algorithm (classification, regression), default: <span class="subst">$&#123;defaultParams.resultType&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(resultType = x))</div><div class="line">      opt[<span class="type">Int</span>](<span class="string">"nWorkers"</span>)</div><div class="line">        .text(<span class="string">s"num of workers, default: <span class="subst">$&#123;defaultParams.nWorkers&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(nWorkers = x))</div><div class="line">      opt[<span class="type">Int</span>](<span class="string">"numRound"</span>)</div><div class="line">        .text(<span class="string">s"number of round(iteration), default: <span class="subst">$&#123;defaultParams.numRound&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(numRound = x))</div><div class="line">      opt[<span class="type">Double</span>](<span class="string">"fracTest"</span>)</div><div class="line">        .text(<span class="string">s"fraction of data to hold out for testing. If given option testInput, "</span> +</div><div class="line">          <span class="string">s"this option is ignored. default: <span class="subst">$&#123;defaultParams.fracTest&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(fracTest = x))</div><div class="line">      opt[<span class="type">String</span>](<span class="string">"dataFormat"</span>)</div><div class="line">        .text(<span class="string">"data format: orc (default)"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(dataFormat = x))</div><div class="line">      opt[<span class="type">Boolean</span>](<span class="string">"isCvModel"</span>)</div><div class="line">        .text(<span class="string">"is cvmodel flag: false (default)"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(isCvModel = x))</div><div class="line">      arg[<span class="type">String</span>](<span class="string">"&lt;inputPath&gt;"</span>)</div><div class="line">        .text(<span class="string">"inputPath to train or predict datasets"</span>)</div><div class="line">        .required()</div><div class="line">        .action((x, c) =&gt; c.copy(inputPath = x))</div><div class="line">      arg[<span class="type">String</span>](<span class="string">"&lt;modelPath&gt;"</span>)</div><div class="line">        .text(<span class="string">"modelPath path to labeled examples"</span>)</div><div class="line">        .required()</div><div class="line">        .action((x, c) =&gt; c.copy(modelPath = x))</div><div class="line">      arg[<span class="type">String</span>](<span class="string">"&lt;resultPath&gt;"</span>)</div><div class="line">        .text(<span class="string">"resultPath to labeled examples"</span>)</div><div class="line">        .required()</div><div class="line">        .action((x, c) =&gt; c.copy(resultPath = x))</div><div class="line">      arg[<span class="type">String</span>](<span class="string">"&lt;taskType&gt;"</span>)</div><div class="line">        .text(<span class="string">"train or predict the rf model"</span>)</div><div class="line">        .required()</div><div class="line">        .action((x, c) =&gt; c.copy(taskType = x))</div><div class="line">      checkConfig &#123; params =&gt;</div><div class="line">        <span class="keyword">if</span> (params.fracTest &lt; <span class="number">0</span> || params.fracTest &gt;= <span class="number">1</span>) &#123;</div><div class="line">          failure(<span class="string">s"fracTest <span class="subst">$&#123;params.fracTest&#125;</span> value incorrect; should be in [0,1)."</span>)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          success</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    parser.parse(args, defaultParams) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(params) =&gt; &#123;</div><div class="line">        params.taskType.trim.toLowerCase <span class="keyword">match</span> &#123;</div><div class="line">          <span class="keyword">case</span> <span class="string">"train"</span> =&gt; train(spark, params)</div><div class="line">          <span class="keyword">case</span> <span class="string">"train_cv"</span> =&gt; train_cv(spark, params)</div><div class="line">          <span class="keyword">case</span> <span class="string">"predict"</span> =&gt; predict(spark, params)</div><div class="line">          <span class="keyword">case</span> <span class="string">"predict_leaf"</span> =&gt; predictLeafs(spark, params)</div><div class="line">          <span class="keyword">case</span> <span class="string">"train_leaf_lr"</span> =&gt; trainLeafsWithLR(spark, params)</div><div class="line">          <span class="keyword">case</span> <span class="string">"eval_leaf_lr"</span> =&gt; evalLeafsWithLR(spark, params)</div><div class="line">          <span class="keyword">case</span> <span class="string">"predict_eval"</span> =&gt; predict_eval(spark, params)</div><div class="line">          <span class="keyword">case</span> _ =&gt; println(<span class="string">"XGBoost method error..."</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">case</span> _ =&gt; sys.exit(<span class="number">1</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    spark.stop()</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * train xgboost model</div><div class="line">    *</div><div class="line">    * @param sparkSession</div><div class="line">    * @param params</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train</span></span>(sparkSession: <span class="type">SparkSession</span>, params: <span class="type">Params</span>): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> (trainDF, testDF) = <span class="type">DataLoadUtils</span>.loadTrainData(sparkSession, params.inputPath, params.fracTest)</div><div class="line">    <span class="comment">// start training</span></div><div class="line">    <span class="keyword">val</span> paramMap = <span class="type">List</span>(</div><div class="line">      <span class="string">"eta"</span> -&gt; <span class="number">0.05</span>f,</div><div class="line">      <span class="string">"max_depth"</span> -&gt; <span class="number">8</span>,</div><div class="line">      <span class="string">"objective"</span> -&gt; <span class="string">"binary:logistic"</span> <span class="comment">// ,"eval_metric" -&gt; "logloss"</span></div><div class="line">    ).toMap</div><div class="line">    <span class="keyword">val</span> xgboostModel = <span class="type">XGBoost</span>.trainWithDataFrame(</div><div class="line">      trainDF, paramMap, params.numRound, params.nWorkers, useExternalMemory = <span class="literal">true</span>)</div><div class="line">    <span class="comment">// xgboost-spark appends the column containing prediction results</span></div><div class="line">    <span class="keyword">val</span> predTestResult = xgboostModel.transform(testDF)</div><div class="line">    <span class="keyword">val</span> predTrainResult = xgboostModel.transform(trainDF)</div><div class="line"></div><div class="line">    predTestResult.show()</div><div class="line"></div><div class="line">    <span class="type">AlgoUtils</span>.deleteFile(params.modelPath)</div><div class="line">    xgboostModel.save(params.modelPath)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>()</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</div><div class="line">    <span class="keyword">val</span> train_accuracy = evaluator.evaluate(predTrainResult)</div><div class="line">    <span class="keyword">val</span> test_accuracy = evaluator.evaluate(predTestResult)</div><div class="line">    println(<span class="string">s"Train Accuracy = <span class="subst">$train_accuracy</span>,  Test Accuracy = <span class="subst">$test_accuracy</span>"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">import</span> sparkSession.implicits._</div><div class="line">    predTestResult.union(predTrainResult).map(_.mkString(sep))</div><div class="line">      .write.mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>).text(params.resultPath)</div><div class="line"></div><div class="line">    trainDF.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    testDF.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    predTestResult.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * train xgboost model with cross validation</div><div class="line">    *</div><div class="line">    * @param sparkSession</div><div class="line">    * @param params</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train_cv</span></span>(sparkSession: <span class="type">SparkSession</span>, params: <span class="type">Params</span>): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> (trainDF, testDF) = <span class="type">DataLoadUtils</span>.loadTrainData(sparkSession, params.inputPath, params.fracTest)</div><div class="line">    <span class="comment">// start training</span></div><div class="line">    <span class="keyword">val</span> paramMap = <span class="type">List</span>(</div><div class="line">      <span class="string">"eta"</span> -&gt; <span class="number">0.05</span>f,</div><div class="line">      <span class="string">"max_depth"</span> -&gt; <span class="number">8</span>,</div><div class="line">      <span class="string">"objective"</span> -&gt; <span class="string">"binary:logistic"</span> <span class="comment">// ,"eval_metric" -&gt; "logloss"</span></div><div class="line">    ).toMap</div><div class="line">    <span class="comment">// Set up Pipeline.</span></div><div class="line">    <span class="keyword">val</span> stages = <span class="keyword">new</span> mutable.<span class="type">ArrayBuffer</span>[<span class="type">PipelineStage</span>]()</div><div class="line"></div><div class="line">    <span class="keyword">val</span> estimator = <span class="keyword">new</span> <span class="type">XGBoostEstimator</span>(paramMap)</div><div class="line">    <span class="comment">// assigning general parameters</span></div><div class="line">    estimator.set(estimator.useExternalMemory, <span class="literal">false</span>)</div><div class="line">      .set(estimator.round, params.numRound)</div><div class="line">      .set(estimator.nWorkers, params.nWorkers)</div><div class="line">      .set(estimator.missing, <span class="type">Float</span>.<span class="type">NaN</span>)</div><div class="line">      .setFeaturesCol(<span class="string">"features"</span>)</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// assigning general parameters</span></div><div class="line">    stages += estimator</div><div class="line">    <span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>().setStages(stages.toArray)</div><div class="line">    <span class="comment">// Fit the Pipeline.</span></div><div class="line">    <span class="keyword">val</span> startTime = <span class="type">System</span>.nanoTime()</div><div class="line"></div><div class="line">    <span class="comment">// We use a ParamGridBuilder to construct a grid of parameters to search over.</span></div><div class="line">    <span class="keyword">val</span> paramGrid = <span class="keyword">new</span> <span class="type">ParamGridBuilder</span>()</div><div class="line">      .addGrid(estimator.maxDepth, <span class="type">Array</span>(<span class="number">8</span>, <span class="number">10</span>))</div><div class="line">      .addGrid(estimator.eta, <span class="type">Array</span>(<span class="number">0.1</span>, <span class="number">0.05</span>))</div><div class="line">      .build()</div><div class="line"></div><div class="line">    <span class="comment">// We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.</span></div><div class="line">    <span class="comment">// This will allow us to jointly choose parameters for all Pipeline stages.</span></div><div class="line">    <span class="comment">// A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.</span></div><div class="line">    <span class="comment">// Note that the evaluator here is a BinaryClassificationEvaluator and its default metric</span></div><div class="line">    <span class="comment">// is areaUnderROC.</span></div><div class="line">    <span class="keyword">val</span> cv = <span class="keyword">new</span> <span class="type">CrossValidator</span>()</div><div class="line">      .setEstimator(pipeline)</div><div class="line">      .setEvaluator(<span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>)</div><div class="line">      .setEstimatorParamMaps(paramGrid)</div><div class="line">      .setNumFolds(<span class="number">5</span>)  <span class="comment">// Use 3+ in practice</span></div><div class="line"></div><div class="line">    <span class="comment">// Run cross-validation, and choose the best set of parameters.</span></div><div class="line">    <span class="keyword">val</span> cvModel = cv.fit(trainDF)</div><div class="line">    cvModel.write.overwrite.save(params.modelPath)</div><div class="line">    <span class="comment">// Make predictions on test documents. cvModel uses the best model found (lrModel).</span></div><div class="line">    <span class="keyword">val</span> train_predict = cvModel.transform(trainDF).select(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>)</div><div class="line">    <span class="keyword">val</span> test_predict = cvModel.transform(testDF).select(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>)</div><div class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>()</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</div><div class="line">    <span class="keyword">val</span> train_accuracy = evaluator.evaluate(train_predict)</div><div class="line">    <span class="keyword">val</span> test_accuracy = evaluator.evaluate(test_predict)</div><div class="line">    println(<span class="string">s"Train Accuracy = <span class="subst">$train_accuracy</span>,  Test Accuracy = <span class="subst">$test_accuracy</span>"</span>)</div><div class="line">    <span class="comment">// $example off$</span></div><div class="line"></div><div class="line">    <span class="keyword">val</span> elapsedTime = (<span class="type">System</span>.nanoTime() - startTime) / <span class="number">1e9</span></div><div class="line">    println(<span class="string">s"Training time: <span class="subst">$elapsedTime</span> seconds"</span>)</div><div class="line"></div><div class="line">    train_predict.printSchema()</div><div class="line">    train_predict.select(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>).show(<span class="number">10</span>)</div><div class="line"></div><div class="line">    trainDF.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    testDF.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * predict xgboost model</div><div class="line">    *</div><div class="line">    * @param sparkSession</div><div class="line">    * @param params</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predict</span></span>(sparkSession: <span class="type">SparkSession</span>, params: <span class="type">Params</span>): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> datasets = <span class="type">DataLoadUtils</span>.loadPredictDataOrc(sparkSession, params.inputPath)</div><div class="line">    <span class="comment">// start training</span></div><div class="line">    <span class="comment">// xgboost-spark appends the column containing prediction results</span></div><div class="line">    <span class="keyword">var</span> result: <span class="type">DataFrame</span> = <span class="literal">null</span></div><div class="line">    <span class="keyword">if</span>(params.isCvModel)&#123;</div><div class="line">      <span class="keyword">val</span> xgboostModel = <span class="type">CrossValidatorModel</span>.load(params.modelPath)</div><div class="line">      result = xgboostModel.transform(datasets)</div><div class="line"></div><div class="line">    &#125;<span class="keyword">else</span>&#123;</div><div class="line">      <span class="keyword">val</span> xgboostModel = <span class="type">XGBoostModel</span>.load(params.modelPath)</div><div class="line">      result = xgboostModel.transform(datasets)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    println(<span class="string">"JRDM:XGBoost"</span>)</div><div class="line">    result.printSchema()</div><div class="line">    result.show(<span class="number">100</span>)</div><div class="line"></div><div class="line">    <span class="keyword">import</span> sparkSession.implicits._</div><div class="line">    <span class="keyword">val</span> predicts = result.select(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"probabilities"</span>, <span class="string">"prediction"</span>)</div><div class="line">      .map(row =&gt; &#123;</div><div class="line">      (row.get(<span class="number">0</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">        row.get(<span class="number">1</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">        row.get(<span class="number">2</span>).asInstanceOf[<span class="type">DenseVector</span>].toArray(<span class="number">1</span>),</div><div class="line">        row.get(<span class="number">3</span>).asInstanceOf[<span class="type">Double</span>])</div><div class="line">    &#125;)</div><div class="line">    predicts.write.mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>).orc(params.resultPath)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> sqlCommand = <span class="string">s"ALTER TABLE dev.dev_temp_msj_risk_jdata_predict_result ADD IF NOT EXISTS PARTITION(dt='<span class="subst">$&#123;params.initDate&#125;</span>', result_type='<span class="subst">$&#123;params.resultType&#125;</span>')"</span></div><div class="line">    sparkSession.sql(sqlCommand)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> df_submission = result.select(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"probabilities"</span>, <span class="string">"prediction"</span>)</div><div class="line">      .map(row =&gt; &#123;(row.get(<span class="number">0</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">        row.get(<span class="number">1</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">        row.get(<span class="number">2</span>).asInstanceOf[<span class="type">DenseVector</span>].toArray(<span class="number">1</span>),</div><div class="line">        row.get(<span class="number">3</span>).asInstanceOf[<span class="type">Double</span>])</div><div class="line">      &#125;).toDF(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"prob"</span>, <span class="string">"predict"</span>)</div><div class="line"></div><div class="line">    df_submission.createOrReplaceTempView(<span class="string">"future_predict_table"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> script_sql = <span class="type">AlgoUtils</span>.genSubmissionResultSql(<span class="string">"gen_submission_result.sql"</span>, params.initDate)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> submission_result = sparkSession.sql(script_sql)</div><div class="line">    submission_result.map(_.mkString(sep)).write.mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>).text(params.resultPath + <span class="string">".submit"</span>)</div><div class="line">    println(<span class="string">"JRDM: submission cnt: "</span> + submission_result.count())</div><div class="line"></div><div class="line">    datasets.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    predicts.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    df_submission.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    submission_result.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * predict each tree score from xgboost model</div><div class="line">    *</div><div class="line">    * @param sparkSession</div><div class="line">    * @param params</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predictLeafs</span></span>(sparkSession: <span class="type">SparkSession</span>, params: <span class="type">Params</span>): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> datasets = <span class="type">DataLoadUtils</span>.loadEvalDataOrc(sparkSession, params.inputPath)</div><div class="line">    <span class="comment">// start training</span></div><div class="line">    <span class="comment">// xgboost-spark appends the column containing prediction results</span></div><div class="line">    <span class="keyword">val</span> xgboostModel = <span class="type">XGBoostModel</span>.load(params.modelPath)</div><div class="line">    <span class="keyword">val</span> result = xgboostModel.transformLeaf(datasets)</div><div class="line">    println(<span class="string">"JRDM:XGBoost"</span>)</div><div class="line">    result.printSchema()</div><div class="line">    result.show(<span class="number">100</span>)</div><div class="line"></div><div class="line">    <span class="keyword">import</span> sparkSession.implicits._</div><div class="line">    <span class="keyword">val</span> predicts = result.select(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"label"</span>, <span class="string">"predLeaf"</span>)</div><div class="line">      .map(row =&gt; &#123;</div><div class="line">        (row.get(<span class="number">0</span>).asInstanceOf[<span class="type">String</span>] + sep</div><div class="line">          + row.get(<span class="number">1</span>).asInstanceOf[<span class="type">String</span>] + sep</div><div class="line">          + row.get(<span class="number">2</span>).asInstanceOf[<span class="type">Int</span>] + sep</div><div class="line">          + row.get(<span class="number">3</span>).asInstanceOf[scala.collection.mutable.<span class="type">WrappedArray</span>[<span class="type">Float</span>]].mkString(sep))</div><div class="line">      &#125;)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> predRDD = result.select(<span class="string">"label"</span>, <span class="string">"predLeaf"</span>).rdd</div><div class="line">      .map(row =&gt; &#123;</div><div class="line">        <span class="type">LabeledPoint</span>(row.get(<span class="number">0</span>).asInstanceOf[<span class="type">Int</span>].toDouble,</div><div class="line">          org.apache.spark.mllib.linalg.<span class="type">Vectors</span>.dense(</div><div class="line">            row.get(<span class="number">1</span>).asInstanceOf[scala.collection.mutable.<span class="type">WrappedArray</span>[<span class="type">Float</span>]]</div><div class="line">              .toArray.map(_.toDouble)))</div><div class="line">      &#125;)</div><div class="line"></div><div class="line">    predRDD.take(<span class="number">10</span>)</div><div class="line">    <span class="keyword">val</span> libsvmFeatsPath = <span class="string">"sjmei/tests/xgboost/gbdt_libsvm_feats"</span></div><div class="line">    <span class="type">AlgoUtils</span>.deleteFile(libsvmFeatsPath)</div><div class="line">    <span class="type">MLUtils</span>.saveAsLibSVMFile(predRDD, libsvmFeatsPath)</div><div class="line">    predicts.show(<span class="number">100</span>)</div><div class="line">    predicts.write.mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>).text(params.resultPath)</div><div class="line"></div><div class="line">    datasets.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    predicts.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * predict each tree score from xgboost model</div><div class="line">    *</div><div class="line">    * @param sparkSession</div><div class="line">    * @param params</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">trainLeafsWithLR</span></span>(sparkSession: <span class="type">SparkSession</span>, params: <span class="type">Params</span>): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> (trainDF, testDF) = <span class="type">DataLoadUtils</span>.loadTrainData(sparkSession, params.inputPath, params.fracTest)</div><div class="line">    <span class="comment">// start training</span></div><div class="line">    <span class="keyword">val</span> paramMap = <span class="type">List</span>(</div><div class="line">      <span class="string">"eta"</span> -&gt; <span class="number">0.05</span>f,</div><div class="line">      <span class="string">"max_depth"</span> -&gt; <span class="number">5</span>,</div><div class="line">      <span class="string">"objective"</span> -&gt; <span class="string">"binary:logistic"</span>,</div><div class="line">      <span class="string">"eval_metric"</span> -&gt; <span class="string">"logloss"</span></div><div class="line">    ).toMap</div><div class="line">    <span class="keyword">val</span> xgboostModel = <span class="type">XGBoost</span>.trainWithDataFrame(</div><div class="line">      trainDF, paramMap, params.numRound, params.nWorkers, useExternalMemory = <span class="literal">true</span>)</div><div class="line">    <span class="comment">// xgboost-spark appends the column containing prediction results</span></div><div class="line">    <span class="keyword">val</span> result = xgboostModel.transformLeaf(trainDF)</div><div class="line"></div><div class="line">    <span class="type">AlgoUtils</span>.deleteFile(params.modelPath+<span class="string">".LeafsWithLR.xgb"</span>)</div><div class="line">    xgboostModel.save(params.modelPath+<span class="string">".LeafsWithLR.xgb"</span>)</div><div class="line"></div><div class="line">    trainDF.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    testDF.unpersist(blocking = <span class="literal">false</span>)</div><div class="line"></div><div class="line">    println(<span class="string">"JRDM:XGBoost"</span>)</div><div class="line">    result.printSchema()</div><div class="line">    result.show(<span class="number">100</span>)</div><div class="line"></div><div class="line">    <span class="keyword">import</span> sparkSession.implicits._</div><div class="line">    <span class="keyword">val</span> df_gbdt_result = result.select(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"label"</span>, <span class="string">"predLeaf"</span>)</div><div class="line">      .map(row =&gt; &#123;</div><div class="line">        (row.get(<span class="number">0</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">          row.get(<span class="number">1</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">          row.get(<span class="number">2</span>).asInstanceOf[<span class="type">Int</span>],</div><div class="line">        <span class="type">Vectors</span>.dense(row.get(<span class="number">3</span>).asInstanceOf[scala.collection.mutable.<span class="type">WrappedArray</span>[<span class="type">Float</span>]].toArray.map(_.toDouble)))</div><div class="line">      &#125;).toDF(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> df_vecIndexer = <span class="keyword">new</span> <span class="type">VectorIndexer</span>()</div><div class="line">      .setInputCol(<span class="string">"features"</span>)</div><div class="line">      .setOutputCol(<span class="string">"features_vec"</span>)</div><div class="line">      .setMaxCategories(<span class="number">200</span>)</div><div class="line">      .fit(df_gbdt_result)</div><div class="line">      .transform(df_gbdt_result)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> dataframes = df_vecIndexer.randomSplit(<span class="type">Array</span>(<span class="number">0.9</span>, <span class="number">0.1</span>), seed = <span class="number">12345</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> training = dataframes(<span class="number">0</span>).cache()</div><div class="line">    <span class="keyword">val</span> testing = dataframes(<span class="number">1</span>).cache()</div><div class="line"></div><div class="line">    <span class="keyword">val</span> lr = <span class="keyword">new</span> <span class="type">LogisticRegression</span>()</div><div class="line">      .setFeaturesCol(<span class="string">"features_vec"</span>)</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setRegParam(<span class="number">0.0</span>)</div><div class="line">      .setElasticNetParam(<span class="number">0.0</span>)</div><div class="line">      .setMaxIter(<span class="number">100</span>)</div><div class="line">      .setTol(<span class="number">1E-6</span>)</div><div class="line">      .setFitIntercept(<span class="literal">true</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> paramGrid = <span class="keyword">new</span> <span class="type">ParamGridBuilder</span>()</div><div class="line">      .addGrid(lr.regParam, <span class="type">Array</span>(<span class="number">0.0</span>, <span class="number">0.1</span>))</div><div class="line">      .addGrid(lr.maxIter, <span class="type">Array</span>(<span class="number">100</span>, <span class="number">50</span>))</div><div class="line">      .build()</div><div class="line">    <span class="keyword">val</span> cv = <span class="keyword">new</span> <span class="type">CrossValidator</span>()</div><div class="line">      .setEstimator(lr)</div><div class="line">      .setEvaluator(<span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>)</div><div class="line">      .setEstimatorParamMaps(paramGrid)</div><div class="line">      .setNumFolds(<span class="number">5</span>)  <span class="comment">// Use 3+ in practice</span></div><div class="line"></div><div class="line">    <span class="keyword">val</span> cvModel = cv.fit(training)</div><div class="line">    cvModel.write.overwrite.save(params.modelPath+<span class="string">".LeafsWithLR.lr"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Shows the best parameters</span></div><div class="line">    cvModel.bestModel <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> pipeline: <span class="type">Pipeline</span> =&gt;</div><div class="line">        pipeline.getStages.zipWithIndex.foreach &#123; <span class="keyword">case</span> (stage, index) =&gt;</div><div class="line">          println(<span class="string">s"Stage[<span class="subst">$&#123;index + 1&#125;</span>]: <span class="subst">$&#123;stage.getClass.getSimpleName&#125;</span>"</span>)</div><div class="line">          println(stage.extractParamMap())</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Make predictions on test documents. cvModel uses the best model found (lrModel).</span></div><div class="line">    <span class="keyword">val</span> train_predict = cvModel.transform(training).select(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>)</div><div class="line">    <span class="keyword">val</span> test_predict = cvModel.transform(testing).select(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>)</div><div class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>()</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</div><div class="line">    <span class="keyword">val</span> train_accuracy = evaluator.evaluate(train_predict)</div><div class="line">    <span class="keyword">val</span> test_accuracy = evaluator.evaluate(test_predict)</div><div class="line">    println(<span class="string">s"Train Accuracy = <span class="subst">$train_accuracy</span>,  Test Accuracy = <span class="subst">$test_accuracy</span>"</span>)</div><div class="line"></div><div class="line">    result.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    training.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    testing.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">evalLeafsWithLR</span></span>(sparkSession: <span class="type">SparkSession</span>, params: <span class="type">Params</span>): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> datasets = <span class="type">DataLoadUtils</span>.loadEvalDataOrc(sparkSession, params.inputPath)</div><div class="line">    <span class="comment">// start training</span></div><div class="line">    <span class="comment">// xgboost-spark appends the column containing prediction results</span></div><div class="line">    <span class="keyword">val</span> xgboostModel = <span class="type">XGBoostModel</span>.load(params.modelPath+<span class="string">".LeafsWithLR.xgb"</span>)</div><div class="line">    <span class="keyword">val</span> xg_result = xgboostModel.transformLeaf(datasets)</div><div class="line">    println(<span class="string">"JRDM:XGBoost"</span>)</div><div class="line">    xg_result.printSchema()</div><div class="line">    xg_result.show(<span class="number">10</span>)</div><div class="line"></div><div class="line">    <span class="keyword">import</span> sparkSession.implicits._</div><div class="line">    <span class="keyword">val</span> df_gbdt_result = xg_result.select(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"label"</span>, <span class="string">"predLeaf"</span>)</div><div class="line">      .map(row =&gt; &#123;</div><div class="line">        (row.get(<span class="number">0</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">          row.get(<span class="number">1</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">          row.get(<span class="number">2</span>).asInstanceOf[<span class="type">Int</span>],</div><div class="line">          <span class="type">Vectors</span>.dense(row.get(<span class="number">3</span>).asInstanceOf[scala.collection.mutable.<span class="type">WrappedArray</span>[<span class="type">Float</span>]].toArray.map(_.toDouble)))</div><div class="line">      &#125;).toDF(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> df_vecIndexer = <span class="keyword">new</span> <span class="type">VectorIndexer</span>()</div><div class="line">      .setInputCol(<span class="string">"features"</span>)</div><div class="line">      .setOutputCol(<span class="string">"features_vec"</span>)</div><div class="line">      .setMaxCategories(<span class="number">1000</span>)</div><div class="line">      .fit(df_gbdt_result)</div><div class="line">      .transform(df_gbdt_result)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> cvModel = <span class="type">CrossValidatorModel</span>.load(params.modelPath+<span class="string">".LeafsWithLR.lr"</span>)</div><div class="line">    <span class="comment">// Make predictions on test documents. cvModel uses the best model found (lrModel).</span></div><div class="line">    <span class="keyword">val</span> lr_result = cvModel.transform(df_vecIndexer).select(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"label"</span>,<span class="string">"probability"</span>,<span class="string">"prediction"</span>)</div><div class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>()</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</div><div class="line">    <span class="keyword">val</span> train_accuracy = evaluator.evaluate(lr_result)</div><div class="line">    println(<span class="string">s"Train Accuracy = <span class="subst">$train_accuracy</span>"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">import</span> sparkSession.implicits._</div><div class="line">    <span class="keyword">val</span> predicts = lr_result</div><div class="line">      .map(row =&gt; &#123;(row.get(<span class="number">0</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">        row.get(<span class="number">1</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">        row.get(<span class="number">2</span>).asInstanceOf[<span class="type">Int</span>],</div><div class="line">        row.get(<span class="number">3</span>).asInstanceOf[<span class="type">DenseVector</span>].toArray(<span class="number">1</span>),</div><div class="line">        row.get(<span class="number">4</span>).asInstanceOf[<span class="type">Double</span>])</div><div class="line">      &#125;).toDF(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"label"</span>, <span class="string">"prob"</span>, <span class="string">"predict"</span>)</div><div class="line"></div><div class="line">    predicts.createOrReplaceTempView(<span class="string">"future_predict_table"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> script_sql = <span class="type">AlgoUtils</span>.genSubmissionResultSql(<span class="string">"gen_submission_result.sql"</span>, params.initDate)</div><div class="line">    <span class="keyword">val</span> submission_result = sparkSession.sql(script_sql)</div><div class="line">    println(<span class="string">"JRDM: submission cnt: "</span> + submission_result.count())</div><div class="line"></div><div class="line">    lr_result.cache()</div><div class="line">    submission_result.cache()</div><div class="line"></div><div class="line">    <span class="type">SubmissionEvalUtils</span>.jdata_report(predicts, submission_result)</div><div class="line"></div><div class="line">    datasets.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    xg_result.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    lr_result.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    df_gbdt_result.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * predict and evaluate xgboost model</div><div class="line">    *</div><div class="line">    * @param sparkSession</div><div class="line">    * @param params</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predict_eval</span></span>(sparkSession: <span class="type">SparkSession</span>, params: <span class="type">Params</span>): <span class="type">Unit</span> = &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> datasets = <span class="type">DataLoadUtils</span>.loadEvalDataOrc(sparkSession, params.inputPath)</div><div class="line">    <span class="comment">// start training</span></div><div class="line">    <span class="comment">// xgboost-spark appends the column containing prediction results</span></div><div class="line">    <span class="keyword">var</span> result: <span class="type">DataFrame</span> = <span class="literal">null</span></div><div class="line">    <span class="keyword">if</span>(params.isCvModel)&#123;</div><div class="line">      <span class="keyword">val</span> xgboostModel = <span class="type">CrossValidatorModel</span>.load(params.modelPath)</div><div class="line">      result = xgboostModel.transform(datasets)</div><div class="line"></div><div class="line">    &#125;<span class="keyword">else</span>&#123;</div><div class="line">      <span class="keyword">val</span> xgboostModel = <span class="type">XGBoostModel</span>.load(params.modelPath)</div><div class="line">      result = xgboostModel.transform(datasets)</div><div class="line">    &#125;</div><div class="line">    println(<span class="string">"JRDM:XGBoost"</span>)</div><div class="line">    result.printSchema()</div><div class="line">    result.show(<span class="number">100</span>)</div><div class="line"></div><div class="line">    <span class="keyword">import</span> sparkSession.implicits._</div><div class="line">    <span class="keyword">val</span> predicts = result.select(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"label"</span>, <span class="string">"probabilities"</span>, <span class="string">"prediction"</span>)</div><div class="line">      .map(row =&gt; &#123;(row.get(<span class="number">0</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">        row.get(<span class="number">1</span>).asInstanceOf[<span class="type">String</span>],</div><div class="line">        row.get(<span class="number">2</span>).asInstanceOf[<span class="type">Int</span>],</div><div class="line">        row.get(<span class="number">3</span>).asInstanceOf[<span class="type">DenseVector</span>].toArray(<span class="number">1</span>),</div><div class="line">        row.get(<span class="number">4</span>).asInstanceOf[<span class="type">Double</span>])</div><div class="line">    &#125;).toDF(<span class="string">"user_id"</span>, <span class="string">"sku_id"</span>, <span class="string">"label"</span>, <span class="string">"prob"</span>, <span class="string">"predict"</span>)</div><div class="line">    predicts.write.mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>).orc(params.resultPath)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> sqlCommand = <span class="string">s"ALTER TABLE dev.dev_temp_msj_risk_jdata_eval_result ADD IF NOT EXISTS PARTITION(dt='<span class="subst">$&#123;params.initDate&#125;</span>',result_type='<span class="subst">$&#123;params.resultType&#125;</span>')"</span></div><div class="line">    sparkSession.sql(sqlCommand)</div><div class="line"></div><div class="line">    predicts.createOrReplaceTempView(<span class="string">"future_predict_table"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> script_sql = <span class="type">AlgoUtils</span>.genSubmissionResultSql(<span class="string">"gen_submission_result.sql"</span>, params.initDate)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> submission_result = sparkSession.sql(script_sql)</div><div class="line">    submission_result.map(_.mkString(sep)).write.mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>).text(params.resultPath+<span class="string">".submit"</span>)</div><div class="line">    println(<span class="string">"JRDM: submission cnt: "</span> + submission_result.count())</div><div class="line">    predicts.cache()</div><div class="line">    submission_result.cache()</div><div class="line"></div><div class="line">    <span class="type">SubmissionEvalUtils</span>.jdata_report(predicts, submission_result)</div><div class="line"></div><div class="line">    datasets.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    predicts.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    submission_result.unpersist(blocking = <span class="literal">false</span>)</div><div class="line"></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="spark提交任务脚本"><a href="#spark提交任务脚本" class="headerlink" title="spark提交任务脚本"></a>spark提交任务脚本</h3><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">#!/bin/sh</div><div class="line">numExecutor=$1</div><div class="line">executorMemory=$2</div><div class="line">driverMemory=$3</div><div class="line">etlDate=$4</div><div class="line">taskType=train</div><div class="line">spark-submit  \</div><div class="line">--master  yarn-cluster \</div><div class="line">--name  "SparkXgboostWithDataFrame" \</div><div class="line">--class com.sjmei.jdata.xgboost.SparkXgboostWithDataFrame \</div><div class="line">--properties-file ../conf/jdata/spark-defaults-jdata.conf \</div><div class="line">--num-executors $&#123;numExecutor&#125;  \</div><div class="line">--executor-memory $&#123;executorMemory&#125;g  \</div><div class="line">--driver-memory $&#123;driverMemory&#125;g   \</div><div class="line">--jars ../target/scopt_2.11-3.5.0.jar,../target/xgboost4j-0.7-jar-with-dependencies.jar,../target/xgboost4j-spark-0.7.jar,../target/velocity-1.7.jar \</div><div class="line">--queue bdp_jmart_risk.bdp_jmart_risk_formal \</div><div class="line">--files ../conf/graph-jdata.properties,../conf/hive-site.xml,../script/mid_result_script/model_blend_feature.sql,../script/mid_result_script/model_blend_pred_feature.sql,../script/mid_result_script/gen_submission_result.sql \</div><div class="line">../target/jdata-spark-1.0-SNAPSHOT.jar  \</div><div class="line">--nWorkers 50 \</div><div class="line">--initDate $&#123;etlDate&#125; \</div><div class="line">$&#123;trainDataPath&#125; \</div><div class="line">$&#123;modelPath&#125; \</div><div class="line">$&#123;resultPath&#125; \</div><div class="line">$&#123;taskType&#125; \</div><div class="line">&gt;./jdata_runXgboost_$&#123;taskType&#125;.`date +%Y%m%d`.log 2&gt;&amp;1</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;代码说明&quot;&gt;&lt;a href=&quot;#代码说明&quot; class=&quot;headerlink&quot; title=&quot;代码说明&quot;&gt;&lt;/a&gt;代码说明&lt;/h3&gt;&lt;p&gt;xgboost作为数据挖掘类比赛的必备算法，之前参加jdata比赛时，也学着使用了下xgboost4j-spark，觉得很好
    
    </summary>
    
      <category term="Notes" scheme="http://yoursite.com/categories/Notes/"/>
    
    
      <category term="xgboost4j" scheme="http://yoursite.com/tags/xgboost4j/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>京东JData算法大赛小结(公司内部赛)</title>
    <link href="http://yoursite.com/2017/06/10/jdata/"/>
    <id>http://yoursite.com/2017/06/10/jdata/</id>
    <published>2017-06-10T14:00:00.000Z</published>
    <updated>2017-06-18T06:43:19.382Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总体解决方案"><a href="#总体解决方案" class="headerlink" title="总体解决方案"></a>总体解决方案</h2><p>本文将高潜用户购买意向预测，抽象为一个二分类问题。从用户，商品，品牌，用户-商品，用户-品牌五个维度进行特征提取。将观察天未来5天有购买行为的用户-商品对标记为正样本，观察天过去30天至未来5天有交互行为但未购买的用户-商品对标记为负样本。由于正负样本比例极不平衡，采用了对正样本进行重采样及负样本进行下采样的方式来平衡正负样本比例。利用xgboost进行模型训练，最后利用LR对预测结果进行加权。取每个用户最高预测概率对应的user-sku对，取top12000作为最终输出结果。</p>
<h2 id="实现方案技术栈"><a href="#实现方案技术栈" class="headerlink" title="实现方案技术栈"></a>实现方案技术栈</h2><p>集市堡垒机(环境) + Hive(ETL) + Spark&amp; Spark-Xgboost(Model)</p>
<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>从用户、商品、品牌、用户-商品交互、用户-品牌交互5个维度，再对各个维度从不同周期(1/3/5/7/10/15/30天)进行建模及特征提取。 </p>
<p>3-1 用户维度(script/dim_feature_v3/dim_user_feature_etl.sql)：用户等级，性别，注册天数，年龄等级，浏览量，点击量，关注量，加购车量，下单量，取消关注量，点击购买率，点击加购率，点击关注率，浏览购买转化率，加购购买转化率，关注购买转化率，浏览day/sku/brand数，点击day/sku/brand数，关注day/sku/brand数，加购车day/sku/brand数，下单day/sku/brand数，取消关注day/sku/brand数，最近浏览/点击/购买/关注距今天数，平均每天浏览/点击/购买/关注量(sku/brand数)，平均浏览/点击/购买/关注行为操作间隔天数  </p>
<p>3-2 商品维度(script/dim_feature_v3/dim_sku_feature_etl.sql)：商品评论数，好评率，差评率，商品属性1，属性2，属性3，浏览量，点击量，关注量，加购车量，下单量，取消关注量，点击购买率，点击加购率，点击关注率，浏览购买转化率，加购购买转化率，关注购买转化率，点击购买用户占比，点击加购用户占比，点击关注用户占比，浏览购买转化用户占比，加购购买转化用户占比，关注购买转化用户占比，浏览用户数，点击用户数，关注用户数，加购车用户数，下单用户数，取消关注用户数，平均每天浏览/点击/购买/关注量(用户数)，平均每个用户浏览/点击/购买/关注量 </p>
<p>3-3 品牌维度(script/dim_feature_v3/dim_brand_feature_etl.sql)：浏览量，点击量，关注量，加购车量，下单量，取消关注量，点击购买率，点击加购率，点击关注率，浏览购买转化率，加购购买转化率，关注购买转化率，点击购买用户占比，点击加购用户占比，点击关注用户占比，浏览购买转化用户占比，加购购买转化用户占比，关注购买转化用户占比，浏览用户数，点击用户数，关注用户数，加购车用户数，下单用户数，取消关注用户数，平均每天浏览/点击/购买/关注量(用户数)，平均每个用户浏览/点击/购买/关注量，商品热度(点击量<em>0.01+下单量</em>0.5+加购量<em>0.1-取消关注量</em>0.1+关注量*0.1) </p>
<p>3-4 用户-商品交互维度(script/dim_feature_v3/dim_user_sku_feature_etl.sql)：浏览量，点击量，关注量，加购车量，下单量，取消关注量，点击购买率，点击加购率，点击关注率，浏览购买转化率，加购购买转化率，关注购买转化率，浏览day数，点击day数，关注day数，加购车day数，下单day数，取消关注day数，最近浏览/点击/购买/关注距今天数，平均浏览/点击/购买/关注行为操作间隔天数 </p>
<p>3-5 用户品牌交互维度(script/dim_feature_v3/dim_user_brand_feature_etl.sql)：浏览量，点击量，关注量，加购车量，下单量，取消关注量，点击购买率，点击加购率，点击关注率，浏览购买转化率，加购购买转化率，关注购买转化率，浏览day数，点击day数，关注day数，加购车day数，下单day数，取消关注day数，最近浏览/点击/购买/关注距今天数，平均浏览/点击/购买/关注行为操作间隔天数 </p>
<p>3-6 交叉类特征(script/dim_feature_v3/feature_wide_table.sql)：用户-商品与用户浏览/点击/关注/加购/下单/取消关注占比，用户-品牌与用户浏览/点击/关注/加购/下单/取消关注占比etc.</p>
<h2 id="样本选择及特征预处理"><a href="#样本选择及特征预处理" class="headerlink" title="样本选择及特征预处理"></a>样本选择及特征预处理</h2><p>4-1 将观察天未来5天有购买行为的用户-商品对标记为正样本，观察天过去30天至未来5天有交互行为但未购买的用户-商品对标记为负样本。<br>Eg.(将2016-04-06~2016-04-10有下单的用户-商品标记为正样本，将2016-03-06~2016-04-10有交互但未下单的用户-商品标记为负样本)。 </p>
<p>4-2 由于正负样本比例极不平衡，正负样本比例约为1500:2400000，采用了对正样本进行重采样及负样本进行下采样的方式来平衡正负样本比例。<br>具体采样方式为：将正样本复制10份，同时将负样本通过随机采样为200000 </p>
<p>4-3 特征预处理：对于类型型特征：通过Spark VectorIndexer进行one-hot编码。对于连续型特征，通过Spark Normalizer进行归一化。  </p>
<h2 id="模型集成方案"><a href="#模型集成方案" class="headerlink" title="模型集成方案"></a>模型集成方案</h2><p>利用spark-xgboost进行滑窗模型训练，最后利用LR对各个预测结果进行加权。取每个用户最高预测概率对应的user-sku对，取top 12000作为最终输出结果。<br>单模型准确率xgboost&gt;gbdt&gt;rf，因此只选择了xgboost以滑窗方式进行模型训练，未采用多模型融合stacking，融合过程也只用了lr加权融合，其它方式待尝试。 </p>
<div align="center"><img src="/uploads/ml/4.jpg" width="1000" height="500" alt="1.1" align="center"></div>

<h2 id="代码运行说明"><a href="#代码运行说明" class="headerlink" title="代码运行说明"></a>代码运行说明</h2><h3 id="工程代码目录：JData-Spark"><a href="#工程代码目录：JData-Spark" class="headerlink" title="工程代码目录：JData-Spark"></a>工程代码目录：JData-Spark</h3><p>使用maven进行源码编译，成功编译后会生成jdata-spark-1.0-SNAPSHOT-assembly.zip<br>jdata-spark-1.0-SNAPSHOT-assembly.zip目录结构如下：</p>
<div align="center"><img src="/uploads/ml/1.jpg" width="1000" height="500" alt="1.1" align="center"></div>

<h3 id="脚本运行"><a href="#脚本运行" class="headerlink" title="脚本运行"></a>脚本运行</h3><p>进入到shell子目录，目录下各步骤脚本如下：</p>
<div align="center"><img src="/uploads/ml/2.jpg" width="1000" height="500" alt="1.1" align="center"></div><br>各个步骤运行说明，各个步骤间有依赖，每个步骤运行完再运行下一个步骤【首先需要将比赛数据集解压后手动放到data目录下】：<br>6-2-1 step1_load_basic_data_and_create_wide_table.sh：加载数据集到hive表，并将user/product/action汇总加工成为一张基础数据宽表。<br>运行命令：nohup sh step1_load_basic_data_and_create_wide_table.sh &gt; tmp.log &amp;<br><br>6-2-2 step2_run_dim_feature_while.sh：加工user/sku/brand/user_sku/user_brand各维度特征，由于后续使用了滑窗集成，所以需要运行多份(part1-part12)。<br>运行命令：nohup sh step2_run_dim_feature_while.sh &gt; tmp.log &amp;<br><br>6-2-3 step3_run_merge_feature_while.sh：将各个维度的特征汇总为一张宽表，便于后续进行抽样及模型训练。由于后续使用了滑窗集成，所以需要运行多份(part1-part12)。<br>运行命令：nohup sh step3_run_merge_feature_while.sh &gt; tmp.log &amp;<br>step3_run_predict_feature.sh：预测指标加工<br>运行命令：nohup sh step3_run_predict_feature.sh &gt; tmp.log &amp;<br><br>6-2-4 step4_run_sample_feature_while.sh：对加工的特征宽表进行采样<br>运行命令：nohup sh step4_run_sample_feature_while.sh &gt; tmp.log &amp;<br>由于模型训练是在风控集市跑的spark任务，因此若要让脚本在其它集市可用，需要手动修改脚本及配置文件【影响步骤3.2.5，3.2.6，3.2.7】<br><div align="center"><img src="/uploads/ml/3.jpg" width="1000" height="500" alt="1.1" align="center"></div>

<p>6-2-5 step5_jdata_runXgboost_train.sh：利用spark-xgboost进行模型训练<br>运行命令：nohup sh step5_jdata_runXgboost_train.sh &gt; tmp.log &amp; </p>
<p>6-2-6 step6_jdata_runXgboost_stacking.sh：将spark-xgboost训练好的6个子模型，进行stacking LR融合<br>运行命令：nohup sh step6_jdata_runXgboost_stacking.sh &gt; tmp.log &amp; </p>
<p>6-2-7 step7_jdata_runXgboost_stacking_predict.sh：利用3.2.6训练好的融合模型，预测用户在4.16-4.20会购买的user_sku对<br>运行命令：nohup sh step7_jdata_runXgboost_stacking_predict.sh &gt; tmp.log &amp;<br>6-2-8 待3.2.7步骤运行完后，需要手动将生成txt格式结果从hdfs目录down下来，并按比赛要求的格式整理输出<br>hadoop fs –get hdfs://ns2/user/mart_risk/sjmei/tests/xgboost/result_stacking_v3_20160406 </p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>第一次参加数据挖掘类比赛，作为一名新手，通过本次比赛，学习了数据挖掘的整个流程，同时也进一步熟悉了spark ml框架的使用。其次，更多的是在实践过程中体会到了自身的不足，要想打好比赛，必须源于对业务的深入理解及数据的细致分析，而这一点恰恰是做的最不好的。比赛中没有花很多时间对数据进行深入理解与细致分析。在特征处理，调参方面也做的很糙。 solo比赛很累，思维也很受限，只知道堆特征+xgboost+lr融合的方案，看到排行榜上其他同学的成绩都在噌噌地往上涨，而自己又不知道该如何优化涨分，成绩也一直停滞不前，以后要多向大牛学习以及多和别的同学一起交流学习。<br>作为一名CS专业毕业的人，对于使用各种数据挖掘工具进行技术实现不是什么问题，但其实对于数据挖掘来说，更重要的还是分析建模能力，对业务的感知能力，自己这方面还很欠缺，今后需要多多加强。<br>感谢公司举办的此次大赛，让我获益良多！ </p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;总体解决方案&quot;&gt;&lt;a href=&quot;#总体解决方案&quot; class=&quot;headerlink&quot; title=&quot;总体解决方案&quot;&gt;&lt;/a&gt;总体解决方案&lt;/h2&gt;&lt;p&gt;本文将高潜用户购买意向预测，抽象为一个二分类问题。从用户，商品，品牌，用户-商品，用户-品牌五个维度进行特征
    
    </summary>
    
      <category term="ML" scheme="http://yoursite.com/categories/ML/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
      <category term="Xgboost" scheme="http://yoursite.com/tags/Xgboost/"/>
    
  </entry>
  
  <entry>
    <title>xgboost4j编译安装笔记</title>
    <link href="http://yoursite.com/2017/05/05/xgboost-install/"/>
    <id>http://yoursite.com/2017/05/05/xgboost-install/</id>
    <published>2017-05-05T14:00:00.000Z</published>
    <updated>2017-08-17T02:16:53.560Z</updated>
    
    <content type="html"><![CDATA[<h3 id="clone工程"><a href="#clone工程" class="headerlink" title="clone工程"></a>clone工程</h3><p><code>git clone --recursive https://github.com/dmlc/xgboost.git</code> </p>
<h3 id="xgboost编译"><a href="#xgboost编译" class="headerlink" title="xgboost编译"></a>xgboost编译</h3><p><code>cd xgboost; make clean_all &amp;&amp; make -j4</code> </p>
<h3 id="xgboost-gpu编译-目前只支持python和cli调用"><a href="#xgboost-gpu编译-目前只支持python和cli调用" class="headerlink" title="xgboost gpu编译(目前只支持python和cli调用)"></a>xgboost gpu编译(目前只支持python和cli调用)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> xgboost</span></div><div class="line"><span class="meta">$</span><span class="bash"> mkdir build</span></div><div class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> build</span></div><div class="line"><span class="meta">$</span><span class="bash"> cmake .. -DPLUGIN_UPDATER_GPU=ON</span></div><div class="line"><span class="meta">$</span><span class="bash"> make -j</span></div><div class="line"></div><div class="line">or </div><div class="line"><span class="meta"></span></div><div class="line">$<span class="bash"> make -j PLUGIN_UPDATER_GPU=ON</span></div></pre></td></tr></table></figure>
<h3 id="xgboost4j编译"><a href="#xgboost4j编译" class="headerlink" title="xgboost4j编译"></a>xgboost4j编译</h3><p><code>cd jvm-packages;mvn clean &amp;&amp; mvn -Dmaven.test.skip=true -Dspark.version=2.1.0 package</code> </p>
<h3 id="xgboost-python编译"><a href="#xgboost-python编译" class="headerlink" title="xgboost python编译"></a>xgboost python编译</h3><p><code>cd python-package;python setup.py install</code></p>
<h3 id="Refrence"><a href="#Refrence" class="headerlink" title="Refrence"></a>Refrence</h3><p><code>1.</code> <a href="https://xgboost.readthedocs.io/en/latest/build.html" target="_blank" rel="external">https://xgboost.readthedocs.io/en/latest/build.html</a><br><code>2.</code> <a href="http://dmlc.ml/2016/12/14/GPU-accelerated-xgboost.html" target="_blank" rel="external">http://dmlc.ml/2016/12/14/GPU-accelerated-xgboost.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;clone工程&quot;&gt;&lt;a href=&quot;#clone工程&quot; class=&quot;headerlink&quot; title=&quot;clone工程&quot;&gt;&lt;/a&gt;clone工程&lt;/h3&gt;&lt;p&gt;&lt;code&gt;git clone --recursive https://github.com/dml
    
    </summary>
    
      <category term="Notes" scheme="http://yoursite.com/categories/Notes/"/>
    
    
      <category term="xgboost4j" scheme="http://yoursite.com/tags/xgboost4j/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>SparkML GBDT&amp;RF算法使用示例</title>
    <link href="http://yoursite.com/2017/01/10/spark-gbdt-rf/"/>
    <id>http://yoursite.com/2017/01/10/spark-gbdt-rf/</id>
    <published>2017-01-10T02:20:00.000Z</published>
    <updated>2017-06-18T06:37:40.950Z</updated>
    
    <content type="html"><![CDATA[<p>GBDT与RF作为机器学习中最常用的两个集成学习算法，Spark中也有相应的实现。下面是基于Spark 2.1.0 GBDT与RF算法的训练与预测(train/predict)接口实现。<br>功能： </p>
<pre><code>- train(训练)/train_cv(训练+网格搜索参数优化+交叉验证)/predict(预测)接口
</code></pre><h3 id="Random-Forest算法train-train-cv-predict实现："><a href="#Random-Forest算法train-train-cv-predict实现：" class="headerlink" title="Random Forest算法train/train_cv/predict实现："></a>Random Forest算法train/train_cv/predict实现：</h3><figure class="highlight sqf"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div></pre></td><td class="code"><pre><div class="line">import com.sjmei.jdata.utils.&#123;AlgoUtils, DataLoadUtils&#125;</div><div class="line">import org.apache.spark.examples.mllib.AbstractParams</div><div class="line">import org.apache.spark.ml.classification.&#123;RandomForestClassificationModel, RandomForestClassifier&#125;</div><div class="line">import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator</div><div class="line">import org.apache.spark.ml.tuning.&#123;CrossValidator, CrossValidatorModel, ParamGridBuilder&#125;</div><div class="line">import org.apache.spark.ml.&#123;Pipeline, PipelineStage&#125;</div><div class="line">import org.apache.spark.sql.DataFrame</div><div class="line">import scopt.OptionParser</div><div class="line"></div><div class="line">import scala.collection.mutable</div><div class="line">import scala.<span class="built_in">language</span>.reflectiveCalls</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Created by cdmeishangjian on 2016/10/20.</div><div class="line">  *</div><div class="line"> */</div><div class="line"></div><div class="line">object RandomForestTaskTest &#123;</div><div class="line"></div><div class="line">  <span class="keyword">case</span> class <span class="built_in">Params</span>(</div><div class="line">                     input: String = null,</div><div class="line">                     modelDir: String = null,</div><div class="line">                     output: String = null,</div><div class="line">                     <span class="built_in">taskType</span>: String = null,</div><div class="line">                     dataFormat: String = <span class="string">"libsvm"</span>,</div><div class="line">                     resultType: String = <span class="string">"rf_predict_eval"</span>,</div><div class="line">                     maxDepth: Int = <span class="number">10</span>,</div><div class="line">                     maxBins: Int = <span class="number">50</span>,</div><div class="line">                     minInstancesPerNode: Int = <span class="number">1</span>,</div><div class="line">                     minInfoGain: Double = <span class="number">0.0</span>,</div><div class="line">                     numTrees: Int = <span class="number">100</span>,</div><div class="line">                     featureSubsetStrategy: String = <span class="string">"auto"</span>,</div><div class="line">                     isCvModel: Boolean = <span class="literal">false</span>,</div><div class="line">                     fracTest: Double = <span class="number">0.1</span>,</div><div class="line">                     cacheNodeIds: Boolean = <span class="literal">false</span>,</div><div class="line">                     checkpointDir: Option[String] = None,</div><div class="line">                     checkpointInterval: Int = <span class="number">10</span>) extends AbstractParams[<span class="built_in">Params</span>]</div><div class="line"></div><div class="line">  def main(args: Array[String]) &#123;</div><div class="line">    val defaultParams = <span class="built_in">Params</span>()</div><div class="line"></div><div class="line">    val parser = new OptionParser[<span class="built_in">Params</span>](<span class="string">"RandomForestExample"</span>) &#123;</div><div class="line">      head(<span class="string">"RandomForestExample: an example random forest app."</span>)</div><div class="line">      opt[String](<span class="string">"resultType"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"algorithm (classification, regression), default: $&#123;defaultParams.resultType&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(resultType = x))</div><div class="line">      opt[Int](<span class="string">"maxDepth"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"max depth of the tree, default: $&#123;defaultParams.maxDepth&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(maxDepth = x))</div><div class="line">      opt[Int](<span class="string">"maxBins"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"max number of bins, default: $&#123;defaultParams.maxBins&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(maxBins = x))</div><div class="line">      opt[Int](<span class="string">"minInstancesPerNode"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"min number of instances required at child nodes to create the parent split,"</span> +</div><div class="line">        s<span class="string">" default: $&#123;defaultParams.minInstancesPerNode&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(minInstancesPerNode = x))</div><div class="line">      opt[Double](<span class="string">"minInfoGain"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"min info gain required to create a split, default: $&#123;defaultParams.minInfoGain&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(minInfoGain = x))</div><div class="line">      opt[Int](<span class="string">"numTrees"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"number of trees in ensemble, default: $&#123;defaultParams.numTrees&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(numTrees = x))</div><div class="line">      opt[String](<span class="string">"featureSubsetStrategy"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"number of features to use per node (supported:"</span> +</div><div class="line">        s<span class="string">" $&#123;RandomForestClassifier.supportedFeatureSubsetStrategies.mkString("</span>,<span class="string">")&#125;),"</span> +</div><div class="line">        s<span class="string">" default: $&#123;defaultParams.numTrees&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(featureSubsetStrategy = x))</div><div class="line">      opt[Double](<span class="string">"fracTest"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"fraction of data to hold out for testing. If given option testInput, "</span> +</div><div class="line">        s<span class="string">"this option is ignored. default: $&#123;defaultParams.fracTest&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(fracTest = x))</div><div class="line">      opt[Boolean](<span class="string">"isCvModel"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"is cvmodel flag: false (default)"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(isCvModel = x))</div><div class="line">      opt[Boolean](<span class="string">"cacheNodeIds"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"whether to use node Id cache during training, "</span> +</div><div class="line">        s<span class="string">"default: $&#123;defaultParams.cacheNodeIds&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(cacheNodeIds = x))</div><div class="line">      opt[String](<span class="string">"checkpointDir"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"checkpoint directory where intermediate node Id caches will be stored, "</span> +</div><div class="line">        s<span class="string">"default: $&#123;</span></div><div class="line">          defaultParams.checkpointDir match &#123;</div><div class="line">            case Some(strVal) =&gt; strVal</div><div class="line">            case None =&gt; "None<span class="string">"</span></div><div class="line">          &#125;</div><div class="line">        &#125;")</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(checkpointDir = Some(x)))</div><div class="line">      opt[Int](<span class="string">"checkpointInterval"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"how often to checkpoint the node Id cache, "</span> +</div><div class="line">        s<span class="string">"default: $&#123;defaultParams.checkpointInterval&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(checkpointInterval = x))</div><div class="line">      opt[String](<span class="string">"dataFormat"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"data format: libsvm (default), dense (deprecated in Spark v1.1)"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(dataFormat = x))</div><div class="line">      arg[String](<span class="string">"&lt;input&gt;"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"input path to labeled examples"</span>)</div><div class="line">        .required()</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(input = x))</div><div class="line">      arg[String](<span class="string">"&lt;modelDir&gt;"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"modelDir path to labeled examples"</span>)</div><div class="line">        .required()</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(modelDir = x))</div><div class="line">      arg[String](<span class="string">"&lt;output&gt;"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"output path to labeled examples"</span>)</div><div class="line">        .required()</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(output = x))</div><div class="line">      arg[String](<span class="string">"&lt;taskType&gt;"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"train or predict the rf model"</span>)</div><div class="line">        .required()</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(<span class="built_in">taskType</span> = x))</div><div class="line">      checkConfig &#123; <span class="built_in">params</span> =&gt;</div><div class="line">        <span class="keyword">if</span> (<span class="built_in">params</span>.fracTest &lt; <span class="number">0</span> || <span class="built_in">params</span>.fracTest &gt;= <span class="number">1</span>) &#123;</div><div class="line">          failure(s<span class="string">"fracTest $&#123;params.fracTest&#125; value incorrect; should be in [0,1)."</span>)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          success</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    parser.parse(args, defaultParams) match &#123;</div><div class="line">      <span class="keyword">case</span> Some(<span class="built_in">params</span>) =&gt; &#123;</div><div class="line">        <span class="built_in">params</span>.<span class="built_in">taskType</span>.trim.toLowerCase match &#123;</div><div class="line">          <span class="keyword">case</span> <span class="string">"train"</span> =&gt; train(<span class="built_in">params</span>)</div><div class="line">          <span class="keyword">case</span> <span class="string">"train_cv"</span> =&gt; train_cv(<span class="built_in">params</span>)</div><div class="line">          <span class="keyword">case</span> <span class="string">"predict"</span> =&gt; predict(<span class="built_in">params</span>)</div><div class="line">          <span class="keyword">case</span> _ =&gt; println(<span class="string">"XGBoost method error..."</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">case</span> _ =&gt; sys.<span class="keyword">exit</span>(<span class="number">1</span>)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  def train(<span class="built_in">params</span>: <span class="built_in">Params</span>): Unit = &#123;</div><div class="line"></div><div class="line">    val spark = AlgoUtils.getSparkSession(s<span class="string">"RandomForestExample with $params"</span>)</div><div class="line">    <span class="built_in">params</span>.checkpointDir.<span class="keyword">foreach</span>(spark.sparkContext.setCheckpointDir)</div><div class="line">    val algo = <span class="built_in">params</span>.resultType.toLowerCase</div><div class="line"></div><div class="line">    println(s<span class="string">"RandomForestExample with parameters:\n$params"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Load training and test data and cache it.</span></div><div class="line">    val (training: DataFrame, test: DataFrame) = DataLoadUtils.loadTrainData(spark, <span class="built_in">params</span>.input, <span class="built_in">params</span>.fracTest)</div><div class="line"></div><div class="line">    <span class="comment">// Set up Pipeline.</span></div><div class="line">    val stages = new mutable.ArrayBuffer[PipelineStage]()</div><div class="line"></div><div class="line">    val dt = new RandomForestClassifier()</div><div class="line">      .setFeaturesCol(<span class="string">"features"</span>)</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setMaxDepth(<span class="built_in">params</span>.maxDepth)</div><div class="line">      .setMaxBins(<span class="built_in">params</span>.maxBins)</div><div class="line">      .setMinInstancesPerNode(<span class="built_in">params</span>.minInstancesPerNode)</div><div class="line">      .setMinInfoGain(<span class="built_in">params</span>.minInfoGain)</div><div class="line">      .setCacheNodeIds(<span class="built_in">params</span>.cacheNodeIds)</div><div class="line">      .setCheckpointInterval(<span class="built_in">params</span>.checkpointInterval)</div><div class="line">      .setFeatureSubsetStrategy(<span class="built_in">params</span>.featureSubsetStrategy)</div><div class="line">      .setNumTrees(<span class="built_in">params</span>.numTrees)</div><div class="line"></div><div class="line">    stages += dt</div><div class="line">    val pipeline = new Pipeline().setStages(stages.<span class="built_in">toArray</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Fit the Pipeline.</span></div><div class="line">    val startTime = System.nanoTime()</div><div class="line">    val pipelineModel = pipeline.fit(training)</div><div class="line">    val elapsedTime = (System.nanoTime() - startTime) / <span class="number">1</span>e9</div><div class="line">    println(s<span class="string">"Training time: $elapsedTime seconds"</span>)</div><div class="line"></div><div class="line">    val rfModel = pipelineModel.stages.last.asInstanceOf[RandomForestClassificationModel]</div><div class="line">    rfModel.write.overwrite.save(<span class="built_in">params</span>.modelDir)</div><div class="line"></div><div class="line">    val predictions = pipelineModel.transform(training)</div><div class="line">    val df_test_pred = pipelineModel.transform(test)</div><div class="line">    <span class="comment">// Get the trained Random Forest from the fitted PipelineModel.</span></div><div class="line">    <span class="keyword">if</span> (rfModel.totalNumNodes &lt; <span class="number">30</span>) &#123;</div><div class="line">      println(rfModel.toDebugString) <span class="comment">// Print full model.</span></div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      println(rfModel) <span class="comment">// Print model summary.</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Evaluate model on training, test data.</span></div><div class="line">    println(<span class="string">"Training &amp; Testing data evaluate results:"</span>)</div><div class="line">    val evaluator = new MulticlassClassificationEvaluator()</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</div><div class="line">    val train_accuracy = evaluator.evaluate(predictions)</div><div class="line">    val test_accuracy = evaluator.evaluate(df_test_pred)</div><div class="line">    println(s<span class="string">"Train Accuracy = $train_accuracy,  Test Accuracy = $test_accuracy"</span>)</div><div class="line">    predictions.printSchema()</div><div class="line"></div><div class="line">    spark.<span class="built_in">stop</span>()</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line">  def train_cv(<span class="built_in">params</span>: <span class="built_in">Params</span>): Unit = &#123;</div><div class="line"></div><div class="line">    val spark = AlgoUtils.getSparkSession(s<span class="string">"RandomForestExample with $params"</span>)</div><div class="line"></div><div class="line">    <span class="built_in">params</span>.checkpointDir.<span class="keyword">foreach</span>(spark.sparkContext.setCheckpointDir)</div><div class="line">    val algo = <span class="built_in">params</span>.resultType.toLowerCase</div><div class="line"></div><div class="line">    println(s<span class="string">"RandomForestExample with parameters:\n$params"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Load training and test data and cache it.</span></div><div class="line">    val (training: DataFrame, test: DataFrame) = DataLoadUtils.loadTrainData(spark, <span class="built_in">params</span>.input, <span class="built_in">params</span>.fracTest)</div><div class="line"></div><div class="line">    <span class="comment">// Set up Pipeline.</span></div><div class="line">    val stages = new mutable.ArrayBuffer[PipelineStage]()</div><div class="line"></div><div class="line">    val dt = new RandomForestClassifier()</div><div class="line">      .setFeaturesCol(<span class="string">"features"</span>)</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setMaxDepth(<span class="built_in">params</span>.maxDepth)</div><div class="line">      .setMaxBins(<span class="built_in">params</span>.maxBins)</div><div class="line">      .setMinInstancesPerNode(<span class="built_in">params</span>.minInstancesPerNode)</div><div class="line">      .setMinInfoGain(<span class="built_in">params</span>.minInfoGain)</div><div class="line">      .setCacheNodeIds(<span class="built_in">params</span>.cacheNodeIds)</div><div class="line">      .setCheckpointInterval(<span class="built_in">params</span>.checkpointInterval)</div><div class="line">      .setFeatureSubsetStrategy(<span class="built_in">params</span>.featureSubsetStrategy)</div><div class="line">      .setNumTrees(<span class="built_in">params</span>.numTrees)</div><div class="line"></div><div class="line">    stages += dt</div><div class="line">    val pipeline = new Pipeline().setStages(stages.<span class="built_in">toArray</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Fit the Pipeline.</span></div><div class="line">    val startTime = System.nanoTime()</div><div class="line"></div><div class="line">    <span class="comment">// We use a ParamGridBuilder to construct a grid of parameters to search over.</span></div><div class="line">    val paramGrid = new ParamGridBuilder()</div><div class="line">      .addGrid(dt.maxDepth, Array(<span class="number">8</span>, <span class="number">10</span>))</div><div class="line">      .addGrid(dt.numTrees, Array(<span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>))</div><div class="line">      .build()</div><div class="line"></div><div class="line">    <span class="comment">// We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.</span></div><div class="line">    <span class="comment">// This will allow us to jointly choose parameters for all Pipeline stages.</span></div><div class="line">    <span class="comment">// A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.</span></div><div class="line">    <span class="comment">// Note that the evaluator here is a BinaryClassificationEvaluator and its default metric</span></div><div class="line">    <span class="comment">// is areaUnderROC.</span></div><div class="line">    val cv = new CrossValidator()</div><div class="line">      .setEstimator(pipeline)</div><div class="line">      .setEvaluator(new MulticlassClassificationEvaluator)</div><div class="line">      .setEstimatorParamMaps(paramGrid)</div><div class="line">      .setNumFolds(<span class="number">5</span>)  <span class="comment">// Use 3+ in practice</span></div><div class="line"></div><div class="line">    <span class="comment">// Run cross-validation, and choose the best set of parameters.</span></div><div class="line">    val cvModel = cv.fit(training)</div><div class="line">    cvModel.write.overwrite.save(<span class="built_in">params</span>.modelDir)</div><div class="line">    <span class="comment">// Make predictions on test documents. cvModel uses the best model found (lrModel).</span></div><div class="line">    val train_predict = cvModel.transform(training).<span class="built_in">select</span>(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>)</div><div class="line">    val test_predict = cvModel.transform(test).<span class="built_in">select</span>(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>)</div><div class="line">    val evaluator = new MulticlassClassificationEvaluator()</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</div><div class="line">    val train_accuracy = evaluator.evaluate(train_predict)</div><div class="line">    val test_accuracy = evaluator.evaluate(test_predict)</div><div class="line">    println(s<span class="string">"Train Accuracy = $train_accuracy,  Test Accuracy = $test_accuracy"</span>)</div><div class="line">    <span class="comment">// $example off$</span></div><div class="line"></div><div class="line">    val elapsedTime = (System.nanoTime() - startTime) / <span class="number">1</span>e9</div><div class="line">    println(s<span class="string">"Training time: $elapsedTime seconds"</span>)</div><div class="line"></div><div class="line">    train_predict.printSchema()</div><div class="line">    train_predict.<span class="built_in">select</span>(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>).show(<span class="number">10</span>)</div><div class="line"></div><div class="line">    spark.<span class="built_in">stop</span>()</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line">  def predict(<span class="built_in">params</span>: <span class="built_in">Params</span>): Unit = &#123;</div><div class="line">    val spark = AlgoUtils.getSparkSession(s<span class="string">"RandomForestExample with $params"</span>)</div><div class="line"></div><div class="line">    <span class="built_in">params</span>.checkpointDir.<span class="keyword">foreach</span>(spark.sparkContext.setCheckpointDir)</div><div class="line"></div><div class="line">    println(s<span class="string">"RandomForestExample with parameters:\n$params"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Load training and test data and cache it.</span></div><div class="line">    val datasets = DataLoadUtils.loadPredictDataOrc(spark, <span class="built_in">params</span>.input)</div><div class="line"></div><div class="line">    <span class="comment">// Fit the Pipeline.</span></div><div class="line">    val startTime = System.nanoTime()</div><div class="line"></div><div class="line">    var predictions: DataFrame = null</div><div class="line">    <span class="keyword">if</span>(<span class="built_in">params</span>.isCvModel)&#123;</div><div class="line">      val predModel = CrossValidatorModel.<span class="built_in">load</span>(<span class="built_in">params</span>.modelDir)</div><div class="line">      predictions = predModel.transform(datasets)</div><div class="line"></div><div class="line">    &#125;<span class="keyword">else</span>&#123;</div><div class="line">      val predModel = RandomForestClassificationModel.<span class="built_in">load</span>(<span class="built_in">params</span>.modelDir)</div><div class="line">      predictions = predModel.transform(datasets)</div><div class="line">    &#125;</div><div class="line">    val elapsedTime = (System.nanoTime() - startTime) / <span class="number">1</span>e9</div><div class="line">    println(s<span class="string">"Training time: $elapsedTime seconds"</span>)</div><div class="line"></div><div class="line">    AlgoUtils.saveRFPredictResult(spark, predictions, <span class="built_in">params</span>)</div><div class="line"></div><div class="line"></div><div class="line">    datasets.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    predictions.unpersist(blocking = <span class="literal">false</span>)</div><div class="line"></div><div class="line">    spark.<span class="built_in">stop</span>()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="GBDT算法train-train-cv-predict实现"><a href="#GBDT算法train-train-cv-predict实现" class="headerlink" title="GBDT算法train/train_cv/predict实现:"></a>GBDT算法train/train_cv/predict实现:</h3><figure class="highlight sqf"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div></pre></td><td class="code"><pre><div class="line">import com.sjmei.jdata.utils.&#123;AlgoUtils, DataLoadUtils&#125;</div><div class="line">import org.apache.spark.examples.mllib.AbstractParams</div><div class="line">import org.apache.spark.ml.classification.&#123;GBTClassificationModel, GBTClassifier&#125;</div><div class="line">import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator</div><div class="line">import org.apache.spark.ml.tuning.&#123;CrossValidator, CrossValidatorModel, ParamGridBuilder&#125;</div><div class="line">import org.apache.spark.ml.&#123;Pipeline, PipelineStage&#125;</div><div class="line">import org.apache.spark.sql.DataFrame</div><div class="line">import org.apache.spark.utils.Logging</div><div class="line">import scopt.OptionParser</div><div class="line"></div><div class="line">import scala.collection.mutable</div><div class="line">import scala.<span class="built_in">language</span>.reflectiveCalls</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  *</div><div class="line">  * Created by cdmeishangjian on 2016/10/26.</div><div class="line">  *</div><div class="line">  */</div><div class="line">object GBTTaskTest extends Logging &#123;</div><div class="line"></div><div class="line">  <span class="keyword">case</span> class <span class="built_in">Params</span>(</div><div class="line">      input: String = null,</div><div class="line">      modelDir: String = null,</div><div class="line">      output: String = null,</div><div class="line">      <span class="built_in">taskType</span>:String = null,</div><div class="line">      dataFormat: String = <span class="string">"libsvm"</span>,</div><div class="line">      algo: String = <span class="string">"classification"</span>,</div><div class="line">      maxDepth: Int = <span class="number">10</span>,</div><div class="line">      maxBins: Int = <span class="number">50</span>,</div><div class="line">      minInstancesPerNode: Int = <span class="number">1</span>,</div><div class="line">      minInfoGain: Double = <span class="number">0.0</span>,</div><div class="line">      maxIter: Int = <span class="number">100</span>,</div><div class="line">      fracTest: Double = <span class="number">0.1</span>,</div><div class="line">      isCvModel: Boolean = <span class="literal">false</span>,</div><div class="line">      cacheNodeIds: Boolean = <span class="literal">false</span>,</div><div class="line">      checkpointDir: Option[String] = None,</div><div class="line">      checkpointInterval: Int = <span class="number">10</span>) extends AbstractParams[<span class="built_in">Params</span>]</div><div class="line"></div><div class="line">  def main(args: Array[String]) &#123;</div><div class="line">    val defaultParams = <span class="built_in">Params</span>()</div><div class="line"></div><div class="line">    val parser = new OptionParser[<span class="built_in">Params</span>](<span class="string">"GBTExample"</span>) &#123;</div><div class="line">      head(<span class="string">"GBTExample: an example Gradient-Boosted Trees app."</span>)</div><div class="line">      opt[String](<span class="string">"algo"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"algorithm (classification, regression), default: $&#123;defaultParams.algo&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(algo = x))</div><div class="line">      opt[Int](<span class="string">"maxDepth"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"max depth of the tree, default: $&#123;defaultParams.maxDepth&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(maxDepth = x))</div><div class="line">      opt[Int](<span class="string">"maxBins"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"max number of bins, default: $&#123;defaultParams.maxBins&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(maxBins = x))</div><div class="line">      opt[Int](<span class="string">"minInstancesPerNode"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"min number of instances required at child nodes to create the parent split,"</span> +</div><div class="line">        s<span class="string">" default: $&#123;defaultParams.minInstancesPerNode&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(minInstancesPerNode = x))</div><div class="line">      opt[Double](<span class="string">"minInfoGain"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"min info gain required to create a split, default: $&#123;defaultParams.minInfoGain&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(minInfoGain = x))</div><div class="line">      opt[Int](<span class="string">"maxIter"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"number of trees in ensemble, default: $&#123;defaultParams.maxIter&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(maxIter = x))</div><div class="line">      opt[Double](<span class="string">"fracTest"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"fraction of data to hold out for testing. If given option testInput, "</span> +</div><div class="line">        s<span class="string">"this option is ignored. default: $&#123;defaultParams.fracTest&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(fracTest = x))</div><div class="line">      opt[Boolean](<span class="string">"isCvModel"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"is cvmodel flag: false (default)"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(isCvModel = x))</div><div class="line">      opt[Boolean](<span class="string">"cacheNodeIds"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"whether to use node Id cache during training, "</span> +</div><div class="line">        s<span class="string">"default: $&#123;defaultParams.cacheNodeIds&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(cacheNodeIds = x))</div><div class="line">      opt[String](<span class="string">"checkpointDir"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"checkpoint directory where intermediate node Id caches will be stored, "</span> +</div><div class="line">        s<span class="string">"default: $&#123;</span></div><div class="line">          defaultParams.checkpointDir match &#123;</div><div class="line">            case Some(strVal) =&gt; strVal</div><div class="line">            case None =&gt; "None<span class="string">"</span></div><div class="line">          &#125;</div><div class="line">        &#125;")</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(checkpointDir = Some(x)))</div><div class="line">      opt[Int](<span class="string">"checkpointInterval"</span>)</div><div class="line">        .<span class="built_in">text</span>(s<span class="string">"how often to checkpoint the node Id cache, "</span> +</div><div class="line">        s<span class="string">"default: $&#123;defaultParams.checkpointInterval&#125;"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(checkpointInterval = x))</div><div class="line">      opt[String](<span class="string">"dataFormat"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"data format: libsvm (default), dense (deprecated in Spark v1.1)"</span>)</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(dataFormat = x))</div><div class="line">      arg[String](<span class="string">"&lt;input&gt;"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"input path to labeled examples"</span>)</div><div class="line">        .required()</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(input = x))</div><div class="line">      arg[String](<span class="string">"&lt;modelDir&gt;"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"modelDir path to labeled examples"</span>)</div><div class="line">        .required()</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(modelDir = x))</div><div class="line">      arg[String](<span class="string">"&lt;output&gt;"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"output path to labeled examples"</span>)</div><div class="line">        .required()</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(output = x))</div><div class="line">      arg[String](<span class="string">"&lt;taskType&gt;"</span>)</div><div class="line">        .<span class="built_in">text</span>(<span class="string">"train or predict the rf model"</span>)</div><div class="line">        .required()</div><div class="line">        .<span class="built_in">action</span>((x, c) =&gt; c.copy(<span class="built_in">taskType</span> = x))</div><div class="line">      checkConfig &#123; <span class="built_in">params</span> =&gt;</div><div class="line">        <span class="keyword">if</span> (<span class="built_in">params</span>.fracTest &lt; <span class="number">0</span> || <span class="built_in">params</span>.fracTest &gt;= <span class="number">1</span>) &#123;</div><div class="line">          failure(s<span class="string">"fracTest $&#123;params.fracTest&#125; value incorrect; should be in [0,1)."</span>)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          success</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    parser.parse(args, defaultParams) match &#123;</div><div class="line">      <span class="keyword">case</span> Some(<span class="built_in">params</span>) =&gt; &#123;</div><div class="line">        <span class="built_in">params</span>.<span class="built_in">taskType</span>.trim.toLowerCase match &#123;</div><div class="line">          <span class="keyword">case</span> <span class="string">"train"</span> =&gt; train(<span class="built_in">params</span>)</div><div class="line">          <span class="keyword">case</span> <span class="string">"train_cv"</span> =&gt; train_cv(<span class="built_in">params</span>)</div><div class="line">          <span class="keyword">case</span> <span class="string">"predict"</span> =&gt; predict(<span class="built_in">params</span>)</div><div class="line">          <span class="keyword">case</span> _ =&gt; println(<span class="string">"XGBoost method error..."</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">case</span> _ =&gt; sys.<span class="keyword">exit</span>(<span class="number">1</span>)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  def train(<span class="built_in">params</span>: <span class="built_in">Params</span>): Unit = &#123;</div><div class="line">    val spark = AlgoUtils.getSparkSession(s<span class="string">"GBTExample with $params"</span>)</div><div class="line"></div><div class="line">    <span class="built_in">params</span>.checkpointDir.<span class="keyword">foreach</span>(spark.sparkContext.setCheckpointDir)</div><div class="line">    val algo = <span class="built_in">params</span>.algo.toLowerCase</div><div class="line"></div><div class="line">    println(s<span class="string">"GBTExample with parameters:\n$params"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Load training and test data and cache it.</span></div><div class="line">    val (training: DataFrame, test: DataFrame) = DataLoadUtils.loadTrainData(spark, <span class="built_in">params</span>.input, <span class="built_in">params</span>.fracTest)</div><div class="line"></div><div class="line">    <span class="comment">// Set up Pipeline</span></div><div class="line">    val stages = new mutable.ArrayBuffer[PipelineStage]()</div><div class="line"></div><div class="line">    <span class="comment">// Learn GBT.</span></div><div class="line">    val dt =  new GBTClassifier()</div><div class="line">      .setFeaturesCol(<span class="string">"features"</span>)</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setMaxDepth(<span class="built_in">params</span>.maxDepth)</div><div class="line">      .setMaxBins(<span class="built_in">params</span>.maxBins)</div><div class="line">      .setMinInstancesPerNode(<span class="built_in">params</span>.minInstancesPerNode)</div><div class="line">      .setMinInfoGain(<span class="built_in">params</span>.minInfoGain)</div><div class="line">      .setCacheNodeIds(<span class="built_in">params</span>.cacheNodeIds)</div><div class="line">      .setCheckpointInterval(<span class="built_in">params</span>.checkpointInterval)</div><div class="line">      .setMaxIter(<span class="built_in">params</span>.maxIter)</div><div class="line">    </div><div class="line">    stages += dt</div><div class="line">    val pipeline = new Pipeline().setStages(stages.<span class="built_in">toArray</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Fit the Pipeline.</span></div><div class="line">    val startTime = System.nanoTime()</div><div class="line">    val pipelineModel = pipeline.fit(training)</div><div class="line">    val elapsedTime = (System.nanoTime() - startTime) / <span class="number">1</span>e9</div><div class="line">    println(s<span class="string">"Training time: $elapsedTime seconds"</span>)</div><div class="line"></div><div class="line">    val gbtModel = pipelineModel.stages.last.asInstanceOf[GBTClassificationModel]</div><div class="line">    gbtModel.write.overwrite.save(<span class="built_in">params</span>.modelDir)</div><div class="line"></div><div class="line">    val predictions = pipelineModel.transform(training)</div><div class="line">    val df_test_pred = pipelineModel.transform(test)</div><div class="line">    <span class="comment">// Get the trained GBT from the fitted PipelineModel.</span></div><div class="line">    <span class="keyword">if</span> (gbtModel.totalNumNodes &lt; <span class="number">30</span>) &#123;</div><div class="line">      println(gbtModel.toDebugString) <span class="comment">// Print full model.</span></div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      println(gbtModel) <span class="comment">// Print model summary.</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Evaluate model on training, test data.</span></div><div class="line">    println(<span class="string">"Training &amp; Testing data evaluate results:"</span>)</div><div class="line">    val evaluator = new MulticlassClassificationEvaluator()</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</div><div class="line">      .setMetricName(<span class="string">"accuracy"</span>)</div><div class="line">    val train_accuracy = evaluator.evaluate(predictions)</div><div class="line">    val test_accuracy = evaluator.evaluate(df_test_pred)</div><div class="line">    println(s<span class="string">"Train Accuracy = $train_accuracy,  Test Accuracy = $test_accuracy"</span>)</div><div class="line"></div><div class="line">    AlgoUtils.saveNormProbResult(spark, predictions, <span class="built_in">params</span>.output)</div><div class="line">    predictions.printSchema()</div><div class="line">    predictions.<span class="built_in">select</span>(<span class="string">"prediction"</span>,<span class="string">"rawPrediction"</span>,<span class="string">"probability"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</div><div class="line"></div><div class="line">    spark.<span class="built_in">stop</span>()</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  def train_cv(<span class="built_in">params</span>: <span class="built_in">Params</span>): Unit = &#123;</div><div class="line">    val spark = AlgoUtils.getSparkSession(s<span class="string">"GBTExample with $params"</span>)</div><div class="line"></div><div class="line">    <span class="built_in">params</span>.checkpointDir.<span class="keyword">foreach</span>(spark.sparkContext.setCheckpointDir)</div><div class="line">    val algo = <span class="built_in">params</span>.algo.toLowerCase</div><div class="line">    println(s<span class="string">"GBTExample with parameters:\n$params"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Load training and test data and cache it.</span></div><div class="line">    val (training: DataFrame, test: DataFrame) = DataLoadUtils.loadTrainData(spark, <span class="built_in">params</span>.input, <span class="built_in">params</span>.fracTest)</div><div class="line">    <span class="comment">// Set up Pipeline.</span></div><div class="line">    val stages = new mutable.ArrayBuffer[PipelineStage]()</div><div class="line"></div><div class="line">    <span class="comment">// Learn GBT.</span></div><div class="line">    val dt = new GBTClassifier()</div><div class="line">      .setFeaturesCol(<span class="string">"features"</span>)</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setMaxDepth(<span class="built_in">params</span>.maxDepth)</div><div class="line">      .setMaxBins(<span class="built_in">params</span>.maxBins)</div><div class="line">      .setMinInstancesPerNode(<span class="built_in">params</span>.minInstancesPerNode)</div><div class="line">      .setMinInfoGain(<span class="built_in">params</span>.minInfoGain)</div><div class="line">      .setCacheNodeIds(<span class="built_in">params</span>.cacheNodeIds)</div><div class="line">      .setCheckpointInterval(<span class="built_in">params</span>.checkpointInterval)</div><div class="line">      .setMaxIter(<span class="built_in">params</span>.maxIter)</div><div class="line">    </div><div class="line">    stages += dt</div><div class="line">    val pipeline = new Pipeline().setStages(stages.<span class="built_in">toArray</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Fit the Pipeline.</span></div><div class="line">    val startTime = System.nanoTime()</div><div class="line"></div><div class="line">    <span class="comment">// We use a ParamGridBuilder to construct a grid of parameters to search over.</span></div><div class="line">    val paramGrid = new ParamGridBuilder()</div><div class="line">      .addGrid(dt.maxDepth, Array(<span class="number">8</span>, <span class="number">10</span>))</div><div class="line">      .addGrid(dt.maxIter, Array(<span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>))</div><div class="line">      .build()</div><div class="line"></div><div class="line">    <span class="comment">// We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.</span></div><div class="line">    <span class="comment">// This will allow us to jointly choose parameters for all Pipeline stages.</span></div><div class="line">    <span class="comment">// A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.</span></div><div class="line">    <span class="comment">// Note that the evaluator here is a BinaryClassificationEvaluator and its default metric</span></div><div class="line">    <span class="comment">// is areaUnderROC.</span></div><div class="line">    val cv = new CrossValidator()</div><div class="line">      .setEstimator(pipeline)</div><div class="line">      .setEvaluator(new MulticlassClassificationEvaluator)</div><div class="line">      .setEstimatorParamMaps(paramGrid)</div><div class="line">      .setNumFolds(<span class="number">5</span>)  <span class="comment">// Use 3+ in practice</span></div><div class="line"></div><div class="line">    <span class="comment">// Run cross-validation, and choose the best set of parameters.</span></div><div class="line">    val cvModel = cv.fit(training)</div><div class="line">    cvModel.write.overwrite.save(<span class="built_in">params</span>.modelDir)</div><div class="line">    <span class="comment">// Make predictions on test documents. cvModel uses the best model found (lrModel).</span></div><div class="line">    val train_predict = cvModel.transform(training).<span class="built_in">select</span>(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>)</div><div class="line">    val test_predict = cvModel.transform(test).<span class="built_in">select</span>(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>)</div><div class="line">    val evaluator = new MulticlassClassificationEvaluator()</div><div class="line">      .setLabelCol(<span class="string">"label"</span>)</div><div class="line">      .setPredictionCol(<span class="string">"prediction"</span>)</div><div class="line">    val train_accuracy = evaluator.evaluate(train_predict)</div><div class="line">    val test_accuracy = evaluator.evaluate(test_predict)</div><div class="line">    println(s<span class="string">"Train Accuracy = $train_accuracy,  Test Accuracy = $test_accuracy"</span>)</div><div class="line">    <span class="comment">// $example off$</span></div><div class="line"></div><div class="line">    val elapsedTime = (System.nanoTime() - startTime) / <span class="number">1</span>e9</div><div class="line">    println(s<span class="string">"Training time: $elapsedTime seconds"</span>)</div><div class="line"></div><div class="line">    train_predict.printSchema()</div><div class="line">    train_predict.<span class="built_in">select</span>(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>).show(<span class="number">10</span>)</div><div class="line"></div><div class="line">    spark.<span class="built_in">stop</span>()</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line">  def predict(<span class="built_in">params</span>: <span class="built_in">Params</span>): Unit = &#123;</div><div class="line">    val spark = AlgoUtils.getSparkSession(s<span class="string">"GBTExample with $params"</span>)</div><div class="line"></div><div class="line">    <span class="built_in">params</span>.checkpointDir.<span class="keyword">foreach</span>(spark.sparkContext.setCheckpointDir)</div><div class="line"></div><div class="line">    println(s<span class="string">"GBTExample with parameters:\n$params"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Load training and test data and cache it.</span></div><div class="line">    val datasets = DataLoadUtils.loadPredictDataOrc(spark,<span class="built_in">params</span>.input)</div><div class="line"></div><div class="line">    <span class="comment">// Fit the Pipeline.</span></div><div class="line">    val startTime = System.nanoTime()</div><div class="line">    var results: DataFrame = null</div><div class="line">    <span class="keyword">if</span>(<span class="built_in">params</span>.isCvModel)&#123;</div><div class="line">      val predModel = CrossValidatorModel.<span class="built_in">load</span>(<span class="built_in">params</span>.modelDir)</div><div class="line">      results = predModel.transform(datasets)</div><div class="line"></div><div class="line">    &#125;<span class="keyword">else</span>&#123;</div><div class="line">      val predModel = GBTClassificationModel.<span class="built_in">load</span>(<span class="built_in">params</span>.modelDir)</div><div class="line">      results = predModel.transform(datasets)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    val elapsedTime = (System.nanoTime() - startTime) / <span class="number">1</span>e9</div><div class="line">    println(s<span class="string">"Training time: $elapsedTime seconds"</span>)</div><div class="line"></div><div class="line">    AlgoUtils.saveNormProbResult(spark, results, <span class="built_in">params</span>.output)</div><div class="line"></div><div class="line">    datasets.unpersist(blocking = <span class="literal">false</span>)</div><div class="line">    results.unpersist(blocking = <span class="literal">false</span>)</div><div class="line"></div><div class="line">    spark.<span class="built_in">stop</span>()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;GBDT与RF作为机器学习中最常用的两个集成学习算法，Spark中也有相应的实现。下面是基于Spark 2.1.0 GBDT与RF算法的训练与预测(train/predict)接口实现。&lt;br&gt;功能： &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- train(训练)/train_cv
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
      <category term="Random Forest" scheme="http://yoursite.com/tags/Random-Forest/"/>
    
      <category term="GBDT" scheme="http://yoursite.com/tags/GBDT/"/>
    
  </entry>
  
  <entry>
    <title>Spark ML离线训练模型用于在线预测</title>
    <link href="http://yoursite.com/2017/01/10/spark-ml-realtime-predict/"/>
    <id>http://yoursite.com/2017/01/10/spark-ml-realtime-predict/</id>
    <published>2017-01-10T02:20:00.000Z</published>
    <updated>2017-06-18T05:54:40.587Z</updated>
    
    <content type="html"><![CDATA[<p>最近公司有需求需要将离线训练好的算法模型应用到线上去实时预测，在线预测不考虑feature加工的情况下，经调研，发现jpmml-sparkml+jpmml-evaluator的方式可以满足条件。不过使用时需要注意该框架是AGPL-3.0协议。 </p>
<h2 id="方案：spark-ml-jpmml-sparkml-jpmml-evaluator"><a href="#方案：spark-ml-jpmml-sparkml-jpmml-evaluator" class="headerlink" title="方案：spark ml + jpmml-sparkml + jpmml-evaluator"></a>方案：spark ml + jpmml-sparkml + jpmml-evaluator</h2><h3 id="Spark离线训练Random-Forest模型并保存为pmml格式："><a href="#Spark离线训练Random-Forest模型并保存为pmml格式：" class="headerlink" title="Spark离线训练Random Forest模型并保存为pmml格式："></a>Spark离线训练Random Forest模型并保存为pmml格式：</h3><figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">import</span> java.io.FileOutputStream</div><div class="line"><span class="built_in">import</span> javax.xml.transform.stream.StreamResult</div><div class="line"></div><div class="line"><span class="built_in">import</span> com.jd.risk.utils.HadoopFileUtil</div><div class="line"><span class="built_in">import</span> org.apache.hadoop.conf.Configuration</div><div class="line"><span class="built_in">import</span> org.apache.hadoop.fs.Path</div><div class="line"><span class="built_in">import</span> org.apache.spark.examples.ml.DecisionTreeExample</div><div class="line"><span class="built_in">import</span> org.apache.spark.examples.mllib.AbstractParams</div><div class="line"><span class="built_in">import</span> org.apache.spark.ml.classification.&#123;RandomForestClassificationModel, RandomForestClassifier&#125;</div><div class="line"><span class="built_in">import</span> org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator</div><div class="line"><span class="built_in">import</span> org.apache.spark.ml.feature.&#123;StringIndexer, VectorAssembler, VectorIndexer&#125;</div><div class="line"><span class="built_in">import</span> org.apache.spark.ml.regression.&#123;RandomForestRegressionModel, RandomForestRegressor&#125;</div><div class="line"><span class="built_in">import</span> org.apache.spark.ml.&#123;Pipeline, PipelineStage&#125;</div><div class="line"><span class="built_in">import</span> org.apache.spark.sql.&#123;DataFrame, SparkSession&#125;</div><div class="line"><span class="built_in">import</span> org.jpmml.model.&#123;JAXBUtil, MetroJAXBUtil&#125;</div><div class="line"><span class="built_in">import</span> org.jpmml.sparkml.ConverterUtil</div><div class="line"><span class="built_in">import</span> scopt.OptionParser</div><div class="line"></div><div class="line"><span class="built_in">import</span> scala.collection.mutable</div><div class="line"><span class="built_in">import</span> scala.language.reflectiveCalls</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Created by cdmeishangjian on 2017/01/19.</div><div class="line">  */</div><div class="line">object RandomForestPMMLTask &#123;</div><div class="line"></div><div class="line">  case class Params(</div><div class="line">      input: <span class="attr">String</span> = <span class="literal">null</span>,</div><div class="line">      modelDir: <span class="attr">String</span> = <span class="literal">null</span>,</div><div class="line">      taskType:<span class="attr">String</span> = <span class="string">"train"</span>,</div><div class="line">      testInput: <span class="attr">String</span> = <span class="string">""</span>,</div><div class="line">      dataFormat: <span class="attr">String</span> = <span class="string">"libsvm"</span>,</div><div class="line">      algo: <span class="attr">String</span> = <span class="string">"classification"</span>,</div><div class="line">      maxDepth: <span class="attr">Int</span> = <span class="number">4</span>,</div><div class="line">      maxBins: <span class="attr">Int</span> = <span class="number">32</span>,</div><div class="line">      minInstancesPerNode: <span class="attr">Int</span> = <span class="number">1</span>,</div><div class="line">      minInfoGain: <span class="attr">Double</span> = <span class="number">0.0</span>,</div><div class="line">      numTrees: <span class="attr">Int</span> = <span class="number">5</span>,</div><div class="line">      featureSubsetStrategy: <span class="attr">String</span> = <span class="string">"auto"</span>,</div><div class="line">      fracTest: <span class="attr">Double</span> = <span class="number">0.2</span>,</div><div class="line">      cacheNodeIds: <span class="attr">Boolean</span> = <span class="literal">false</span>,</div><div class="line">      checkpointDir: Option[String] = None,</div><div class="line">      checkpointInterval: <span class="attr">Int</span> = <span class="number">10</span>) extends AbstractParams[Params]</div><div class="line"></div><div class="line">  def main(args: Array[String]) &#123;</div><div class="line">    val <span class="attr">defaultParams</span> = Params()</div><div class="line"></div><div class="line">    val <span class="attr">parser</span> = new OptionParser[Params](<span class="string">"RandomForestExample"</span>) &#123;</div><div class="line">      head(<span class="string">"RandomForestExample: an example random forest app."</span>)</div><div class="line">      opt[String](<span class="string">"algo"</span>)</div><div class="line">        .text(s<span class="string">"algorithm (classification, regression), default: <span class="subst">$&#123;defaultParams.algo&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">algo</span> = x))</div><div class="line">      opt[String](<span class="string">"taskType"</span>)</div><div class="line">        .text(s<span class="string">"modelType, default: <span class="subst">$&#123;defaultParams.taskType&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">taskType</span> = x))</div><div class="line">      opt[Int](<span class="string">"maxDepth"</span>)</div><div class="line">        .text(s<span class="string">"max depth of the tree, default: <span class="subst">$&#123;defaultParams.maxDepth&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">maxDepth</span> = x))</div><div class="line">      opt[Int](<span class="string">"maxBins"</span>)</div><div class="line">        .text(s<span class="string">"max number of bins, default: <span class="subst">$&#123;defaultParams.maxBins&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">maxBins</span> = x))</div><div class="line">      opt[Int](<span class="string">"minInstancesPerNode"</span>)</div><div class="line">        .text(s<span class="string">"min number of instances required at child nodes to create the parent split,"</span> +</div><div class="line">        s<span class="string">" default: <span class="subst">$&#123;defaultParams.minInstancesPerNode&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">minInstancesPerNode</span> = x))</div><div class="line">      opt[Double](<span class="string">"minInfoGain"</span>)</div><div class="line">        .text(s<span class="string">"min info gain required to create a split, default: <span class="subst">$&#123;defaultParams.minInfoGain&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">minInfoGain</span> = x))</div><div class="line">      opt[Int](<span class="string">"numTrees"</span>)</div><div class="line">        .text(s<span class="string">"number of trees in ensemble, default: <span class="subst">$&#123;defaultParams.numTrees&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">numTrees</span> = x))</div><div class="line">      opt[String](<span class="string">"featureSubsetStrategy"</span>)</div><div class="line">        .text(s<span class="string">"number of features to use per node (supported:"</span> +</div><div class="line">        s<span class="string">" <span class="subst">$&#123;RandomForestClassifier.supportedFeatureSubsetStrategies.mkString(<span class="string">","</span>)&#125;</span>),"</span> +</div><div class="line">        s<span class="string">" default: <span class="subst">$&#123;defaultParams.numTrees&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">featureSubsetStrategy</span> = x))</div><div class="line">      opt[Double](<span class="string">"fracTest"</span>)</div><div class="line">        .text(s<span class="string">"fraction of data to hold out for testing. If given option testInput, "</span> +</div><div class="line">        s<span class="string">"this option is ignored. default: <span class="subst">$&#123;defaultParams.fracTest&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">fracTest</span> = x))</div><div class="line">      opt[Boolean](<span class="string">"cacheNodeIds"</span>)</div><div class="line">        .text(s<span class="string">"whether to use node Id cache during training, "</span> +</div><div class="line">        s<span class="string">"default: <span class="subst">$&#123;defaultParams.cacheNodeIds&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">cacheNodeIds</span> = x))</div><div class="line">      opt[String](<span class="string">"checkpointDir"</span>)</div><div class="line">        .text(s<span class="string">"checkpoint directory where intermediate node Id caches will be stored, "</span> +</div><div class="line">        s<span class="string">"default: <span class="subst">$&#123;</span></span></div><div class="line">          defaultParams.checkpointDir match &#123;</div><div class="line">            case Some(strVal) =&gt; strVal</div><div class="line">            case <span class="attr">None</span> =&gt; <span class="string">"None"</span></div><div class="line">          &#125;</div><div class="line">        &#125;")</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">checkpointDir</span> = Some(x)))</div><div class="line">      opt[Int](<span class="string">"checkpointInterval"</span>)</div><div class="line">        .text(s<span class="string">"how often to checkpoint the node Id cache, "</span> +</div><div class="line">        s<span class="string">"default: <span class="subst">$&#123;defaultParams.checkpointInterval&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">checkpointInterval</span> = x))</div><div class="line">      opt[String](<span class="string">"testInput"</span>)</div><div class="line">        .text(s<span class="string">"input path to test dataset. If given, option fracTest is ignored."</span> +</div><div class="line">        s<span class="string">" default: <span class="subst">$&#123;defaultParams.testInput&#125;</span>"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">testInput</span> = x))</div><div class="line">      opt[String](<span class="string">"dataFormat"</span>)</div><div class="line">        .text(<span class="string">"data format: libsvm (default), dense (deprecated in Spark v1.1)"</span>)</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">dataFormat</span> = x))</div><div class="line">      arg[String](<span class="string">"&lt;input&gt;"</span>)</div><div class="line">        .text(<span class="string">"input path to labeled examples"</span>)</div><div class="line">        .required()</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">input</span> = x))</div><div class="line">      arg[String](<span class="string">"&lt;modelDir&gt;"</span>)</div><div class="line">        .text(<span class="string">"modelDir path to labeled examples"</span>)</div><div class="line">        .required()</div><div class="line">        .action((x, c) =&gt; c.copy(<span class="attr">modelDir</span> = x))</div><div class="line">      checkConfig &#123; <span class="attr">params</span> =&gt;</div><div class="line">        <span class="keyword">if</span> (params.fracTest &lt; <span class="number">0</span> || params.fracTest &gt;= <span class="number">1</span>) &#123;</div><div class="line">          failure(s<span class="string">"fracTest <span class="subst">$&#123;params.fracTest&#125;</span> value incorrect; should be in [0,1)."</span>)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          success</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    parser.parse(args, defaultParams) match &#123;</div><div class="line">      case Some(params) =&gt; &#123;</div><div class="line">        <span class="keyword">if</span>(params.taskType.equalsIgnoreCase(<span class="string">"train"</span>))&#123;</div><div class="line">          train(params)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      case <span class="attr">_</span> =&gt; sys.exit(<span class="number">1</span>)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  def train(params: Params): <span class="attr">Unit</span> = &#123;</div><div class="line">    val <span class="attr">spark</span> = SparkSession</div><div class="line">      .builder</div><div class="line">        .master(<span class="string">"local"</span>)</div><div class="line">      .appName(s<span class="string">"RandomForestExample with $params"</span>)</div><div class="line">      .getOrCreate()</div><div class="line"></div><div class="line">    params.checkpointDir.foreach(spark.sparkContext.setCheckpointDir)</div><div class="line">    val <span class="attr">algo</span> = params.algo.toLowerCase</div><div class="line"></div><div class="line">    println(s<span class="string">"RandomForestExample with parameters:\n$params"</span>)</div><div class="line"></div><div class="line">    // Load training <span class="literal">and</span> test data <span class="literal">and</span> cache it.</div><div class="line">    val (training: DataFrame, test: DataFrame) = AlgoUtils.loadMaliceDataFrame(spark.sparkContext, params.input, params.fracTest)</div><div class="line"></div><div class="line">    // Set up Pipeline.</div><div class="line">    val <span class="attr">stages</span> = new mutable.ArrayBuffer[PipelineStage]()</div><div class="line">    // (<span class="number">1</span>) For classification, re-index classes.</div><div class="line">    val <span class="attr">labelColName</span> = <span class="keyword">if</span> (<span class="attr">algo</span> == <span class="string">"classification"</span>) <span class="string">"indexedLabel"</span> <span class="keyword">else</span> <span class="string">"label"</span></div><div class="line">    <span class="keyword">if</span> (<span class="attr">algo</span> == <span class="string">"classification"</span>) &#123;</div><div class="line">      val <span class="attr">labelIndexer</span> = new StringIndexer()</div><div class="line">        .setInputCol(<span class="string">"label"</span>)</div><div class="line">        .setOutputCol(labelColName)</div><div class="line">      stages += labelIndexer</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    val <span class="attr">vectorAssember</span> = new VectorAssembler()</div><div class="line">    vectorAssember.setInputCols(Array(<span class="string">"degree"</span>,<span class="string">"tcNum"</span>,<span class="string">"pageRank"</span>,<span class="string">"commVertexNum"</span>,<span class="string">"normQ"</span>,<span class="string">"gtRate"</span>,<span class="string">"eqRate"</span>,<span class="string">"ltRate"</span>))</div><div class="line">    vectorAssember.setOutputCol(<span class="string">"features"</span>)</div><div class="line"></div><div class="line">    stages += vectorAssember</div><div class="line">    // (<span class="number">2</span>) Identify categorical features using VectorIndexer.</div><div class="line">    //     Features <span class="keyword">with</span> more than maxCategories values will be treated as continuous.</div><div class="line">    val <span class="attr">featuresIndexer</span> = new VectorIndexer()</div><div class="line">      .setInputCol(<span class="string">"features"</span>)</div><div class="line">      .setOutputCol(<span class="string">"indexedFeatures"</span>)</div><div class="line">      .setMaxCategories(<span class="number">10</span>)</div><div class="line">    stages += featuresIndexer</div><div class="line">    // (<span class="number">3</span>) Learn Random Forest.</div><div class="line">    val <span class="attr">dt</span> = algo match &#123;</div><div class="line">      case <span class="string">"classification"</span> =&gt;</div><div class="line">        new RandomForestClassifier()</div><div class="line">          .setFeaturesCol(<span class="string">"features"</span>)</div><div class="line">          .setLabelCol(labelColName)</div><div class="line">          .setMaxDepth(params.maxDepth)</div><div class="line">          .setMaxBins(params.maxBins)</div><div class="line">          .setMinInstancesPerNode(params.minInstancesPerNode)</div><div class="line">          .setMinInfoGain(params.minInfoGain)</div><div class="line">          .setCacheNodeIds(params.cacheNodeIds)</div><div class="line">          .setCheckpointInterval(params.checkpointInterval)</div><div class="line">          .setFeatureSubsetStrategy(params.featureSubsetStrategy)</div><div class="line">          .setNumTrees(params.numTrees)</div><div class="line">      case <span class="string">"regression"</span> =&gt;</div><div class="line">        new RandomForestRegressor()</div><div class="line">          .setFeaturesCol(<span class="string">"features"</span>)</div><div class="line">          .setLabelCol(labelColName)</div><div class="line">          .setMaxDepth(params.maxDepth)</div><div class="line">          .setMaxBins(params.maxBins)</div><div class="line">          .setMinInstancesPerNode(params.minInstancesPerNode)</div><div class="line">          .setMinInfoGain(params.minInfoGain)</div><div class="line">          .setCacheNodeIds(params.cacheNodeIds)</div><div class="line">          .setCheckpointInterval(params.checkpointInterval)</div><div class="line">          .setFeatureSubsetStrategy(params.featureSubsetStrategy)</div><div class="line">          .setNumTrees(params.numTrees)</div><div class="line">      case <span class="attr">_</span> =&gt; <span class="built_in">throw</span> new IllegalArgumentException(<span class="string">"Algo <span class="subst">$&#123;params.algo&#125;</span> not supported."</span>)</div><div class="line">    &#125;</div><div class="line">    stages += dt</div><div class="line">    val <span class="attr">pipeline</span> = new Pipeline().setStages(stages.toArray)</div><div class="line"></div><div class="line">    // Fit the Pipeline.</div><div class="line">    val <span class="attr">startTime</span> = System.nanoTime()</div><div class="line">    val <span class="attr">pipelineModel</span> = pipeline.fit(training)</div><div class="line">    val <span class="attr">elapsedTime</span> = (System.nanoTime() - startTime) / <span class="number">1</span>e9</div><div class="line">    println(s<span class="string">"Training time: $elapsedTime seconds"</span>)</div><div class="line"></div><div class="line">    val <span class="attr">rfModel</span> = pipelineModel.stages.last.asInstanceOf[RandomForestClassificationModel]</div><div class="line">    <span class="comment">/**</span></div><div class="line">      * write model pmml format to hdfs</div><div class="line">      */</div><div class="line">    val <span class="attr">modelPmmlPath</span> = params.modelDir</div><div class="line">    val <span class="attr">pmml</span> = ConverterUtil.toPMML(training.schema, pipelineModel);</div><div class="line">    val <span class="attr">conf</span> = new Configuration();</div><div class="line">    HadoopFileUtil.deleteFile(modelPmmlPath)</div><div class="line">    val <span class="attr">path</span> = new Path(modelPmmlPath);</div><div class="line">    val <span class="attr">fs</span> = path.getFileSystem(conf);</div><div class="line">    val <span class="attr">out</span> = fs.create(path);</div><div class="line">    MetroJAXBUtil.marshalPMML(pmml, out);</div><div class="line">    MetroJAXBUtil.marshalPMML(pmml, new FileOutputStream(modelPmmlPath));</div><div class="line">    JAXBUtil.marshalPMML(pmml, new StreamResult(System.out));</div><div class="line"></div><div class="line"></div><div class="line">    val <span class="attr">predictions</span> = pipelineModel.transform(training)</div><div class="line"></div><div class="line">    // Get the trained Random Forest from the fitted PipelineModel.</div><div class="line">    algo match &#123;</div><div class="line">      case <span class="string">"classification"</span> =&gt;</div><div class="line">        <span class="keyword">if</span> (rfModel.totalNumNodes &lt; <span class="number">30</span>) &#123;</div><div class="line">          println(rfModel.toDebugString) // Print full model.</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          println(rfModel) // Print model summary.</div><div class="line">        &#125;</div><div class="line">      case <span class="string">"regression"</span> =&gt;</div><div class="line">        val <span class="attr">rfrModel</span> = pipelineModel.stages.last.asInstanceOf[RandomForestRegressionModel]</div><div class="line">        <span class="keyword">if</span> (rfrModel.totalNumNodes &lt; <span class="number">30</span>) &#123;</div><div class="line">          println(rfrModel.toDebugString) // Print full model.</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          println(rfrModel) // Print model summary.</div><div class="line">        &#125;</div><div class="line">      case <span class="attr">_</span> =&gt; <span class="built_in">throw</span> new IllegalArgumentException(<span class="string">"Algo <span class="subst">$&#123;params.algo&#125;</span> not supported."</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    // Evaluate model on training, test data.</div><div class="line">    algo match &#123;</div><div class="line">      case <span class="string">"classification"</span> =&gt;</div><div class="line">        println(<span class="string">"Training data results:"</span>)</div><div class="line">        DecisionTreeExample.evaluateClassificationModel(pipelineModel, training, labelColName)</div><div class="line">        val <span class="attr">evaluator</span> = new MulticlassClassificationEvaluator()</div><div class="line">          .setLabelCol(<span class="string">"indexedLabel"</span>)</div><div class="line">          .setPredictionCol(<span class="string">"prediction"</span>)</div><div class="line">          .setMetricName(<span class="string">"accuracy"</span>)</div><div class="line">        val <span class="attr">accuracy</span> = evaluator.evaluate(predictions)</div><div class="line">        println(<span class="string">"Test Error = "</span> + (<span class="number">1.0</span> - accuracy))</div><div class="line">      case <span class="string">"regression"</span> =&gt;</div><div class="line">        println(<span class="string">"Training data results:"</span>)</div><div class="line">        DecisionTreeExample.evaluateRegressionModel(pipelineModel, training, labelColName)</div><div class="line">      case <span class="attr">_</span> =&gt;</div><div class="line">        <span class="built_in">throw</span> new IllegalArgumentException(<span class="string">"Algo <span class="subst">$&#123;params.algo&#125;</span> not supported."</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    predictions.printSchema()</div><div class="line">    predictions.select(<span class="string">"label"</span>,<span class="string">"prediction"</span>,<span class="string">"probability"</span>).show(<span class="number">10</span>)</div><div class="line"></div><div class="line">    spark.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="jpmml-evaluator实现在线实时预测："><a href="#jpmml-evaluator实现在线实时预测：" class="headerlink" title="jpmml-evaluator实现在线实时预测："></a>jpmml-evaluator实现在线实时预测：</h3><figure class="highlight processing"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by cdmeishangjian on 2017/1/19.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> class PrdictScore &#123;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(<span class="keyword">String</span>[] args) <span class="keyword">throws</span> Exception &#123;</div><div class="line">        PMML pmml = readPMML(<span class="keyword">new</span> File(<span class="string">"data/pmmlmodel/rf.pmml"</span>));</div><div class="line">        ModelEvaluatorFactory modelEvaluatorFactory = ModelEvaluatorFactory.newInstance();</div><div class="line"><span class="comment">//        System.out.println(pmml.getModels().get(0));</span></div><div class="line">        Evaluator evaluator = modelEvaluatorFactory.newModelEvaluator(pmml);</div><div class="line"><span class="comment">//        ModelEvaluator evaluator = new MiningModelEvaluator(pmml);</span></div><div class="line">        evaluator.verify();</div><div class="line">        List&lt;InputField&gt; inputFields = evaluator.getInputFields();</div><div class="line"></div><div class="line">        InputStream is = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"data/train.txt"</span>));</div><div class="line">        <span class="keyword">BufferedReader</span> br = <span class="keyword">new</span> <span class="keyword">BufferedReader</span>(<span class="keyword">new</span> InputStreamReader(is));</div><div class="line">        <span class="keyword">String</span> <span class="built_in">line</span>;</div><div class="line"></div><div class="line">        <span class="built_in">int</span> diffDelta = <span class="number">0</span>;</div><div class="line">        <span class="built_in">int</span> sameDelta = <span class="number">0</span>;</div><div class="line">        <span class="keyword">while</span>((<span class="built_in">line</span> = br.readLine()) != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="keyword">String</span>[] splits = <span class="built_in">line</span>.<span class="built_in">split</span>(<span class="string">"\t"</span>,<span class="number">-1</span>);</div><div class="line"></div><div class="line">            <span class="keyword">double</span> targetMs = transToDouble(splits[<span class="number">14</span>]);</div><div class="line">            <span class="keyword">double</span> risk_value = transToDouble(splits[<span class="number">2</span>]);</div><div class="line"></div><div class="line">            <span class="keyword">double</span> label = <span class="number">0.0</span>;</div><div class="line">            <span class="keyword">if</span>(targetMs==<span class="number">1.0</span> &amp;&amp; risk_value &gt;<span class="number">5.0</span>d)&#123;</div><div class="line">                label = <span class="number">1.0</span>;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            LinkedHashMap&lt;FieldName, FieldValue&gt; arguments = readArgumentsFromLine(splits, inputFields);</div><div class="line"></div><div class="line">            Map&lt;FieldName, ?&gt; results = evaluator.evaluate(arguments);</div><div class="line">            List&lt;TargetField&gt; targetFields = evaluator.getTargetFields();</div><div class="line">            <span class="keyword">for</span>(TargetField targetField : targetFields)&#123;</div><div class="line">                FieldName targetFieldName = targetField.getName();</div><div class="line">                <span class="keyword">Object</span> targetFieldValue = results.<span class="built_in">get</span>(targetFieldName);</div><div class="line"></div><div class="line">                ProbabilityDistribution nodeMap = (ProbabilityDistribution)targetFieldValue;</div><div class="line">                <span class="keyword">Object</span> result = nodeMap.getResult();</div><div class="line">                <span class="keyword">if</span>(label == Double.valueOf(result.toString()))&#123;</div><div class="line">                    sameDelta +=<span class="number">1</span>;</div><div class="line">                &#125;<span class="keyword">else</span>&#123;</div><div class="line">                    diffDelta +=<span class="number">1</span>;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        System.out.<span class="built_in">println</span>(<span class="string">"acc count:"</span>+sameDelta);</div><div class="line">        System.out.<span class="built_in">println</span>(<span class="string">"error count:"</span>+diffDelta);</div><div class="line">        System.out.<span class="built_in">println</span>(<span class="string">"acc rate:"</span>+(sameDelta*<span class="number">1.0</span>d/(sameDelta+diffDelta)));</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 从文件中读取pmml模型文件</div><div class="line">     * @param file</div><div class="line">     * @return</div><div class="line">     * @throws Exception</div><div class="line">     */</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> PMML readPMML(File file) <span class="keyword">throws</span> Exception &#123;</div><div class="line"></div><div class="line">        InputStream is = <span class="keyword">new</span> FileInputStream(file);</div><div class="line">        <span class="keyword">return</span> PMMLUtil.unmarshal(is);</div><div class="line"></div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 构造模型输入特征字段</div><div class="line">     * @param splits</div><div class="line">     * @param inputFields</div><div class="line">     * @return</div><div class="line">     */</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> LinkedHashMap&lt;FieldName, FieldValue&gt; readArgumentsFromLine(<span class="keyword">String</span>[] splits, List&lt;InputField&gt; inputFields) &#123;</div><div class="line"></div><div class="line">        List&lt;Double&gt; lists = <span class="keyword">new</span> ArrayList&lt;Double&gt;();</div><div class="line">        lists.<span class="built_in">add</span>(Double.valueOf(splits[<span class="number">3</span>]));</div><div class="line">        lists.<span class="built_in">add</span>(Double.valueOf(splits[<span class="number">4</span>]));</div><div class="line">        lists.<span class="built_in">add</span>(Double.valueOf(splits[<span class="number">5</span>]));</div><div class="line">        lists.<span class="built_in">add</span>(Double.valueOf(splits[<span class="number">7</span>]));</div><div class="line">        lists.<span class="built_in">add</span>(Double.valueOf(splits[<span class="number">8</span>]));</div><div class="line">        lists.<span class="built_in">add</span>(Double.valueOf(splits[<span class="number">9</span>]));</div><div class="line">        lists.<span class="built_in">add</span>(Double.valueOf(splits[<span class="number">10</span>]));</div><div class="line">        lists.<span class="built_in">add</span>(Double.valueOf(splits[<span class="number">11</span>]));</div><div class="line"></div><div class="line">        LinkedHashMap&lt;FieldName, FieldValue&gt; arguments = <span class="keyword">new</span> LinkedHashMap&lt;FieldName, FieldValue&gt;();</div><div class="line"></div><div class="line">        <span class="built_in">int</span> i = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span>(InputField inputField : inputFields)&#123;</div><div class="line">            FieldName inputFieldName = inputField.getName();</div><div class="line">            <span class="comment">// The raw (ie. user-supplied) value could be any Java primitive value</span></div><div class="line">            <span class="keyword">Object</span> rawValue = lists.<span class="built_in">get</span>(i);</div><div class="line">            <span class="comment">// The raw value is passed through: 1) outlier treatment, 2) missing value treatment, 3) invalid value treatment and 4) type conversion</span></div><div class="line">            FieldValue inputFieldValue = inputField.prepare(rawValue);</div><div class="line"></div><div class="line">            arguments.put(inputFieldName, inputFieldValue);</div><div class="line">            i+=<span class="number">1</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">return</span> arguments;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Double transToDouble(<span class="keyword">String</span> label) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">return</span> Double.valueOf(label);</div><div class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</div><div class="line">            <span class="keyword">return</span> Double.valueOf(<span class="number">0</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近公司有需求需要将离线训练好的算法模型应用到线上去实时预测，在线预测不考虑feature加工的情况下，经调研，发现jpmml-sparkml+jpmml-evaluator的方式可以满足条件。不过使用时需要注意该框架是AGPL-3.0协议。 &lt;/p&gt;
&lt;h2 id=&quot;方案
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>cuda/tensorflow/keras安装笔记</title>
    <link href="http://yoursite.com/2017/01/05/cuda-install/"/>
    <id>http://yoursite.com/2017/01/05/cuda-install/</id>
    <published>2017-01-05T14:00:00.000Z</published>
    <updated>2017-06-19T07:31:49.467Z</updated>
    
    <content type="html"><![CDATA[<ol>
<li><p>sudo yum install kernel-devel-$(uname -r)、kernel-headers-$(uname -r) 手动下载，rpm -ivh安装 </p>
</li>
<li><p>禁用nouveau driver，创建 <code>/etc/modprobe.d/blacklist-nouveau.conf</code>: </p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">blacklist nouveau</div><div class="line">options nouveau <span class="attribute">modeset</span>=0</div></pre></td></tr></table></figure>
</li>
<li><p>Regenerate the kernel initramfs and 重启机器: <code>sudo dracut --force</code> </p>
</li>
<li><p><code>sh cuda_8.0.44_linux.run</code>(全部默认选项) &amp; <code>chmod 755 -R /usr/local/cuda-8.0</code></p>
</li>
<li><p>cudnn安装： </p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">tar</span> <span class="selector-tag">-xzvf</span> <span class="selector-tag">cudnn-8</span><span class="selector-class">.0-linux-x64-v5</span><span class="selector-class">.1</span><span class="selector-class">.tgz</span></div><div class="line"><span class="selector-tag">cd</span> <span class="selector-tag">cudnn-8</span><span class="selector-class">.0-linux-x64-v5</span><span class="selector-class">.1</span></div><div class="line"><span class="selector-tag">sudo</span> <span class="selector-tag">cp</span> <span class="selector-tag">lib64</span><span class="comment">/* /usr/local/cuda/lib64/</span></div><div class="line">sudo cp include/* /usr/local/cuda/include/</div><div class="line"></div><div class="line">复制后软链接会失效，需要重新建立软链接：</div><div class="line">ln -s libcudnn.so.6.0.21 libcudnn.so.6</div><div class="line">ln -s libcudnn.so.6 libcudnn.so</div></pre></td></tr></table></figure>
</li>
<li><p>设置环境变量:  </p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="builtin-name">export</span> <span class="attribute">LD_LIBRARY_PATH</span>=<span class="variable">$LD_LIBRARY_PATH</span>:/usr/local/cuda-8.0/lib64</div><div class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="string">"/usr/local/cuda-8.0/bin:<span class="variable">$PATH</span>"</span></div></pre></td></tr></table></figure>
</li>
<li><p><code>pip install tensorflow/theano/keras</code>(若无法下载包，手动下载再安装) </p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install --upgrade https:<span class="regexp">//</span>storage.googleapis.com<span class="regexp">/tensorflow/</span>linux<span class="regexp">/gpu/</span>tensorflow_gpu-<span class="number">1.2</span>.<span class="number">0</span>-cp35-cp35m-manylinux1_x86_64.whl</div></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;&lt;p&gt;sudo yum install kernel-devel-$(uname -r)、kernel-headers-$(uname -r) 手动下载，rpm -ivh安装 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;禁用nouveau driver，创建 &lt;code
    
    </summary>
    
      <category term="Notes" scheme="http://yoursite.com/categories/Notes/"/>
    
    
      <category term="cuda" scheme="http://yoursite.com/tags/cuda/"/>
    
      <category term="tensorflow" scheme="http://yoursite.com/tags/tensorflow/"/>
    
      <category term="keras" scheme="http://yoursite.com/tags/keras/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客迁移笔记</title>
    <link href="http://yoursite.com/2016/12/20/hexo-transfer/"/>
    <id>http://yoursite.com/2016/12/20/hexo-transfer/</id>
    <published>2016-12-20T14:00:00.000Z</published>
    <updated>2017-08-17T02:52:32.501Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hexo博客迁移笔记"><a href="#Hexo博客迁移笔记" class="headerlink" title="Hexo博客迁移笔记"></a>Hexo博客迁移笔记</h2><p>发现pelican搭建的github博客，访问特别慢，而且模板样式不是很好看;网上调研了下，觉得hexo的模板特别简洁，访问速度也还可以，于是将原来基于pelican的博客引擎倒腾到hexo上来。</p>
<h3 id="step-1-hexo-install"><a href="#step-1-hexo-install" class="headerlink" title="step 1: hexo install"></a>step 1: hexo install</h3><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">npm</span> install -g cnpm --registry=https:<span class="regexp">//</span>registry.<span class="built_in">npm</span>.taobao.org</div><div class="line"><span class="built_in">npm</span> install hexo-cli -g</div></pre></td></tr></table></figure>
<h3 id="step2-hexo-init"><a href="#step2-hexo-init" class="headerlink" title="step2: hexo init"></a>step2: hexo init</h3><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">hexo init hexo-blog  <span class="comment">#执行init命令初始化到你指定的hexo目录</span></div><div class="line">cd hexo-blog</div><div class="line">npm install    <span class="comment">#install before start blogging</span></div><div class="line">hexo generate       <span class="comment">#自动根据当前目录下文件,生成静态网页</span></div><div class="line">hexo server         <span class="comment">#运行本地服务</span></div><div class="line"></div><div class="line">QA:</div><div class="line"><span class="number">1.</span> localhost:<span class="number">4000</span>无法访问</div><div class="line">你的电脑端口被占用了。hexo默认的端口是<span class="number">4000</span>，如果你的电脑安装了福昕阅读器，就是他，没错，坑爹吧！！！！</div><div class="line">启动hexo s 的时候，用这个命令，换一个端口。`hexo s -p <span class="number">5000</span>`</div><div class="line"></div><div class="line"><span class="number">2.</span> FATAL can <span class="keyword">not</span> <span class="built_in">read</span> <span class="keyword">a</span> block mapping entry; <span class="keyword">a</span> multiline key may <span class="keyword">not</span> be <span class="keyword">an</span> implicit key <span class="keyword">at</span> <span class="built_in">line</span> <span class="number">13</span>, column <span class="number">1</span>:</div><div class="line">检查<span class="title">_config</span>.yml内容，特别注意`:`后面需要有一个空格</div></pre></td></tr></table></figure>
<figure class="highlight golo"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div></pre></td><td class="code"><pre><div class="line">&lt;li&gt; &lt;a title=<span class="string">"把这个链接拖到你的Chrome收藏夹工具栏中"</span> href='javascript:(<span class="keyword">function</span>() &#123;</div><div class="line">    <span class="keyword">function</span> c() &#123;</div><div class="line">        <span class="keyword">var</span> e = document.createElement(<span class="string">"link"</span>);</div><div class="line">        e.setAttribute(<span class="string">"type"</span>, <span class="string">"text/css"</span>);</div><div class="line">        e.setAttribute(<span class="string">"rel"</span>, <span class="string">"stylesheet"</span>);</div><div class="line">        e.setAttribute(<span class="string">"href"</span>, f);</div><div class="line">        e.setAttribute(<span class="string">"class"</span>, l);</div><div class="line">        document.body.appendChild(e)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> h() &#123;</div><div class="line">        <span class="keyword">var</span> e = document.getElementsByClassName(l);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> t = <span class="number">0</span>; t &lt; e.length; t++) &#123;</div><div class="line">            document.body.removeChild(e[t])</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> p() &#123;</div><div class="line">        <span class="keyword">var</span> e = document.createElement(<span class="string">"div"</span>);</div><div class="line">        e.setAttribute(<span class="string">"class"</span>, a);</div><div class="line">        document.body.appendChild(e);</div><div class="line">        setTimeout(<span class="keyword">function</span>() &#123;</div><div class="line">            document.body.removeChild(e)</div><div class="line">        &#125;, <span class="number">100</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> d(e) &#123;</div><div class="line">        <span class="keyword">return</span> &#123;</div><div class="line">            height : e.offsetHeight,</div><div class="line">            width : e.offsetWidth</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> v(i) &#123;</div><div class="line">        <span class="keyword">var</span> s = d(i);</div><div class="line">        <span class="keyword">return</span> s.height &gt; e &amp;&amp; s.height &lt; n &amp;&amp; s.width &gt; t &amp;&amp; s.width &lt; r</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> m(e) &#123;</div><div class="line">        <span class="keyword">var</span> t = e;</div><div class="line">        <span class="keyword">var</span> n = <span class="number">0</span>;</div><div class="line">        <span class="keyword">while</span> (!!t) &#123;</div><div class="line">            n += t.offsetTop;</div><div class="line">            t = t.offsetParent</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> n</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> g() &#123;</div><div class="line">        <span class="keyword">var</span> e = document.documentElement;</div><div class="line">        <span class="keyword">if</span> (!!window.innerWidth) &#123;</div><div class="line">            <span class="keyword">return</span> window.innerHeight</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (e &amp;&amp; !isNaN(e.clientHeight)) &#123;</div><div class="line">            <span class="keyword">return</span> e.clientHeight</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> y() &#123;</div><div class="line">        <span class="keyword">if</span> (window.pageYOffset) &#123;</div><div class="line">            <span class="keyword">return</span> window.pageYOffset</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> Math.max(document.documentElement.scrollTop, document.body.scrollTop)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> E(e) &#123;</div><div class="line">        <span class="keyword">var</span> t = m(e);</div><div class="line">        <span class="keyword">return</span> t &gt;= w &amp;&amp; t &lt;= b + w</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> S() &#123;</div><div class="line">        <span class="keyword">var</span> e = document.createElement(<span class="string">"audio"</span>);</div><div class="line">        e.setAttribute(<span class="string">"class"</span>, l);</div><div class="line">        e.src = i;</div><div class="line">        e.loop = <span class="literal">false</span>;</div><div class="line">        e.addEventListener(<span class="string">"canplay"</span>, <span class="keyword">function</span>() &#123;</div><div class="line">            setTimeout(<span class="keyword">function</span>() &#123;</div><div class="line">                x(k)</div><div class="line">            &#125;, <span class="number">500</span>);</div><div class="line">            setTimeout(<span class="keyword">function</span>() &#123;</div><div class="line">                N();</div><div class="line">                p();</div><div class="line">                <span class="keyword">for</span> (<span class="keyword">var</span> e = <span class="number">0</span>; e &lt; O.length; e++) &#123;</div><div class="line">                    T(O[e])</div><div class="line">                &#125;</div><div class="line">            &#125;, <span class="number">15500</span>)</div><div class="line">        &#125;, <span class="literal">true</span>);</div><div class="line">        e.addEventListener(<span class="string">"ended"</span>, <span class="keyword">function</span>() &#123;</div><div class="line">            N();</div><div class="line">            h()</div><div class="line">        &#125;, <span class="literal">true</span>);</div><div class="line">        e.innerHTML = <span class="string">" &lt;p&gt;If you are reading this, it is because your browser does not support the audio element. We recommend that you get a new browser.&lt;/p&gt; &lt;p&gt;"</span>;</div><div class="line">        document.body.appendChild(e);</div><div class="line">        e.play()</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> x(e) &#123;</div><div class="line">        e.className += <span class="string">" "</span> + s + <span class="string">" "</span> + o</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> T(e) &#123;</div><div class="line">        e.className += <span class="string">" "</span> + s + <span class="string">" "</span> + u[Math.floor(Math.random() * u.length)]</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">function</span> N() &#123;</div><div class="line">        <span class="keyword">var</span> e = document.getElementsByClassName(s);</div><div class="line">        <span class="keyword">var</span> t = new RegExp(<span class="string">"\\b"</span> + s + <span class="string">"\\b"</span>);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> n = <span class="number">0</span>; n &lt; e.length; ) &#123;</div><div class="line">            e[n].className = e[n].className.replace(t, <span class="string">""</span>)</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">var</span> e = <span class="number">30</span>;</div><div class="line">    <span class="keyword">var</span> t = <span class="number">30</span>;</div><div class="line">    <span class="keyword">var</span> n = <span class="number">350</span>;</div><div class="line">    <span class="keyword">var</span> r = <span class="number">350</span>;</div><div class="line">    <span class="keyword">var</span> i = <span class="string">"//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake.mp3"</span>;</div><div class="line">    <span class="keyword">var</span> s = <span class="string">"mw-harlem_shake_me"</span>;</div><div class="line">    <span class="keyword">var</span> o = <span class="string">"im_first"</span>;</div><div class="line">    <span class="keyword">var</span> u = [<span class="string">"im_drunk"</span>, <span class="string">"im_baked"</span>, <span class="string">"im_trippin"</span>, <span class="string">"im_blown"</span>];</div><div class="line">    <span class="keyword">var</span> a = <span class="string">"mw-strobe_light"</span>;</div><div class="line">    <span class="keyword">var</span> f = <span class="string">"//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake-style.css"</span>;</div><div class="line">    <span class="keyword">var</span> l = <span class="string">"mw_added_css"</span>;</div><div class="line">    <span class="keyword">var</span> b = g();</div><div class="line">    <span class="keyword">var</span> w = y();</div><div class="line">    <span class="keyword">var</span> C = document.getElementsByTagName(<span class="string">"*"</span>);</div><div class="line">    <span class="keyword">var</span> k = <span class="literal">null</span>;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> L = <span class="number">0</span>; L &lt; C.length; L++) &#123;</div><div class="line">        <span class="keyword">var</span> A = C[L];</div><div class="line">        <span class="keyword">if</span> (v(A)) &#123;</div><div class="line">            <span class="keyword">if</span> (E(A)) &#123;</div><div class="line">                k = A;</div><div class="line">                <span class="keyword">break</span></div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (A === <span class="literal">null</span>) &#123;</div><div class="line">        console.warn(<span class="string">"Could not find a node of the right size. Please try a different page."</span>);</div><div class="line">        <span class="keyword">return</span></div><div class="line">    &#125;</div><div class="line">    c();</div><div class="line">    S();</div><div class="line">    <span class="keyword">var</span> O = [];</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> L = <span class="number">0</span>; L &lt; C.length; L++) &#123;</div><div class="line">        <span class="keyword">var</span> A = C[L];</div><div class="line">        <span class="keyword">if</span> (v(A)) &#123;</div><div class="line">            O.push(A)</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;)()    '&gt;High一下&lt;/a&gt; &lt;/li&gt;</div></pre></td></tr></table></figure>
<h3 id="step3-blog-config"><a href="#step3-blog-config" class="headerlink" title="step3:blog config"></a>step3:blog config</h3><figure class="highlight applescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="number">1.</span> 修改<span class="keyword">or</span>添加菜单项名：修改对应的翻译文件 languages/***.yml，在 menu 字段下添加一项 </div><div class="line"><span class="number">2.</span> 设定菜单项图标，对应的字段是menu_icons，此设定格式是 <span class="built_in">item</span> <span class="built_in">name</span>: icon <span class="built_in">name</span>(参考：Font Awesome 图标名字) </div><div class="line"><span class="number">3.</span> auto_excerpt:</div><div class="line">enable: <span class="literal">true</span></div><div class="line"><span class="built_in">length</span>: <span class="number">150</span></div></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h2><ol>
<li><a href="http://www.jianshu.com/p/b7886271e21a" target="_blank" rel="external">Hexo安装和配置</a> </li>
<li><a href="http://theme-next.iissnan.com/getting-started.html#menu-settings" target="_blank" rel="external">NexT使用文档</a> </li>
<li><a href="http://www.bootcss.com/p/font-awesome/" target="_blank" rel="external">Font Awesome</a> </li>
<li><a href="https://github.com/iissnan/hexo-theme-next/wiki/" target="_blank" rel="external">next-wiki</a></li>
<li><a href="http://fontawesome.io/cheatsheet/" target="_blank" rel="external">fontawesome-cheatsheet</a></li>
<li><a href="http://www.jianshu.com/p/f869d1940985" target="_blank" rel="external">设置博客播放音乐</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Hexo博客迁移笔记&quot;&gt;&lt;a href=&quot;#Hexo博客迁移笔记&quot; class=&quot;headerlink&quot; title=&quot;Hexo博客迁移笔记&quot;&gt;&lt;/a&gt;Hexo博客迁移笔记&lt;/h2&gt;&lt;p&gt;发现pelican搭建的github博客，访问特别慢，而且模板样式不是很好看
    
    </summary>
    
      <category term="Notes" scheme="http://yoursite.com/categories/Notes/"/>
    
    
      <category term="markdown" scheme="http://yoursite.com/tags/markdown/"/>
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>OrientDB API学习笔记</title>
    <link href="http://yoursite.com/2016/11/04/orientdb-learning-notes/"/>
    <id>http://yoursite.com/2016/11/04/orientdb-learning-notes/</id>
    <published>2016-11-04T14:20:00.000Z</published>
    <updated>2017-06-18T06:53:03.948Z</updated>
    
    <content type="html"><![CDATA[<p>OrientDB’s APIs: Document, Object, and Graph</p>
<p>Records (or documents/vertices)<br>attributes(or “fields” and “properties”)</p>
<p>In OrientDB each record has its own self-assigned unique ID within the database called Record ID or RID. It is composed of two parts:<br><code>#&lt;cluster-id&gt;:&lt;cluster-position&gt;</code><br>cluster-id： is the id of the cluster. Each database can have a maximum of 32,767 clusters (2^15-1)<br>cluster-position： is the position of the record inside the cluster. Each cluster can handle up to 9,223,372,036,854,780,000 (2^63) records, namely 9,223,372 Trillion of records!</p>
<p>A RID (Record ID) is the physical position of the record inside the database.</p>
<p> OrientDB has the concept of records as an element of storage. There are different types of records, document is one type of records.</p>
<p> A document is composed of attributes(or “fields” and “properties”) and can belong to one class. </p>
<p> Classes are also used in OrientDB as a type of data model according to certain rules.</p>
<p> A cluster is a place where a group of records are stored. Perhaps the best equivalent in the relational world would be a Table. </p>
<p> By default, OrientDB will create one cluster per class. All the records of a class are stored in the same cluster which has the same name as the class. You can create up to 32,767 (2^15-1) clusters in a database.</p>
<p> The benefits of using different physical places to store records are:</p>
<p>faster queries against clusters because only a sub-set of all the class’s clusters must be searched<br>good partitioning allows you to reduce/remove the use of indexes<br>parallel queries if on multiple disks<br>sharding large data sets across multiple disks or server instances<br>There are two types of clusters:<br>Physical Cluster (known as local) which is persistent because it writes directly to the file system<br>Memory Cluster where everything is volatile and will be lost on termination of the process or server if the database is remote</p>
<p>The most important feature of a graph database is the management of relationships</p>
<p>With OrientDB, speed of traversal is not affected by the database size.It is always constant regardless if it has one record or 100 billion records. This is critical in the age of Big Data.</p>
<p>OrientDB comes with a generic Vertex persistent class called “V” (OGraphVertex in previous releases) and “E” (OGraphEdge in the past) for Edge. </p>
<p>lightweight edges: they don’t have own identities as record, but are physically stored as links inside vertices. OrientDB automatically uses Lightweight edges only when edges have no properties, otherwise regular edges are used.<br>This is to improve performance and reduce the space on disk. But as a consequence, since lightweight edges don’t exist as separate records in the database</p>
<p>Class –&gt;table(classes can be schema-full, schema-less, or mixed.)<br>Property –&gt; column<br>Record –&gt; row<br>Cluster(store the data of a class in different physical locations)</p>
<p> Console命令</p>
<p> 连接数据库：<code>connect remote:172.19.163.83/jrdm orientdb orientdb</code></p>
<p><a href="http://orientdb.com/docs/2.0/orientdb.wiki/Tutorial-Relationships.html" target="_blank" rel="external">http://orientdb.com/docs/2.0/orientdb.wiki/Tutorial-Relationships.html</a><br><a href="http://orientdb.com/spark-orientdb/" target="_blank" rel="external">http://orientdb.com/spark-orientdb/</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;OrientDB’s APIs: Document, Object, and Graph&lt;/p&gt;
&lt;p&gt;Records (or documents/vertices)&lt;br&gt;attributes(or “fields” and “properties”)&lt;/p&gt;
&lt;p&gt;In
    
    </summary>
    
      <category term="Notes" scheme="http://yoursite.com/categories/Notes/"/>
    
    
      <category term="orientdb" scheme="http://yoursite.com/tags/orientdb/"/>
    
  </entry>
  
  <entry>
    <title>OrientDB分布式安装文档</title>
    <link href="http://yoursite.com/2016/11/02/orientdb-distribute-install/"/>
    <id>http://yoursite.com/2016/11/02/orientdb-distribute-install/</id>
    <published>2016-11-02T02:00:00.000Z</published>
    <updated>2017-06-18T06:44:40.362Z</updated>
    
    <content type="html"><![CDATA[<h3 id="step-1-在虚拟机centos上新建用户jdorientdb-下载orientdb包解压到-software-orientdb目录"><a href="#step-1-在虚拟机centos上新建用户jdorientdb-下载orientdb包解压到-software-orientdb目录" class="headerlink" title="step 1:在虚拟机centos上新建用户jdorientdb,下载orientdb包解压到 /software/orientdb目录"></a>step 1:在虚拟机centos上新建用户jdorientdb,下载orientdb包解压到 /software/orientdb目录</h3><h3 id="step-2-设置ORIENTDB-HOME环境变量"><a href="#step-2-设置ORIENTDB-HOME环境变量" class="headerlink" title="step 2:设置ORIENTDB_HOME环境变量"></a>step 2:设置ORIENTDB_HOME环境变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">vim ~/.bash_rc</div><div class="line"></div><div class="line">export ORIENTDB_HOME=<span class="string">"your soft directory"</span></div><div class="line"></div><div class="line">source ~/.bash_rc</div></pre></td></tr></table></figure>
<h3 id="step-3-修改config-orientdb-server-config-xml，设置用户登录密码"><a href="#step-3-修改config-orientdb-server-config-xml，设置用户登录密码" class="headerlink" title="step 3:修改config/orientdb-server-config.xml，设置用户登录密码"></a>step 3:修改config/orientdb-server-config.xml，设置用户登录密码</h3><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&lt;users&gt;</div><div class="line">    &lt;user resources="*" password="jdorientdb" name="jdorientdb"/&gt;</div><div class="line">&lt;/users&gt;</div></pre></td></tr></table></figure>
<h3 id="step-4-修改bin-orientdb-sh"><a href="#step-4-修改bin-orientdb-sh" class="headerlink" title="step 4:修改bin/orientdb.sh"></a>step 4:修改bin/orientdb.sh</h3><p>orientdb启动默认需要root权限，修改配置去除root权限限制<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># You have to SET the OrientDB installation directory here</span></div><div class="line">ORIENTDB_DIR=<span class="string">"$ORIENTDB_HOME"</span></div><div class="line">ORIENTDB_USER=<span class="string">"jdorientdb"</span></div><div class="line"></div><div class="line">start方法中注释root权限执行：</div><div class="line"><span class="comment">#su $ORIENTDB_USER -c "cd \"$ORIENTDB_DIR/bin\"; </span></div><div class="line">/usr/bin/nohup ./server.sh <span class="number">1</span>&gt;$LOG_DIR/orientdb.log <span class="number">2</span>&gt;$LOG_DIR/orientdb.err &amp;</div><div class="line"></div><div class="line">stop方法中注释root权限执行：</div><div class="line"><span class="comment">#su $ORIENTDB_USER -c "cd \"$ORIENTDB_DIR/bin\";</span></div><div class="line">/usr/bin/nohup ./shutdown.sh <span class="number">1</span>&gt;&gt;$LOG_DIR/orientdb.log <span class="number">2</span>&gt;&gt;$LOG_DIR/orientdb.err &amp;</div></pre></td></tr></table></figure></p>
<h3 id="step-5-配置集群中各节点发现服务，修改configh-azecast-xml"><a href="#step-5-配置集群中各节点发现服务，修改configh-azecast-xml" class="headerlink" title="step 5:配置集群中各节点发现服务，修改configh/azecast.xml"></a>step 5:配置集群中各节点发现服务，修改configh/azecast.xml</h3><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">&lt;group&gt;</div><div class="line">    &lt;name&gt;jdorientdb&lt;/name&gt;</div><div class="line">    &lt;password&gt;jdorientdb&lt;/password&gt;</div><div class="line">&lt;/group&gt;</div><div class="line"></div><div class="line">&lt;network&gt;</div><div class="line">    &lt;port auto-increment="true"&gt;2434&lt;/port&gt;</div><div class="line">    &lt;join&gt;</div><div class="line">        &lt;multicast enabled="false"&gt;</div><div class="line">            &lt;multicast-group&gt;235.1.1.1&lt;/multicast-group&gt;</div><div class="line">            &lt;multicast-port&gt;2434&lt;/multicast-port&gt;</div><div class="line">        &lt;/multicast&gt;</div><div class="line">         &lt;tcp-ip enabled="true"&gt;#配置待优化</div><div class="line">                &lt;member&gt;jdorientdb1:2434&lt;/member&gt;</div><div class="line">                &lt;member&gt;jdorientdb2:2434&lt;/member&gt;</div><div class="line">                &lt;member&gt;jdorientdb3:2434&lt;/member&gt;</div><div class="line">                &lt;member&gt;jdorientdb4:2434&lt;/member&gt;</div><div class="line">            &lt;/tcp-ip&gt;           </div><div class="line">    &lt;/join&gt;</div><div class="line">&lt;/network&gt;</div></pre></td></tr></table></figure>
<h3 id="step6-修改config-default-distributed-db-config-json"><a href="#step6-修改config-default-distributed-db-config-json" class="headerlink" title="step6:修改config/default-distributed-db-config.json"></a>step6:修改config/default-distributed-db-config.json</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="string">"autoDeploy"</span>: true,</div><div class="line">  <span class="string">"readQuorum"</span>: <span class="number">1</span>,</div><div class="line">  <span class="string">"writeQuorum"</span>: <span class="string">"majority"</span>,</div><div class="line">  <span class="string">"executionMode"</span>: <span class="string">"asynchronous"</span>,</div><div class="line">  <span class="string">"readYourWrites"</span>: true,</div><div class="line">  <span class="string">"servers"</span>: &#123;</div><div class="line">    <span class="string">"jdorientdb1"</span>: <span class="string">"master"</span>,</div><div class="line">    <span class="string">"jdorietndb2"</span>:<span class="string">"master"</span>,</div><div class="line">    <span class="string">"jdorientdb3"</span>:<span class="string">"master"</span>,</div><div class="line">    <span class="string">"jdorientdb4"</span>:<span class="string">"master"</span></div><div class="line">  &#125;,</div><div class="line">  <span class="string">"clusters"</span>: &#123;</div><div class="line">    <span class="string">"internal"</span>: &#123;</div><div class="line">    &#125;,</div><div class="line">    <span class="string">"*"</span>: &#123;</div><div class="line">      <span class="string">"servers"</span>: [<span class="string">"jdorientdb1"</span>,<span class="string">"jdorientdb2"</span>,<span class="string">"jdorientdb3"</span>,<span class="string">"jdorientdb4"</span>]</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="step-7-每台虚拟机分别设置ip别名，修改-etc-hosts"><a href="#step-7-每台虚拟机分别设置ip别名，修改-etc-hosts" class="headerlink" title="step 7:每台虚拟机分别设置ip别名，修改/etc/hosts"></a>step 7:每台虚拟机分别设置ip别名，修改/etc/hosts</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="number">10.14</span><span class="number">.133</span><span class="number">.18</span>    jdorientdb2</div><div class="line"><span class="number">10.14</span><span class="number">.133</span><span class="number">.13</span>    jdorientdb1</div><div class="line"><span class="number">10.14</span><span class="number">.133</span><span class="number">.25</span>    jdorientdb3</div><div class="line"><span class="number">10.14</span><span class="number">.133</span><span class="number">.75</span>    jdorientdb4</div></pre></td></tr></table></figure>
<h3 id="step-8-将配置好的orientdb分别发送到其他虚拟机"><a href="#step-8-将配置好的orientdb分别发送到其他虚拟机" class="headerlink" title="step 8:将配置好的orientdb分别发送到其他虚拟机"></a>step 8:将配置好的orientdb分别发送到其他虚拟机</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scp -r /software/orientdb jdorientdb@jdorientdb2:/software/jdorientdb</div></pre></td></tr></table></figure>
<h3 id="step-9-分别启动每台虚拟机上的orientdb进程"><a href="#step-9-分别启动每台虚拟机上的orientdb进程" class="headerlink" title="step 9:分别启动每台虚拟机上的orientdb进程"></a>step 9:分别启动每台虚拟机上的orientdb进程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">nohup bin/dserver.sh &gt; tmp.log &amp;</div><div class="line"></div><div class="line">首次启动需要设置nodeName，设置为与ip别名一致</div></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h3><p>1.<a href="http://orientdb.com/docs/last/Distributed-Configuration.html" target="_blank" rel="external">Distributed-Configuration</a><br>2.<a href="http://blog.topspeedsnail.com/archives/1884" target="_blank" rel="external">http://blog.topspeedsnail.com/archives/1884</a><br>3.<a href="http://orientdb.com/docs/last/Performance-Tuning.html" target="_blank" rel="external">Performance-Tuning</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;step-1-在虚拟机centos上新建用户jdorientdb-下载orientdb包解压到-software-orientdb目录&quot;&gt;&lt;a href=&quot;#step-1-在虚拟机centos上新建用户jdorientdb-下载orientdb包解压到-softw
    
    </summary>
    
      <category term="Notes" scheme="http://yoursite.com/categories/Notes/"/>
    
    
      <category term="orientdb" scheme="http://yoursite.com/tags/orientdb/"/>
    
  </entry>
  
  <entry>
    <title>已有集群环境中运行不同版本的spark任务</title>
    <link href="http://yoursite.com/2016/10/09/spark-run-spark-on-diff-env/"/>
    <id>http://yoursite.com/2016/10/09/spark-run-spark-on-diff-env/</id>
    <published>2016-10-09T14:00:00.000Z</published>
    <updated>2017-06-18T07:34:39.052Z</updated>
    
    <content type="html"><![CDATA[<p>因为公司部署的Spark集群版本还停留在1.5.2，但现在spark已经更新到2.0.1了。由于想迫切尝试下spark的新特性，如Spark ML模型保存功能,SparkSession统一接口 etc. 因此想到是否可以基于现有的集群环境来运行最新版本spark程序，经过几番捣腾，终于成功，固记录下来分享给大家。</p>
<p>本文使用的spark版本是2.0.0，而公司的集群spark版本是1.5.2</p>
<p><strong>1.</strong> 首先去官网<code>http://spark.apache.org/</code>下载最新版本包，也可去github上clone最新源码，然后在IDEA中编译</p>
<p><code>step1</code> 由于spark2.0取消了spark-assembly jar，但2.0之前打包方式均为assembly jar形式；如果还想使用assembly jar形式，可以修改源码assembly模块中pom.xml配置: </p>
<figure class="highlight dust"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="xml"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span></div><div class="line">  <span class="tag">&lt;<span class="name">sbt.project.name</span>&gt;</span>assembly<span class="tag">&lt;/<span class="name">sbt.project.name</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">build.testJarPhase</span>&gt;</span>none<span class="tag">&lt;/<span class="name">build.testJarPhase</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">build.copyDependenciesPhase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">build.copyDependenciesPhase</span>&gt;</span></div><div class="line">  <span class="comment">&lt;!--fat jar config by sj_mei--&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">spark.jar.basename</span>&gt;</span>spark-assembly-$<span class="template-variable">&#123;project.version&#125;</span><span class="xml">-hadoop$</span><span class="template-variable">&#123;hadoop.version&#125;</span><span class="xml">.jar<span class="tag">&lt;/<span class="name">spark.jar.basename</span>&gt;</span></span></div><div class="line">  <span class="tag">&lt;<span class="name">spark.jar</span>&gt;</span>$<span class="template-variable">&#123;project.build.directory&#125;</span><span class="xml">/$</span><span class="template-variable">&#123;spark.jar.basename&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">spark.jar</span>&gt;</span></span></div><div class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></div></pre></td></tr></table></figure>
<p><code>step2</code> spark解压后目录：<br><img src="/uploads/spark/spark-2.0-home.png" alt="spark home目录列表"></p>
<p><strong>2.</strong> 因spark-shell,spark-sql,spark-submit运行时需要读取<code>SPARK_HOME</code>与<code>SPARK_CONF_DIR</code>配置，为让spark不用原生产环境中的配置，所以需要重新设置零时环境变量(对当前会话窗口有效)<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">方法1：在自定义env配置文件.mybashrc中设置：</div><div class="line"><span class="builtin-name">export</span> <span class="attribute">SPARK_HOME</span>=/home/sjmei/plugins/spark_2.0</div><div class="line"><span class="builtin-name">export</span> <span class="attribute">SPARK_CONF_DIR</span>=/home/sjmei/plugins/spark_2.0/conf</div><div class="line"></div><div class="line">让当前设置生效:source .mybashrc</div><div class="line"></div><div class="line">方法2：也可以在bin目录下spark-shell.sh,spark-submit.sh中单独配置上述两个变量</div></pre></td></tr></table></figure></p>
<p><strong>3.</strong> 修改<code>conf/spark-defaults.conf</code>文件，避免让spark运行时读取系统原有配置文件<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">spark<span class="selector-class">.yarn</span><span class="selector-class">.jars</span>   hdfs:<span class="comment">//ns2/user/mart_risk/jrdm/jars/*.jar</span></div><div class="line">or</div><div class="line">[运行时会警告参数已弃用]</div><div class="line">spark<span class="selector-class">.yarn</span><span class="selector-class">.jar</span>    hdfs:<span class="comment">//ns2/user/mart_risk/sjmei/lib/spark-assembly-2.0.0-hadoop2.7.1.jar</span></div></pre></td></tr></table></figure></p>
<p><img src="/uploads/spark/spark-defaults.png" alt="spark-defaults.conf"></p>
<p><strong>4.</strong> 经过上述同步，spark2.0就设置好了，接下来就可以试试运行bin/spark-shell，bin/spark-submit来提交任务了^_^<br><img src="/uploads/spark/run-spark-shell.png" alt="run-spark-shell"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;因为公司部署的Spark集群版本还停留在1.5.2，但现在spark已经更新到2.0.1了。由于想迫切尝试下spark的新特性，如Spark ML模型保存功能,SparkSession统一接口 etc. 因此想到是否可以基于现有的集群环境来运行最新版本spark程序，经过几
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>OrientDB单机版安装笔记</title>
    <link href="http://yoursite.com/2016/09/28/orientdb-install/"/>
    <id>http://yoursite.com/2016/09/28/orientdb-install/</id>
    <published>2016-09-28T14:00:00.000Z</published>
    <updated>2017-06-18T06:44:55.761Z</updated>
    
    <content type="html"><![CDATA[<h3 id="step-one-设置ORIENTDB-HOME-in-bash-rc"><a href="#step-one-设置ORIENTDB-HOME-in-bash-rc" class="headerlink" title="step one:设置ORIENTDB_HOME in ~/.bash_rc"></a>step one:设置ORIENTDB_HOME in ~/.bash_rc</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export ORIENTDB_HOME=<span class="string">"your soft directory"</span></div></pre></td></tr></table></figure>
<h3 id="step-two-修改config-orientdb-server-config-xml，设置用户登录密码"><a href="#step-two-修改config-orientdb-server-config-xml，设置用户登录密码" class="headerlink" title="step two:修改config/orientdb-server-config.xml，设置用户登录密码"></a>step two:修改config/orientdb-server-config.xml，设置用户登录密码</h3><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;users&gt;</div><div class="line">    &lt;user resources="*" password="orientdb" name="orientdb"/&gt;</div><div class="line">    &lt;user resources="connect,server.listDatabases,server.dblist" password="spark" name="guest"/&gt;</div><div class="line">&lt;/users&gt;</div></pre></td></tr></table></figure>
<h3 id="step-three-修改bin-orientdb-sh"><a href="#step-three-修改bin-orientdb-sh" class="headerlink" title="step three:修改bin/orientdb.sh"></a>step three:修改bin/orientdb.sh</h3><p>orientdb启动默认需要root权限，修改配置去除root权限限制<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># You have to SET the OrientDB installation directory here</span></div><div class="line">ORIENTDB_DIR=<span class="string">"$ORIENTDB_HOME"</span></div><div class="line">ORIENTDB_USER=<span class="string">"orientdb"</span></div><div class="line"></div><div class="line">start方法修改为：</div><div class="line"><span class="comment">#su $ORIENTDB_USER -c "cd \"$ORIENTDB_DIR/bin\"; /usr/bin/nohup ./server.sh 1&gt;$LOG_DIR/orientdb.log 2&gt;$LOG_DIR/orientdb.err &amp;"</span></div><div class="line">/usr/bin/nohup ./server.sh <span class="number">1</span>&gt;$LOG_DIR/orientdb.log <span class="number">2</span>&gt;$LOG_DIR/orientdb.err &amp;</div><div class="line"></div><div class="line">stop方法修改为：</div><div class="line"><span class="comment">#su $ORIENTDB_USER -c "cd \"$ORIENTDB_DIR/bin\"; /usr/bin/nohup ./shutdown.sh 1&gt;&gt;$LOG_DIR/orientdb.log 2&gt;&gt;$LOG_DIR/orientdb.err &amp;"</span></div><div class="line">/usr/bin/nohup ./shutdown.sh <span class="number">1</span>&gt;&gt;$LOG_DIR/orientdb.log <span class="number">2</span>&gt;&gt;$LOG_DIR/orientdb.err &amp;</div></pre></td></tr></table></figure></p>
<h3 id="bin-server-sh启动进程服务-or-bin-orientdb-sh-start-stop-后台启动服务"><a href="#bin-server-sh启动进程服务-or-bin-orientdb-sh-start-stop-后台启动服务" class="headerlink" title="bin/server.sh启动进程服务 or bin/orientdb.sh start/stop 后台启动服务"></a>bin/server.sh启动进程服务 or bin/orientdb.sh start/stop 后台启动服务</h3><h3 id="neo4j单机节点安装：修改conf-neo4j-conf"><a href="#neo4j单机节点安装：修改conf-neo4j-conf" class="headerlink" title="neo4j单机节点安装：修改conf/neo4j.conf"></a>neo4j单机节点安装：修改conf/neo4j.conf</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dbms.connector.http.address=<span class="number">172.19</span><span class="number">.163</span><span class="number">.83</span>:<span class="number">7474</span></div></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h3><p>1.<a href="http://blog.topspeedsnail.com/archives/1884" target="_blank" rel="external">http://blog.topspeedsnail.com/archives/1884</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;step-one-设置ORIENTDB-HOME-in-bash-rc&quot;&gt;&lt;a href=&quot;#step-one-设置ORIENTDB-HOME-in-bash-rc&quot; class=&quot;headerlink&quot; title=&quot;step one:设置ORIENTDB_HO
    
    </summary>
    
      <category term="Notes" scheme="http://yoursite.com/categories/Notes/"/>
    
    
      <category term="orientdb" scheme="http://yoursite.com/tags/orientdb/"/>
    
      <category term="neo4j" scheme="http://yoursite.com/tags/neo4j/"/>
    
  </entry>
  
  <entry>
    <title>Spark GraphX</title>
    <link href="http://yoursite.com/2016/09/25/spark-graphx/"/>
    <id>http://yoursite.com/2016/09/25/spark-graphx/</id>
    <published>2016-09-25T14:00:00.000Z</published>
    <updated>2017-08-17T02:51:59.294Z</updated>
    
    <content type="html"><![CDATA[<h3 id="图性能优化笔记1"><a href="#图性能优化笔记1" class="headerlink" title="图性能优化笔记1"></a>图性能优化笔记1</h3><p>原始方法对求社区对应顶点数过程中，使用了单机函数collectAsMap，当社区数非常多时，该函数将数据汇总到driver节点，导致driver节点发生OOM。<br><code>解决办法</code>：避免对大数据量使用collectAsMap操作，改为RDD集合求将交集。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getGraphWithCommVertexNum</span></span>[<span class="type">ED</span>: <span class="type">ClassTag</span>](g: <span class="type">Graph</span>[<span class="type">VertexAttr</span>, <span class="type">ED</span>]): <span class="type">Graph</span>[<span class="type">VertexAttr</span>, <span class="type">ED</span>] = &#123;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * modified by cdemishangian</div><div class="line">      *</div><div class="line">      * BugFix: avoid using collectAsMap lead to driver OOM</div><div class="line">      *</div><div class="line">      * val cvnMap = g.vertices.map ( e =&gt; (e._2.community, 1)).reduceByKey(_ + _).collectAsMap</div><div class="line">      * val graph = g.mapVertices&#123; (vid, vertexAttr) =&gt;</div><div class="line">      * vertexAttr.commVertexNum = cvnMap.getOrElse(vertexAttr.community, LocalConstants.countMissingVal)</div><div class="line">      *   vertexAttr</div><div class="line">      * &#125;</div><div class="line">      */</div><div class="line">    <span class="keyword">val</span> cvnMapRDD = g.vertices.map(e =&gt; (e._2.community, <span class="number">1</span>)).reduceByKey(_ + _)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> commCntRDD = g.vertices.map(r =&gt;&#123;</div><div class="line">      (r._2.community,r._1)</div><div class="line">    &#125;).leftOuterJoin(cvnMapRDD).map(r=&gt;</div><div class="line">      (r._2._1,(r._1,r._2._2.getOrElse(<span class="type">LocalConstants</span>.countMissingVal)))</div><div class="line">    )</div><div class="line"></div><div class="line">    <span class="keyword">val</span> graph = g.subgraph(vpred = (vid,attr)=&gt; vid != <span class="type">LocalConstants</span>.vidLongMissingVal).joinVertices(commCntRDD)&#123;</div><div class="line">      (vid, vertexAttr, commCnt) =&gt;</div><div class="line">        vertexAttr.commVertexNum = commCnt._2</div><div class="line">        vertexAttr</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    graph</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="图性能优化笔记2"><a href="#图性能优化笔记2" class="headerlink" title="图性能优化笔记2"></a>图性能优化笔记2</h3><p>由于spark2.0中彻底废弃了mapReduceTriplets函数，改为了aggregateMessages操作，<br>以下代码为mapReduceTriplets转换为aggregateMessages的转换操作</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">    <span class="keyword">val</span> nodeWeightMapFunc = (e:<span class="type">EdgeTriplet</span>[<span class="type">VD</span>,<span class="type">Long</span>]) =&gt; <span class="type">Iterator</span>((e.srcId,e.attr), (e.dstId,e.attr))</div><div class="line">    <span class="keyword">val</span> nodeWeightReduceFunc = (e1:<span class="type">Long</span>,e2:<span class="type">Long</span>) =&gt; e1+e2</div><div class="line">    <span class="keyword">val</span> nodeWeights = graph.mapReduceTriplets(nodeWeightMapFunc,nodeWeightReduceFunc)</div><div class="line"></div><div class="line"></div><div class="line">    <span class="keyword">val</span> nodeWeightMapFunc = (e:<span class="type">EdgeContext</span>[<span class="type">VD</span>,<span class="type">Long</span>,<span class="type">Long</span>]) =&gt; &#123;</div><div class="line">      e.sendToDst(e.attr)</div><div class="line">      e.sendToSrc(e.attr)</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">val</span> nodeWeightReduceFunc = (e1:<span class="type">Long</span>,e2:<span class="type">Long</span>) =&gt; e1+e2</div><div class="line">    <span class="keyword">val</span> nodeWeights = graph.aggregateMessages(nodeWeightMapFunc,nodeWeightReduceFunc) </div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">   * Creates the messages passed between each vertex to convey neighborhood community data.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">sendMsg</span></span>(et:<span class="type">EdgeTriplet</span>[<span class="type">VertexState</span>,<span class="type">Long</span>]) = &#123;</div><div class="line">    <span class="keyword">val</span> m1 = (et.dstId,<span class="type">Map</span>((et.srcAttr.community,et.srcAttr.communitySigmaTot)-&gt;et.attr))</div><div class="line">    <span class="keyword">val</span> m2 = (et.srcId,<span class="type">Map</span>((et.dstAttr.community,et.dstAttr.communitySigmaTot)-&gt;et.attr))</div><div class="line">    <span class="type">Iterator</span>(m1, m2)    </div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">sendMsg</span></span>(et:<span class="type">EdgeContext</span>[<span class="type">VertexState</span>,<span class="type">Long</span>,<span class="type">Map</span>[(<span class="type">Long</span>,<span class="type">Long</span>),<span class="type">Long</span>]]) = &#123;</div><div class="line">    et.sendToDst(<span class="type">Map</span>((et.srcAttr.community, et.srcAttr.communitySigmaTot) -&gt; et.attr))</div><div class="line">    et.sendToSrc(<span class="type">Map</span>((et.dstAttr.community, et.dstAttr.communitySigmaTot) -&gt; et.attr))</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="图性能优化笔记3"><a href="#图性能优化笔记3" class="headerlink" title="图性能优化笔记3"></a>图性能优化笔记3</h3><p>现在业务场景在计算graphx中的三角计数指标时，由于关系数很多，达到10亿条边，通过观察运行日志发现，每次运行tcNum指标时，会产生25倍于边内存量的Shuffle Read/Write；由于缺乏对底层原理的掌握，一直不知道如何优化，经过几周的间断性尝试，今天终于通过设置图分区策略解决问题:设置PartitionStrategy.EdgePartition2D<br><figure class="highlight markdown"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">def getGraphWithAttrTCNum[<span class="string">ED: ClassTag</span>](<span class="link">g: Graph[VertexAttr, ED]</span>): Graph[VertexAttr, ED] = &#123;</div><div class="line"><span class="code">    val newGraph = g.convertToCanonicalEdges().partitionBy(PartitionStrategy.EdgePartition2D)</span></div><div class="line"><span class="code">    val tcv = newGraph.triangleCount().vertices</span></div><div class="line"><span class="code">    logWarning("JRDM:"+tcv.count)</span></div><div class="line"></div><div class="line"><span class="code">    val graph = g.outerJoinVertices(tcv) &#123; (id, a, o) =&gt;</span></div><div class="line"><span class="code">      a.tcNum = o.getOrElse(LocalConstants.countMissingVal)</span></div><div class="line"><span class="code">      a</span></div><div class="line"><span class="code">    &#125;</span></div><div class="line"></div><div class="line"><span class="code">    graph</span></div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>val lineArray = line.split(“\s+”)//\s表示空格,回车,换行等空白符, +号表示一个或多个</p>
<h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><ol>
<li>sc.textFile 读文件，生成原始的RDD</li>
<li>每个分区(的计算节点)把每条记录放进 PrimitiveVector 里，这个结构是spark里为primitive数据优化的存储结构。<br>把 PrimitiveVector 里的数据一条条取出，转化成 EdgePartition ，即 EdgeRDD 的分区实现。这个过程中生成了面向列存的结构：src点的array，dst点的array，edge的属性array，以及两个正反向map(用于对应点的local id和global id)。</li>
<li>对 EdgeRDD 做一次count触发这次边建模任务，真正persist起来。</li>
<li>用 EdgePartition 去生成一个 RoutingTablePartition ，里面是vertexId到partitionId的对应关系，借助 RoutingTablePartition 生成 VertexRDD 。</li>
<li>由 EdgeRDD 和 VertexRDD 生成 Graph。前者维护了边的属性、边两头顶点的属性、两头顶点各自的global vertexID、两头顶点各自的local Id（在一个edge分区里的array index）、用于寻址array的正反向map。后者维护了点存在于哪个边的分区上的Map。</li>
</ol>
<p>我们对 Fast Unfolding 算法做一个简要介绍，它分为以下两个阶段：</p>
<p>第一个阶段：首先将每个节点指定到唯一的一个社区，然后按顺序将节点在这些社区间进行移动。怎么移动呢？以上图中的节点 i 为例，它有三个邻居节点 j1, j2, j3，我们分别尝试将节点 i 移动到 j1, j2, j3 所在的社区，并计算相应的 modularity 变化值，哪个变化值最大就将节点 i 移动到相应的社区中去（当然，这里我们要求最大的 modularity 变化值要为正，如果变化值均为负，则节点 i 保持不动）。按照这个方法反复迭代，直到网络中任何节点的移动都不能再改善总的 modularity 值为止。</p>
<p>第二个阶段：将第一个阶段得到的社区视为新的“节点”（一个社区对应一个），重新构造子图，两个新“节点”之间边的权值为相应两个社区之间各边的权值的总和。</p>
<p>我们将上述两个阶段合起来称为一个 pass，显然，这个 pass  可以继续下去。</p>
<p>从上述描述我们可以看出，这种算法包含了一种 hierarchy 结构，正如对一个学校的所有初中生进行聚合一样，首先我们可以将他们按照班级来聚合，进一步还可以在此基础上按照年级来聚合，两次聚合都可以看做是一个社区发现结果，就看你想要聚合到什么层次与程度。</p>
<p>标签传播算法（LPA）的做法比较简单：<br>第一步: 为所有节点指定一个唯一的标签；<br>第二步: 逐轮刷新所有节点的标签，直到达到收敛要求为止。对于每一轮刷新，节点标签刷新的规则如下:<br>    对于某一个节点，考察其所有邻居节点的标签，并进行统计，将出现个数最多的那个标签赋给当前节点。当个数最多的标签不唯一时，随机选一个。</p>
<p>注：算法中的记号 N_n^k 表示节点 n 的邻居中标签为 k 的所有节点构成的集合。</p>
<p>并行化问题及解决策略</p>
<p>进行并行化处理时，我们主要遇到两个问题：一是中间计算量过大，二是消息滞后。</p>
<p><strong>中间计算量过大</strong><br>如果直接使用公式（1）进行Modularity计算，会导致中间计算量过大，因为它需要考虑两两节点对的情况（pairwise），即n平方的量级（n为节点个数），在大数据量情况下并不可行。</p>
<p>尝试的一个解决方法是，进行分步计算，如根据节点Id的hash值将数据划分成100个分区，每次只对分区内的节点进行计算。但是这种方法处理不直观，效率也不高。</p>
<p>经过反复尝试后，我们发现，更好的解决方法是使用化简后的公式（2）进行处理，避免了pairwise的过程。</p>
<p><strong>消息滞后</strong><br>由于在并行化处理时，在t轮时每个节点根据t-1轮时的邻居社区信息进行更新，存在一定的消息滞后现象，会造成 “互换社区” 的问题</p>
<p>每个节点被分配到不同的社区中（节点1属于G1，节点2属于G2，节点3属于G3，节点4属于G4）<br>第二轮b图时，每个节点根据它邻居的信息进行更新（如节点1的新社区为邻居节点2在第一轮的社区G2）<br>最终情况会导致不相连的节点反而归属同一社区（如节点1与3均受到节点2的影响，归属社区G2）<br>第三轮c图类似，造成社区的互换。造成这种情况的原因在于，每个节点根据它的邻居前一轮的信息进行变化，而它的邻居也在同步改变。</p>
<p>类似的，还会存在有 “社区归属延迟” 问题。示意图如图4所示。节点1的归属社区受到节点2的影响，归属到社区2。但是节点2的社区也在同步变化，它可能归属于社区3，这样就造成只有节点1归属到社区2，成为一个孤立的点。</p>
<p>考虑有以下两种解决策略：</p>
<p>添加随机值，即每轮迭代中会有部分节点的社区保持不变。如果阈值足够高，其实相当于逐个节点进行社区信息的更新，也即与串行的方法等价。使用随机值带来的问题是不能保证结果，得到的Modularity值有时高，有时低。并且，“互换社区”的问题不一定能解决。考虑到的一种解决思路是，多次运行，取最优。但是，这种方法也不太可靠，随机性较大。</p>
<p>得到结果后构建逻辑图，求解连通区域，将同一个连通区域的点都归为一个社区。比如初始结果是互换社区的<1,2>,<2,1>（格式为&lt;节点Id，归属社区&gt;），求连通区域就可以将它们都归属同一社区。这种思路也可以解决 “社区归属延迟”的问题，如初始结果是<1,2>,<2,3>,<3,4>，节点1应该与归属社区2，但是节点2又归属于社区3，所以最终应该节点1,2,3都归属社区3。</3,4></2,3></1,2></2,1></1,2></p>
<p>对比上面两种方法，后一种策略充分考虑了图的特性，更为可取，能够保证结果的稳定性。大致代码如下：</p>
<p><strong>总结</strong></p>
<p>FastUnfolding算法，基于结果Modularity值的优化进行，得到的社区发现效果比较理想，对比LPA算法会更稳定。并且，FastUnfolding算法会不断合并节点构造新图，大大减少了计算量，使得大规模图数据的计算成为可能。</p>
<p>原始的FastUnfolding算法采用串行化的实现思路，不适合面对海量数据。实现中需要进行算法并行化，充分利用并行化框架带来的计算优势。在将传统的串行化算法改造成并行化算法的过程中时，会遇到中间计算量过大、消息滞后造成的问题，如“互换社区”和“社区归属延迟”问题。解决的思路是考虑图的特性，对结果再次求解连通图区域，并通过重置社区得到最终结果。这样既保证了算法的准确性，又保证其性能，从而能够在大规模的网络上，进行实际的生产应用。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h3><p>[1]：<a href="http://blog.csdn.net/pelick/article/details/47293495" target="_blank" rel="external"> GraphX 图数据建模和存储</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;图性能优化笔记1&quot;&gt;&lt;a href=&quot;#图性能优化笔记1&quot; class=&quot;headerlink&quot; title=&quot;图性能优化笔记1&quot;&gt;&lt;/a&gt;图性能优化笔记1&lt;/h3&gt;&lt;p&gt;原始方法对求社区对应顶点数过程中，使用了单机函数collectAsMap，当社区数非常多时，
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
      <category term="Graphx" scheme="http://yoursite.com/categories/Spark/Graphx/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
      <category term="Graphx" scheme="http://yoursite.com/tags/Graphx/"/>
    
  </entry>
  
  <entry>
    <title>Spark Netty Rpc</title>
    <link href="http://yoursite.com/2016/09/25/spark-rpc/"/>
    <id>http://yoursite.com/2016/09/25/spark-rpc/</id>
    <published>2016-09-25T14:00:00.000Z</published>
    <updated>2017-06-18T07:28:43.030Z</updated>
    
    <content type="html"><![CDATA[<h3 id="RpcEnv"><a href="#RpcEnv" class="headerlink" title="RpcEnv"></a>RpcEnv</h3><p>RPC Environment (aka RpcEnv) is an environment for RpcEndpoints to process messages. A RPC Environment manages the entire lifecycle of RpcEndpoints:</p>
<ul>
<li>registers (sets up) endpoints (by name or uri)</li>
<li>routes incoming messages to them</li>
<li>stops them</li>
</ul>
<h3 id="RpcEndpoint"><a href="#RpcEndpoint" class="headerlink" title="RpcEndpoint"></a>RpcEndpoint</h3><p>RpcEndpoints define how to handle messages (what functions to execute given a message). RpcEndpoints register (with a name or uri) to RpcEnv to receive messages from RpcEndpointRefs.<br>RpcEndpoints 定义了如何处理消息(对指定消息执行指定功能)，它向RpcEnv注册并接收来自RpcEndpointRefs的消息<br><img src="/uploads/spark/rpcenv-endpoints.png" alt="rpcenv-endpoints"></p>
<p>A RpcEndpoint can be registered to one and only one RpcEnv.<br>The lifecycle of a RpcEndpoint is onStart, receive and onStop in sequence.<br>receive can be called concurrently.<br>Tip: If you want receive to be thread-safe, use ThreadSafeRpcEndpoint.</p>
<h3 id="RpcEndpointRef"><a href="#RpcEndpointRef" class="headerlink" title="RpcEndpointRef"></a>RpcEndpointRef</h3><p>A RpcEndpointRef is a reference for a RpcEndpoint in a RpcEnv.<br>It is serializable entity and so you can send it over a network or save it for later use (it can however be deserialized using the owning RpcEnv only).<br>A RpcEndpointRef has an address (a Spark URL), and a name.<br>You can send asynchronous one-way messages to the corresponding RpcEndpoint using send method.<br>You can send a semi-synchronous message, i.e. “subscribe” to be notified when a response arrives, using ask method. You can also block the current calling thread for a response using askWithRetry method.</p>
<h3 id="RpcAddress"><a href="#RpcAddress" class="headerlink" title="RpcAddress"></a>RpcAddress</h3><p>RpcAddress is the logical address for an RPC Environment, with hostname and port.<br>RpcAddress is encoded as a Spark URL, i.e. spark://host:port.</p>
<h3 id="RpcEndpointAddress"><a href="#RpcEndpointAddress" class="headerlink" title="RpcEndpointAddress"></a>RpcEndpointAddress</h3><p>RpcEndpointAddress is the logical address for an endpoint registered to an RPC Environment, with RpcAddress and name.+<br>It is in the format of spark://[name]@[rpcAddress.host]:[rpcAddress.port].</p>
<h3 id="Ask-Operation-Timeout"><a href="#Ask-Operation-Timeout" class="headerlink" title="Ask Operation Timeout"></a>Ask Operation Timeout</h3><p>Ask operation is when a RPC client expects a response to a message. It is a blocking operation.<br>You can control the time to wait for a response using the following settings (in that order):<br>spark.rpc.askTimeout<br>spark.network.timeout<br>Their value can be a number alone (seconds) or any number with time suffix, e.g. 50s, 100ms, or 250us. See Settings.</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h3><ol>
<li><a href="https://github.com/jaceklaskowski/mastering-apache-spark-book/blob/master/spark-rpc.adoc" target="_blank" rel="external">mastering-apache-spark-book#spark-rpc</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;RpcEnv&quot;&gt;&lt;a href=&quot;#RpcEnv&quot; class=&quot;headerlink&quot; title=&quot;RpcEnv&quot;&gt;&lt;/a&gt;RpcEnv&lt;/h3&gt;&lt;p&gt;RPC Environment (aka RpcEnv) is an environment for Rpc
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark Submit任务提交过程源码分析</title>
    <link href="http://yoursite.com/2016/09/25/spark-submit/"/>
    <id>http://yoursite.com/2016/09/25/spark-submit/</id>
    <published>2016-09-25T14:00:00.000Z</published>
    <updated>2017-06-18T07:41:51.234Z</updated>
    
    <content type="html"><![CDATA[<p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="http://music.163.com/outchain/player?type=2&id=28947001&auto=1&height=66"></iframe><br>由于对spark-submit提交后执行流程比较好奇，所以研究了一下spark源码，以下算是阅读笔记吧。</p>
<h2 id="spark-submit启动脚本："><a href="#spark-submit启动脚本：" class="headerlink" title="spark-submit启动脚本："></a>spark-submit启动脚本：</h2><ul>
<li>shell -z判断参数是否为空； $@：表示所有参数；$?：表示上一次程序返回值</li>
<li>使用@ 或<em>可以获取数组中的所有元素，例如：${array_name[</em>]}，${array_name[@]}</li>
<li>SparkSubmit–&gt;yarn/Client–&gt;ApplicationMaster<ul>
<li>Client：负责提交作业到Master。</li>
<li>Master：接收Client提交的作业，管理Worker，并命令Worker启动Driver和Executor。</li>
<li>Worker：负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，比如启动Driver和Executor。</li>
</ul>
</li>
<li>shell read可以带有-a, -d, -e, -n, -p, -r, -t, 和 -s八个选项。<figure class="highlight haml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">-<span class="ruby">a ：将内容读入到数值中</span></div><div class="line">-<span class="ruby">d ：表示delimiter，即定界符，一般情况下是以IFS为参数的间隔，但是通过-d，可以定义一直读到出现执行的字符位置。</span></div><div class="line">-<span class="ruby">n ：用于限定最多可以有多少字符可以作为有效读入。</span></div><div class="line">-<span class="ruby">p ：用于给出提示符，在前面的例子中我们使用了echo –n “…“来给出提示符，可以使用read –p ‘… my promt?’value的方式只需一个语句来表示。</span></div><div class="line">-<span class="ruby">r ：在参数输入中，我们可以使用’/’表示没有输入完，换行继续输入。</span></div><div class="line">-<span class="ruby">s ：对于一些特殊的符号，例如箭头号，不将他们在terminal上打印，我们按光标，在回车之后，如果要求显示，即echo，光标向上，如果不使用-s，在输入时，输入处显示^[[A，即在terminal上打印，之后如果要求echo，光标会上移。</span></div><div class="line">-<span class="ruby">t ：用于表示等待输入的时间，单位为秒，等待时间超过，将继续执行后面的脚本，注意不作为null输入，参数将保留原有的值</span></div></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">exec <span class="string">"$&#123;SPARK_HOME&#125;"</span>/bin/spark-class org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.deploy</span><span class="selector-class">.SparkSubmit</span> <span class="string">"$@"</span></div></pre></td></tr></table></figure>
<ul>
<li>spark-class代码(配置spark任务执行环境变量，提交执行程序)：<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">. "$&#123;SPARK_HOME&#125;"/bin/load-spark-env.sh</div><div class="line">build_command() &#123;</div><div class="line">  "$RUNNER" -Xmx128m -cp "$LAUNCH_CLASSPATH" org.apache.spark.launcher.Main "$@"</div><div class="line">  printf "%d\0" $?</div><div class="line">&#125;</div><div class="line"></div><div class="line">//解析参数</div><div class="line">CMD=()</div><div class="line">while IFS= read -d '' -r ARG; do</div><div class="line">  CMD+=("$ARG")</div><div class="line">done &lt; &lt;(build_command "$@")</div><div class="line"></div><div class="line">COUNT=$&#123;#CMD[@]&#125;</div><div class="line">LAST=$((COUNT - 1))</div><div class="line">LAUNCHER_EXIT_CODE=$&#123;CMD[$LAST]&#125;</div><div class="line">if [ $LAUNCHER_EXIT_CODE != 0 ]; then</div><div class="line">  exit $LAUNCHER_EXIT_CODE</div><div class="line">fi</div><div class="line"></div><div class="line">CMD=("$&#123;CMD[@]:0:$LAST&#125;")</div><div class="line">exec "$&#123;CMD[@]&#125;"</div><div class="line"></div><div class="line">exec "$&#123;CMD[@]&#125;"，即执行java -Xmx128m -cp "$LAUNCH_CLASSPATH" org.apache.spark.deploy.SparkSubmit "$@"，最终执行代码示例：</div><div class="line">/software/servers/jdk1.7.0_67/bin/java -cp /software/servers/druid/mart_risk/hadoop/lib/native/:/software/servers/druid/mart_risk/hadoop/share/hadoop/common/lib/hadoop-lzo-0.4.20.jar:/software/conf/druid/mart_risk/bdp_jmart_risk.bdp_jmart_risk_hkh/hive_conf/:/home/mart_risk/data_dir/sjmei/plugins/spark_2.0/conf/:/home/mart_risk/data_dir/sjmei/plugins/spark_2.0/jars/*:/software/conf/druid/mart_risk/bdp_jmart_risk.bdp_jmart_risk_hkh/hadoop_conf/ -XX:MaxPermSize=256m org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode cluster --conf spark.driver.memory=10g --properties-file ./conf/spark-defaults.conf --class com.jd.risk.dm.spark.ml.alphago.GBTMLlib --name spark gbt algo for devices --num-executors 10 --executor-memory 10g --executor-cores 2 --jars ./examples/jars/scopt_2.11-3.3.0.jar --queue bdp_jmart_risk.bdp_jmart_risk_hkh ./libs/jrdm-dm-2.0-SNAPSHOT.jar hdfs://ns2/user/mart_risk/dev.db/risk_jrdm_msj_devices_training_black training</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="deploy-SparkSubmit代码："><a href="#deploy-SparkSubmit代码：" class="headerlink" title="deploy.SparkSubmit代码："></a>deploy.SparkSubmit代码：</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div><div class="line">336</div><div class="line">337</div><div class="line">338</div><div class="line">339</div><div class="line">340</div><div class="line">341</div><div class="line">342</div><div class="line">343</div><div class="line">344</div><div class="line">345</div><div class="line">346</div><div class="line">347</div><div class="line">348</div><div class="line">349</div><div class="line">350</div><div class="line">351</div><div class="line">352</div><div class="line">353</div><div class="line">354</div><div class="line">355</div><div class="line">356</div><div class="line">357</div><div class="line">358</div><div class="line">359</div><div class="line">360</div><div class="line">361</div><div class="line">362</div><div class="line">363</div><div class="line">364</div><div class="line">365</div><div class="line">366</div><div class="line">367</div><div class="line">368</div><div class="line">369</div><div class="line">370</div><div class="line">371</div><div class="line">372</div><div class="line">373</div><div class="line">374</div><div class="line">375</div><div class="line">376</div><div class="line">377</div><div class="line">378</div><div class="line">379</div><div class="line">380</div><div class="line">381</div><div class="line">382</div><div class="line">383</div><div class="line">384</div><div class="line">385</div><div class="line">386</div><div class="line">387</div><div class="line">388</div><div class="line">389</div><div class="line">390</div><div class="line">391</div><div class="line">392</div><div class="line">393</div><div class="line">394</div><div class="line">395</div><div class="line">396</div><div class="line">397</div><div class="line">398</div><div class="line">399</div><div class="line">400</div><div class="line">401</div><div class="line">402</div><div class="line">403</div><div class="line">404</div><div class="line">405</div><div class="line">406</div><div class="line">407</div><div class="line">408</div><div class="line">409</div><div class="line">410</div><div class="line">411</div><div class="line">412</div><div class="line">413</div><div class="line">414</div><div class="line">415</div><div class="line">416</div><div class="line">417</div><div class="line">418</div><div class="line">419</div><div class="line">420</div><div class="line">421</div><div class="line">422</div><div class="line">423</div><div class="line">424</div><div class="line">425</div><div class="line">426</div><div class="line">427</div><div class="line">428</div><div class="line">429</div><div class="line">430</div><div class="line">431</div><div class="line">432</div><div class="line">433</div><div class="line">434</div><div class="line">435</div><div class="line">436</div><div class="line">437</div><div class="line">438</div><div class="line">439</div><div class="line">440</div><div class="line">441</div><div class="line">442</div><div class="line">443</div><div class="line">444</div><div class="line">445</div><div class="line">446</div><div class="line">447</div><div class="line">448</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> appArgs = <span class="keyword">new</span> <span class="type">SparkSubmitArguments</span>(args)</div><div class="line">    ...</div><div class="line">    appArgs.action <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">SUBMIT</span> =&gt; submit(appArgs)</div><div class="line">      <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">KILL</span> =&gt; kill(appArgs)</div><div class="line">      <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">REQUEST_STATUS</span> =&gt; requestStatus(appArgs)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  </div><div class="line"><span class="comment">/**</span></div><div class="line">   * Submit the application using the provided parameters.</div><div class="line">   * This runs in two steps. First, we prepare the launch environment by setting up</div><div class="line">   * the appropriate classpath, system properties, and application arguments for</div><div class="line">   * running the child main class based on the cluster manager and the deploy mode.</div><div class="line">   * Second, we use this launch environment to invoke the main method of the child</div><div class="line">   * main class.</div><div class="line">   */</div><div class="line">  <span class="meta">@tailrec</span></div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submit</span></span>(args: <span class="type">SparkSubmitArguments</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> (childArgs, childClasspath, sysProps, childMainClass) = prepareSubmitEnvironment(args)</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">doRunMain</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">      <span class="keyword">if</span> (args.proxyUser != <span class="literal">null</span>) &#123;</div><div class="line">        <span class="keyword">val</span> proxyUser = <span class="type">UserGroupInformation</span>.createProxyUser(args.proxyUser,</div><div class="line">          <span class="type">UserGroupInformation</span>.getCurrentUser())</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          proxyUser.doAs(<span class="keyword">new</span> <span class="type">PrivilegedExceptionAction</span>[<span class="type">Unit</span>]() &#123;</div><div class="line">            <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">              runMain(childArgs, childClasspath, sysProps, childMainClass, args.verbose)</div><div class="line">            &#125;</div><div class="line">          &#125;)</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          ...</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        runMain(childArgs, childClasspath, sysProps, childMainClass, args.verbose)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">     <span class="comment">// In standalone cluster mode, there are two submission gateways:</span></div><div class="line">     <span class="comment">//   (1) The traditional RPC gateway using o.a.s.deploy.Client as a wrapper</span></div><div class="line">     <span class="comment">//   (2) The new REST-based gateway introduced in Spark 1.3</span></div><div class="line">     <span class="comment">// The latter is the default behavior as of Spark 1.3, but Spark submit will fail over</span></div><div class="line">     <span class="comment">// to use the legacy gateway if the master endpoint turns out to be not a REST server.</span></div><div class="line">    <span class="keyword">if</span> (args.isStandaloneCluster &amp;&amp; args.useRest) &#123;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        <span class="comment">// scalastyle:off println</span></div><div class="line">        printStream.println(<span class="string">"Running Spark using the REST application submission protocol."</span>)</div><div class="line">        <span class="comment">// scalastyle:on println</span></div><div class="line">        doRunMain()</div><div class="line">      &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          ...</div><div class="line">          args.useRest = <span class="literal">false</span></div><div class="line">          submit(args)</div><div class="line">      &#125;</div><div class="line">    <span class="comment">// In all other modes, just run the main class as prepared</span></div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      doRunMain()</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  </div><div class="line"><span class="comment">/**</span></div><div class="line">   * Prepare the environment for submitting an application.</div><div class="line">   * This returns a 4-tuple:</div><div class="line">   *   (1) the arguments for the child process,</div><div class="line">   *   (2) a list of classpath entries for the child,</div><div class="line">   *   (3) a map of system properties, and</div><div class="line">   *   (4) the main class for the child</div><div class="line">   * Exposed for testing.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span>[deploy] <span class="function"><span class="keyword">def</span> <span class="title">prepareSubmitEnvironment</span></span>(args: <span class="type">SparkSubmitArguments</span>)</div><div class="line">      : (<span class="type">Seq</span>[<span class="type">String</span>], <span class="type">Seq</span>[<span class="type">String</span>], <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>], <span class="type">String</span>) = &#123;</div><div class="line">    <span class="comment">// Return values</span></div><div class="line">    <span class="keyword">val</span> childArgs = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">String</span>]()</div><div class="line">    <span class="keyword">val</span> childClasspath = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">String</span>]()</div><div class="line">    <span class="keyword">val</span> sysProps = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">String</span>]()</div><div class="line">    <span class="keyword">var</span> childMainClass = <span class="string">""</span></div><div class="line"></div><div class="line">    <span class="comment">// Set the cluster manager</span></div><div class="line">    <span class="keyword">val</span> clusterManager: <span class="type">Int</span> = args.master <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="string">"yarn"</span> =&gt; <span class="type">YARN</span></div><div class="line">      <span class="keyword">case</span> <span class="string">"yarn-client"</span> | <span class="string">"yarn-cluster"</span> =&gt;</div><div class="line">        printWarning(<span class="string">s"Master <span class="subst">$&#123;args.master&#125;</span> is deprecated since 2.0."</span> +</div><div class="line">          <span class="string">" Please use master \"yarn\" with specified deploy mode instead."</span>)</div><div class="line">        <span class="type">YARN</span></div><div class="line">      <span class="keyword">case</span> m <span class="keyword">if</span> m.startsWith(<span class="string">"spark"</span>) =&gt; <span class="type">STANDALONE</span></div><div class="line">      <span class="keyword">case</span> m <span class="keyword">if</span> m.startsWith(<span class="string">"mesos"</span>) =&gt; <span class="type">MESOS</span></div><div class="line">      <span class="keyword">case</span> m <span class="keyword">if</span> m.startsWith(<span class="string">"local"</span>) =&gt; <span class="type">LOCAL</span></div><div class="line">      <span class="keyword">case</span> _ =&gt;</div><div class="line">        printErrorAndExit(<span class="string">"Master must either be yarn or start with spark, mesos, local"</span>)</div><div class="line">        <span class="number">-1</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Set the deploy mode; default is client mode</span></div><div class="line">    <span class="keyword">var</span> deployMode: <span class="type">Int</span> = args.deployMode <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="string">"client"</span> | <span class="literal">null</span> =&gt; <span class="type">CLIENT</span></div><div class="line">      <span class="keyword">case</span> <span class="string">"cluster"</span> =&gt; <span class="type">CLUSTER</span></div><div class="line">      <span class="keyword">case</span> _ =&gt; printErrorAndExit(<span class="string">"Deploy mode must be either client or cluster"</span>); <span class="number">-1</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Because the deprecated way of specifying "yarn-cluster" and "yarn-client" encapsulate both</span></div><div class="line">    <span class="comment">// the master and deploy mode, we have some logic to infer the master and deploy mode</span></div><div class="line">    <span class="comment">// from each other if only one is specified, or exit early if they are at odds.</span></div><div class="line">    <span class="keyword">if</span> (clusterManager == <span class="type">YARN</span>) &#123;</div><div class="line">      (args.master, args.deployMode) <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> (<span class="string">"yarn-cluster"</span>, <span class="literal">null</span>) =&gt;</div><div class="line">          deployMode = <span class="type">CLUSTER</span></div><div class="line">          args.master = <span class="string">"yarn"</span></div><div class="line">        <span class="keyword">case</span> (<span class="string">"yarn-cluster"</span>, <span class="string">"client"</span>) =&gt;</div><div class="line">          printErrorAndExit(<span class="string">"Client deploy mode is not compatible with master \"yarn-cluster\""</span>)</div><div class="line">        <span class="keyword">case</span> (<span class="string">"yarn-client"</span>, <span class="string">"cluster"</span>) =&gt;</div><div class="line">          printErrorAndExit(<span class="string">"Cluster deploy mode is not compatible with master \"yarn-client\""</span>)</div><div class="line">        <span class="keyword">case</span> (_, mode) =&gt;</div><div class="line">          args.master = <span class="string">"yarn"</span></div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// Make sure YARN is included in our build if we're trying to use it</span></div><div class="line">      <span class="keyword">if</span> (!<span class="type">Utils</span>.classIsLoadable(<span class="string">"org.apache.spark.deploy.yarn.Client"</span>) &amp;&amp; !<span class="type">Utils</span>.isTesting) &#123;</div><div class="line">        printErrorAndExit(</div><div class="line">          <span class="string">"Could not load YARN classes. "</span> +</div><div class="line">          <span class="string">"This copy of Spark may not have been compiled with YARN support."</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Update args.deployMode if it is null. It will be passed down as a Spark property later.</span></div><div class="line">    (args.deployMode, deployMode) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> (<span class="literal">null</span>, <span class="type">CLIENT</span>) =&gt; args.deployMode = <span class="string">"client"</span></div><div class="line">      <span class="keyword">case</span> (<span class="literal">null</span>, <span class="type">CLUSTER</span>) =&gt; args.deployMode = <span class="string">"cluster"</span></div><div class="line">      <span class="keyword">case</span> _ =&gt;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">val</span> isYarnCluster = clusterManager == <span class="type">YARN</span> &amp;&amp; deployMode == <span class="type">CLUSTER</span></div><div class="line">    <span class="keyword">val</span> isMesosCluster = clusterManager == <span class="type">MESOS</span> &amp;&amp; deployMode == <span class="type">CLUSTER</span></div><div class="line"></div><div class="line">    <span class="comment">// Resolve maven dependencies if there are any and add classpath to jars. Add them to py-files</span></div><div class="line">    <span class="comment">// too for packages that include Python code</span></div><div class="line">    <span class="keyword">val</span> exclusions: <span class="type">Seq</span>[<span class="type">String</span>] =</div><div class="line">      <span class="keyword">if</span> (!<span class="type">StringUtils</span>.isBlank(args.packagesExclusions)) &#123;</div><div class="line">        args.packagesExclusions.split(<span class="string">","</span>)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Nil</span></div><div class="line">      &#125;</div><div class="line">    <span class="keyword">val</span> resolvedMavenCoordinates = <span class="type">SparkSubmitUtils</span>.resolveMavenCoordinates(args.packages,</div><div class="line">      <span class="type">Option</span>(args.repositories), <span class="type">Option</span>(args.ivyRepoPath), exclusions = exclusions)</div><div class="line">    <span class="keyword">if</span> (!<span class="type">StringUtils</span>.isBlank(resolvedMavenCoordinates)) &#123;</div><div class="line">      args.jars = mergeFileLists(args.jars, resolvedMavenCoordinates)</div><div class="line">      <span class="keyword">if</span> (args.isPython) &#123;</div><div class="line">        args.pyFiles = mergeFileLists(args.pyFiles, resolvedMavenCoordinates)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// install any R packages that may have been passed through --jars or --packages.</span></div><div class="line">    <span class="comment">// Spark Packages may contain R source code inside the jar.</span></div><div class="line">    <span class="keyword">if</span> (args.isR &amp;&amp; !<span class="type">StringUtils</span>.isBlank(args.jars)) &#123;</div><div class="line">      <span class="type">RPackageUtils</span>.checkAndBuildRPackage(args.jars, printStream, args.verbose)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Require all python files to be local, so we can add them to the PYTHONPATH</span></div><div class="line">    <span class="comment">// In YARN cluster mode, python files are distributed as regular files, which can be non-local.</span></div><div class="line">    <span class="comment">// In Mesos cluster mode, non-local python files are automatically downloaded by Mesos.</span></div><div class="line">    <span class="keyword">if</span> (args.isPython &amp;&amp; !isYarnCluster &amp;&amp; !isMesosCluster) &#123;</div><div class="line">      <span class="keyword">if</span> (<span class="type">Utils</span>.nonLocalPaths(args.primaryResource).nonEmpty) &#123;</div><div class="line">        printErrorAndExit(<span class="string">s"Only local python files are supported: <span class="subst">$args</span>.primaryResource"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">val</span> nonLocalPyFiles = <span class="type">Utils</span>.nonLocalPaths(args.pyFiles).mkString(<span class="string">","</span>)</div><div class="line">      <span class="keyword">if</span> (nonLocalPyFiles.nonEmpty) &#123;</div><div class="line">        printErrorAndExit(<span class="string">s"Only local additional python files are supported: <span class="subst">$nonLocalPyFiles</span>"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Require all R files to be local</span></div><div class="line">    <span class="keyword">if</span> (args.isR &amp;&amp; !isYarnCluster) &#123;</div><div class="line">      <span class="keyword">if</span> (<span class="type">Utils</span>.nonLocalPaths(args.primaryResource).nonEmpty) &#123;</div><div class="line">        printErrorAndExit(<span class="string">s"Only local R files are supported: <span class="subst">$args</span>.primaryResource"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// The following modes are not supported or applicable</span></div><div class="line">    (clusterManager, deployMode) <span class="keyword">match</span> &#123;</div><div class="line">      ...</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// If we're running a python app, set the main class to our specific python runner</span></div><div class="line">    <span class="keyword">if</span> (args.isPython &amp;&amp; deployMode == <span class="type">CLIENT</span>) &#123;</div><div class="line">      <span class="keyword">if</span> (args.primaryResource == <span class="type">PYSPARK_SHELL</span>) &#123;</div><div class="line">        args.mainClass = <span class="string">"org.apache.spark.api.python.PythonGatewayServer"</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">// If a python file is provided, add it to the child arguments and list of files to deploy.</span></div><div class="line">        <span class="comment">// Usage: PythonAppRunner &lt;main python file&gt; &lt;extra python files&gt; [app arguments]</span></div><div class="line">        args.mainClass = <span class="string">"org.apache.spark.deploy.PythonRunner"</span></div><div class="line">        args.childArgs = <span class="type">ArrayBuffer</span>(args.primaryResource, args.pyFiles) ++ args.childArgs</div><div class="line">        <span class="keyword">if</span> (clusterManager != <span class="type">YARN</span>) &#123;</div><div class="line">          <span class="comment">// The YARN backend distributes the primary file differently, so don't merge it.</span></div><div class="line">          args.files = mergeFileLists(args.files, args.primaryResource)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (clusterManager != <span class="type">YARN</span>) &#123;</div><div class="line">        <span class="comment">// The YARN backend handles python files differently, so don't merge the lists.</span></div><div class="line">        args.files = mergeFileLists(args.files, args.pyFiles)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (args.pyFiles != <span class="literal">null</span>) &#123;</div><div class="line">        sysProps(<span class="string">"spark.submit.pyFiles"</span>) = args.pyFiles</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// In YARN mode for an R app, add the SparkR package archive and the R package</span></div><div class="line">    <span class="comment">// archive containing all of the built R libraries to archives so that they can</span></div><div class="line">    <span class="comment">// be distributed with the job</span></div><div class="line">    ...</div><div class="line">    </div><div class="line">    <span class="comment">// Special flag to avoid deprecation warnings at the client</span></div><div class="line">    sysProps(<span class="string">"SPARK_SUBMIT"</span>) = <span class="string">"true"</span></div><div class="line"></div><div class="line">    <span class="comment">// A list of rules to map each argument to system properties or command-line options in</span></div><div class="line">    <span class="comment">// each deploy mode; we iterate through these below</span></div><div class="line">    <span class="keyword">val</span> options = <span class="type">List</span>[<span class="type">OptionAssigner</span>](</div><div class="line"></div><div class="line">      <span class="comment">// All cluster managers</span></div><div class="line">      <span class="type">OptionAssigner</span>(args.master, <span class="type">ALL_CLUSTER_MGRS</span>, <span class="type">ALL_DEPLOY_MODES</span>, sysProp = <span class="string">"spark.master"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.deployMode, <span class="type">ALL_CLUSTER_MGRS</span>, <span class="type">ALL_DEPLOY_MODES</span>,</div><div class="line">        sysProp = <span class="string">"spark.submit.deployMode"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.name, <span class="type">ALL_CLUSTER_MGRS</span>, <span class="type">ALL_DEPLOY_MODES</span>, sysProp = <span class="string">"spark.app.name"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.ivyRepoPath, <span class="type">ALL_CLUSTER_MGRS</span>, <span class="type">CLIENT</span>, sysProp = <span class="string">"spark.jars.ivy"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.driverMemory, <span class="type">ALL_CLUSTER_MGRS</span>, <span class="type">CLIENT</span>,</div><div class="line">        sysProp = <span class="string">"spark.driver.memory"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.driverExtraClassPath, <span class="type">ALL_CLUSTER_MGRS</span>, <span class="type">ALL_DEPLOY_MODES</span>,</div><div class="line">        sysProp = <span class="string">"spark.driver.extraClassPath"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.driverExtraJavaOptions, <span class="type">ALL_CLUSTER_MGRS</span>, <span class="type">ALL_DEPLOY_MODES</span>,</div><div class="line">        sysProp = <span class="string">"spark.driver.extraJavaOptions"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.driverExtraLibraryPath, <span class="type">ALL_CLUSTER_MGRS</span>, <span class="type">ALL_DEPLOY_MODES</span>,</div><div class="line">        sysProp = <span class="string">"spark.driver.extraLibraryPath"</span>),</div><div class="line"></div><div class="line">      <span class="comment">// Yarn only</span></div><div class="line">      <span class="type">OptionAssigner</span>(args.queue, <span class="type">YARN</span>, <span class="type">ALL_DEPLOY_MODES</span>, sysProp = <span class="string">"spark.yarn.queue"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.numExecutors, <span class="type">YARN</span>, <span class="type">ALL_DEPLOY_MODES</span>,</div><div class="line">        sysProp = <span class="string">"spark.executor.instances"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.jars, <span class="type">YARN</span>, <span class="type">ALL_DEPLOY_MODES</span>, sysProp = <span class="string">"spark.yarn.dist.jars"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.files, <span class="type">YARN</span>, <span class="type">ALL_DEPLOY_MODES</span>, sysProp = <span class="string">"spark.yarn.dist.files"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.archives, <span class="type">YARN</span>, <span class="type">ALL_DEPLOY_MODES</span>, sysProp = <span class="string">"spark.yarn.dist.archives"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.principal, <span class="type">YARN</span>, <span class="type">ALL_DEPLOY_MODES</span>, sysProp = <span class="string">"spark.yarn.principal"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.keytab, <span class="type">YARN</span>, <span class="type">ALL_DEPLOY_MODES</span>, sysProp = <span class="string">"spark.yarn.keytab"</span>),</div><div class="line"></div><div class="line">      <span class="comment">// Other options</span></div><div class="line">      <span class="type">OptionAssigner</span>(args.executorCores, <span class="type">STANDALONE</span> | <span class="type">YARN</span>, <span class="type">ALL_DEPLOY_MODES</span>,</div><div class="line">        sysProp = <span class="string">"spark.executor.cores"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.executorMemory, <span class="type">STANDALONE</span> | <span class="type">MESOS</span> | <span class="type">YARN</span>, <span class="type">ALL_DEPLOY_MODES</span>,</div><div class="line">        sysProp = <span class="string">"spark.executor.memory"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.totalExecutorCores, <span class="type">STANDALONE</span> | <span class="type">MESOS</span>, <span class="type">ALL_DEPLOY_MODES</span>,</div><div class="line">        sysProp = <span class="string">"spark.cores.max"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.files, <span class="type">LOCAL</span> | <span class="type">STANDALONE</span> | <span class="type">MESOS</span>, <span class="type">ALL_DEPLOY_MODES</span>,</div><div class="line">        sysProp = <span class="string">"spark.files"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.jars, <span class="type">LOCAL</span>, <span class="type">CLIENT</span>, sysProp = <span class="string">"spark.jars"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.jars, <span class="type">STANDALONE</span> | <span class="type">MESOS</span>, <span class="type">ALL_DEPLOY_MODES</span>, sysProp = <span class="string">"spark.jars"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.driverMemory, <span class="type">STANDALONE</span> | <span class="type">MESOS</span> | <span class="type">YARN</span>, <span class="type">CLUSTER</span>,</div><div class="line">        sysProp = <span class="string">"spark.driver.memory"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.driverCores, <span class="type">STANDALONE</span> | <span class="type">MESOS</span> | <span class="type">YARN</span>, <span class="type">CLUSTER</span>,</div><div class="line">        sysProp = <span class="string">"spark.driver.cores"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.supervise.toString, <span class="type">STANDALONE</span> | <span class="type">MESOS</span>, <span class="type">CLUSTER</span>,</div><div class="line">        sysProp = <span class="string">"spark.driver.supervise"</span>),</div><div class="line">      <span class="type">OptionAssigner</span>(args.ivyRepoPath, <span class="type">STANDALONE</span>, <span class="type">CLUSTER</span>, sysProp = <span class="string">"spark.jars.ivy"</span>)</div><div class="line">    )</div><div class="line"></div><div class="line">    <span class="comment">// In client mode, launch the application main class directly</span></div><div class="line">    <span class="comment">// In addition, add the main application jar and any added jars (if any) to the classpath</span></div><div class="line">    <span class="keyword">if</span> (deployMode == <span class="type">CLIENT</span>) &#123;</div><div class="line">      childMainClass = args.mainClass</div><div class="line">      <span class="keyword">if</span> (isUserJar(args.primaryResource)) &#123;</div><div class="line">        childClasspath += args.primaryResource</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (args.jars != <span class="literal">null</span>) &#123; childClasspath ++= args.jars.split(<span class="string">","</span>) &#125;</div><div class="line">      <span class="keyword">if</span> (args.childArgs != <span class="literal">null</span>) &#123; childArgs ++= args.childArgs &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Map all arguments to command-line options or system properties for our chosen mode</span></div><div class="line">    <span class="keyword">for</span> (opt &lt;- options) &#123;</div><div class="line">      <span class="keyword">if</span> (opt.value != <span class="literal">null</span> &amp;&amp;</div><div class="line">          (deployMode &amp; opt.deployMode) != <span class="number">0</span> &amp;&amp;</div><div class="line">          (clusterManager &amp; opt.clusterManager) != <span class="number">0</span>) &#123;</div><div class="line">        <span class="keyword">if</span> (opt.clOption != <span class="literal">null</span>) &#123; childArgs += (opt.clOption, opt.value) &#125;</div><div class="line">        <span class="keyword">if</span> (opt.sysProp != <span class="literal">null</span>) &#123; sysProps.put(opt.sysProp, opt.value) &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Add the application jar automatically so the user doesn't have to call sc.addJar</span></div><div class="line">    <span class="comment">// For YARN cluster mode, the jar is already distributed on each node as "app.jar"</span></div><div class="line">    <span class="comment">// For python and R files, the primary resource is already distributed as a regular file</span></div><div class="line">    <span class="keyword">if</span> (!isYarnCluster &amp;&amp; !args.isPython &amp;&amp; !args.isR) &#123;</div><div class="line">      <span class="keyword">var</span> jars = sysProps.get(<span class="string">"spark.jars"</span>).map(x =&gt; x.split(<span class="string">","</span>).toSeq).getOrElse(<span class="type">Seq</span>.empty)</div><div class="line">      <span class="keyword">if</span> (isUserJar(args.primaryResource)) &#123;</div><div class="line">        jars = jars ++ <span class="type">Seq</span>(args.primaryResource)</div><div class="line">      &#125;</div><div class="line">      sysProps.put(<span class="string">"spark.jars"</span>, jars.mkString(<span class="string">","</span>))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// In standalone cluster mode, use the REST client to submit the application (Spark 1.3+).</span></div><div class="line">    <span class="comment">// All Spark parameters are expected to be passed to the client through system properties.</span></div><div class="line">    <span class="keyword">if</span> (args.isStandaloneCluster) &#123;</div><div class="line">      <span class="keyword">if</span> (args.useRest) &#123;</div><div class="line">        childMainClass = <span class="string">"org.apache.spark.deploy.rest.RestSubmissionClient"</span></div><div class="line">        childArgs += (args.primaryResource, args.mainClass)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">// In legacy standalone cluster mode, use Client as a wrapper around the user class</span></div><div class="line">        childMainClass = <span class="string">"org.apache.spark.deploy.Client"</span></div><div class="line">        <span class="keyword">if</span> (args.supervise) &#123; childArgs += <span class="string">"--supervise"</span> &#125;</div><div class="line">        <span class="type">Option</span>(args.driverMemory).foreach &#123; m =&gt; childArgs += (<span class="string">"--memory"</span>, m) &#125;</div><div class="line">        <span class="type">Option</span>(args.driverCores).foreach &#123; c =&gt; childArgs += (<span class="string">"--cores"</span>, c) &#125;</div><div class="line">        childArgs += <span class="string">"launch"</span></div><div class="line">        childArgs += (args.master, args.primaryResource, args.mainClass)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (args.childArgs != <span class="literal">null</span>) &#123;</div><div class="line">        childArgs ++= args.childArgs</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Let YARN know it's a pyspark app, so it distributes needed libraries.</span></div><div class="line">    <span class="keyword">if</span> (clusterManager == <span class="type">YARN</span>) &#123;</div><div class="line">      <span class="keyword">if</span> (args.isPython) &#123;</div><div class="line">        sysProps.put(<span class="string">"spark.yarn.isPython"</span>, <span class="string">"true"</span>)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (args.pyFiles != <span class="literal">null</span>) &#123;</div><div class="line">        sysProps(<span class="string">"spark.submit.pyFiles"</span>) = args.pyFiles</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// assure a keytab is available from any place in a JVM</span></div><div class="line">    <span class="keyword">if</span> (clusterManager == <span class="type">YARN</span> || clusterManager == <span class="type">LOCAL</span>) &#123;</div><div class="line">      <span class="keyword">if</span> (args.principal != <span class="literal">null</span>) &#123;</div><div class="line">        require(args.keytab != <span class="literal">null</span>, <span class="string">"Keytab must be specified when principal is specified"</span>)</div><div class="line">        <span class="keyword">if</span> (!<span class="keyword">new</span> <span class="type">File</span>(args.keytab).exists()) &#123;</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"Keytab file: <span class="subst">$&#123;args.keytab&#125;</span> does not exist"</span>)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          <span class="comment">// Add keytab and principal configurations in sysProps to make them available</span></div><div class="line">          <span class="comment">// for later use; e.g. in spark sql, the isolated class loader used to talk</span></div><div class="line">          <span class="comment">// to HiveMetastore will use these settings. They will be set as Java system</span></div><div class="line">          <span class="comment">// properties and then loaded by SparkConf</span></div><div class="line">          sysProps.put(<span class="string">"spark.yarn.keytab"</span>, args.keytab)</div><div class="line">          sysProps.put(<span class="string">"spark.yarn.principal"</span>, args.principal)</div><div class="line"></div><div class="line">          <span class="type">UserGroupInformation</span>.loginUserFromKeytab(args.principal, args.keytab)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// In yarn-cluster mode, use yarn.Client as a wrapper around the user class</span></div><div class="line">    <span class="keyword">if</span> (isYarnCluster) &#123;</div><div class="line">      childMainClass = <span class="string">"org.apache.spark.deploy.yarn.Client"</span></div><div class="line">      <span class="keyword">if</span> (args.isPython) &#123;</div><div class="line">        childArgs += (<span class="string">"--primary-py-file"</span>, args.primaryResource)</div><div class="line">        childArgs += (<span class="string">"--class"</span>, <span class="string">"org.apache.spark.deploy.PythonRunner"</span>)</div><div class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (args.isR) &#123;</div><div class="line">        <span class="keyword">val</span> mainFile = <span class="keyword">new</span> <span class="type">Path</span>(args.primaryResource).getName</div><div class="line">        childArgs += (<span class="string">"--primary-r-file"</span>, mainFile)</div><div class="line">        childArgs += (<span class="string">"--class"</span>, <span class="string">"org.apache.spark.deploy.RRunner"</span>)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">if</span> (args.primaryResource != <span class="type">SparkLauncher</span>.<span class="type">NO_RESOURCE</span>) &#123;</div><div class="line">          childArgs += (<span class="string">"--jar"</span>, args.primaryResource)</div><div class="line">        &#125;</div><div class="line">        childArgs += (<span class="string">"--class"</span>, args.mainClass)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (args.childArgs != <span class="literal">null</span>) &#123;</div><div class="line">        args.childArgs.foreach &#123; arg =&gt; childArgs += (<span class="string">"--arg"</span>, arg) &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (isMesosCluster) &#123;</div><div class="line">      ...</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Load any properties specified through --conf and the default properties file</span></div><div class="line">    <span class="keyword">for</span> ((k, v) &lt;- args.sparkProperties) &#123;</div><div class="line">      sysProps.getOrElseUpdate(k, v)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Ignore invalid spark.driver.host in cluster modes.</span></div><div class="line">    <span class="keyword">if</span> (deployMode == <span class="type">CLUSTER</span>) &#123;</div><div class="line">      sysProps -= <span class="string">"spark.driver.host"</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Resolve paths in certain spark properties</span></div><div class="line">    <span class="keyword">val</span> pathConfigs = <span class="type">Seq</span>(</div><div class="line">      <span class="string">"spark.jars"</span>,</div><div class="line">      <span class="string">"spark.files"</span>,</div><div class="line">      <span class="string">"spark.yarn.dist.files"</span>,</div><div class="line">      <span class="string">"spark.yarn.dist.archives"</span>,</div><div class="line">      <span class="string">"spark.yarn.dist.jars"</span>)</div><div class="line">    pathConfigs.foreach &#123; config =&gt;</div><div class="line">      <span class="comment">// Replace old URIs with resolved URIs, if they exist</span></div><div class="line">      sysProps.get(config).foreach &#123; oldValue =&gt;</div><div class="line">        sysProps(config) = <span class="type">Utils</span>.resolveURIs(oldValue)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Resolve and format python file paths properly before adding them to the PYTHONPATH.</span></div><div class="line">    <span class="comment">// The resolving part is redundant in the case of --py-files, but necessary if the user</span></div><div class="line">    <span class="comment">// explicitly sets `spark.submit.pyFiles` in his/her default properties file.</span></div><div class="line">    sysProps.get(<span class="string">"spark.submit.pyFiles"</span>).foreach &#123; pyFiles =&gt;</div><div class="line">      <span class="keyword">val</span> resolvedPyFiles = <span class="type">Utils</span>.resolveURIs(pyFiles)</div><div class="line">      <span class="keyword">val</span> formattedPyFiles = <span class="type">PythonRunner</span>.formatPaths(resolvedPyFiles).mkString(<span class="string">","</span>)</div><div class="line">      sysProps(<span class="string">"spark.submit.pyFiles"</span>) = formattedPyFiles</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    (childArgs, childClasspath, sysProps, childMainClass)</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">   * Run the main method of the child class using the provided launch environment.</div><div class="line">   * Note that this main class will not be the one provided by the user if we</div><div class="line">   * are running cluster deploy mode or python applications.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runMain</span></span>(</div><div class="line">      childArgs: <span class="type">Seq</span>[<span class="type">String</span>],</div><div class="line">      childClasspath: <span class="type">Seq</span>[<span class="type">String</span>],</div><div class="line">      sysProps: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>],</div><div class="line">      childMainClass: <span class="type">String</span>,</div><div class="line">      verbose: <span class="type">Boolean</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">if</span> (verbose) &#123;</div><div class="line">      printStream.println(<span class="string">s"Main class:\n<span class="subst">$childMainClass</span>"</span>)</div><div class="line">      printStream.println(<span class="string">s"Arguments:\n<span class="subst">$&#123;childArgs.mkString("\n")&#125;</span>"</span>)</div><div class="line">      printStream.println(<span class="string">s"System properties:\n<span class="subst">$&#123;sysProps.mkString("\n")&#125;</span>"</span>)</div><div class="line">      printStream.println(<span class="string">s"Classpath elements:\n<span class="subst">$&#123;childClasspath.mkString("\n")&#125;</span>"</span>)</div><div class="line">      printStream.println(<span class="string">"\n"</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> loader =</div><div class="line">      <span class="keyword">if</span> (sysProps.getOrElse(<span class="string">"spark.driver.userClassPathFirst"</span>, <span class="string">"false"</span>).toBoolean) &#123;</div><div class="line">        <span class="keyword">new</span> <span class="type">ChildFirstURLClassLoader</span>(<span class="keyword">new</span> <span class="type">Array</span>[<span class="type">URL</span>](<span class="number">0</span>),</div><div class="line">          <span class="type">Thread</span>.currentThread.getContextClassLoader)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">new</span> <span class="type">MutableURLClassLoader</span>(<span class="keyword">new</span> <span class="type">Array</span>[<span class="type">URL</span>](<span class="number">0</span>),</div><div class="line">          <span class="type">Thread</span>.currentThread.getContextClassLoader)</div><div class="line">      &#125;</div><div class="line">    <span class="type">Thread</span>.currentThread.setContextClassLoader(loader)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (jar &lt;- childClasspath) &#123;</div><div class="line">      addJarToClasspath(jar, loader)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> ((key, value) &lt;- sysProps) &#123;</div><div class="line">      <span class="type">System</span>.setProperty(key, value)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">var</span> mainClass: <span class="type">Class</span>[_] = <span class="literal">null</span></div><div class="line"></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      mainClass = <span class="type">Utils</span>.classForName(childMainClass)</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      ...</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<h2 id="deploy-yarn-Client代码："><a href="#deploy-yarn-Client代码：" class="headerlink" title="deploy.yarn.Client代码："></a>deploy.yarn.Client代码：</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(argStrings: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">    <span class="keyword">if</span> (!sys.props.contains(<span class="string">"SPARK_SUBMIT"</span>)) &#123;</div><div class="line">      logWarning(<span class="string">"WARNING: This client is deprecated and will be removed in a "</span> +</div><div class="line">        <span class="string">"future version of Spark. Use ./bin/spark-submit with \"--master yarn\""</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Set an env variable indicating we are running in YARN mode.</span></div><div class="line">    <span class="comment">// Note that any env variable with the SPARK_ prefix gets propagated to all (remote) processes</span></div><div class="line">    <span class="type">System</span>.setProperty(<span class="string">"SPARK_YARN_MODE"</span>, <span class="string">"true"</span>)</div><div class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span></div><div class="line"></div><div class="line">    <span class="keyword">val</span> args = <span class="keyword">new</span> <span class="type">ClientArguments</span>(argStrings)</div><div class="line">    <span class="keyword">new</span> <span class="type">Client</span>(args, sparkConf).run()</div><div class="line">  &#125;</div><div class="line">  </div><div class="line"><span class="comment">/**</span></div><div class="line">   * Submit an application to the ResourceManager.</div><div class="line">   * If set spark.yarn.submit.waitAppCompletion to true, it will stay alive</div><div class="line">   * reporting the application's status until the application has exited for any reason.</div><div class="line">   * Otherwise, the client process will exit after submission.</div><div class="line">   * If the application finishes with a failed, killed, or undefined status,</div><div class="line">   * throw an appropriate SparkException.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">this</span>.appId = submitApplication()</div><div class="line">    <span class="keyword">if</span> (!launcherBackend.isConnected() &amp;&amp; fireAndForget) &#123;</div><div class="line">      <span class="keyword">val</span> report = getApplicationReport(appId)<span class="comment">//ApplicationReport是应用程序的报告（包括程序用户、程序队列、程序名称等等）</span></div><div class="line">      <span class="keyword">val</span> state = report.getYarnApplicationState<span class="comment">//得到应用程序的完成状态</span></div><div class="line">      logInfo(<span class="string">s"Application report for <span class="subst">$appId</span> (state: <span class="subst">$state</span>)"</span>)</div><div class="line">      logInfo(formatReportDetails(report))</div><div class="line">      <span class="keyword">if</span> (state == <span class="type">YarnApplicationState</span>.<span class="type">FAILED</span> || state == <span class="type">YarnApplicationState</span>.<span class="type">KILLED</span>) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"Application <span class="subst">$appId</span> finished with status: <span class="subst">$state</span>"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">//涉及两个对象YarnApplicationState（对于yarn来说任务的状态）、FinalApplicationStatus（对于任务来说任务的运行状态）</span></div><div class="line">      <span class="keyword">val</span> (yarnApplicationState, finalApplicationStatus) = monitorApplication(appId)</div><div class="line">      <span class="keyword">if</span> (yarnApplicationState == <span class="type">YarnApplicationState</span>.<span class="type">FAILED</span> ||</div><div class="line">        finalApplicationStatus == <span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"Application <span class="subst">$appId</span> finished with failed status"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (yarnApplicationState == <span class="type">YarnApplicationState</span>.<span class="type">KILLED</span> ||</div><div class="line">        finalApplicationStatus == <span class="type">FinalApplicationStatus</span>.<span class="type">KILLED</span>) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"Application <span class="subst">$appId</span> is killed"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (finalApplicationStatus == <span class="type">FinalApplicationStatus</span>.<span class="type">UNDEFINED</span>) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"The final status of application <span class="subst">$appId</span> is undefined"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  </div><div class="line"> <span class="comment">/**</span></div><div class="line">   * Submit an application running our ApplicationMaster to the ResourceManager.</div><div class="line">   * The stable Yarn API provides a convenience method (YarnClient#createApplication) for</div><div class="line">   * creating applications and setting up the application submission context. This was not</div><div class="line">   * available in the alpha API.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">submitApplication</span></span>(): <span class="type">ApplicationId</span> = &#123;</div><div class="line">    <span class="keyword">var</span> appId: <span class="type">ApplicationId</span> = <span class="literal">null</span></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      launcherBackend.connect()</div><div class="line">      <span class="comment">// Setup the credentials before doing anything else,</span></div><div class="line">      <span class="comment">// so we have don't have issues at any point.</span></div><div class="line">      setupCredentials()</div><div class="line">      yarnClient.init(yarnConf)</div><div class="line">      yarnClient.start()</div><div class="line"></div><div class="line">      logInfo(<span class="string">"Requesting a new application from cluster with %d NodeManagers"</span></div><div class="line">        .format(yarnClient.getYarnClusterMetrics.getNumNodeManagers))</div><div class="line"></div><div class="line">      <span class="comment">// Get a new application from our RM</span></div><div class="line">      <span class="keyword">val</span> newApp = yarnClient.createApplication()<span class="comment">// 构建ApplicationMaster的container(包括jar包路径 userClas等)</span></div><div class="line">      <span class="keyword">val</span> newAppResponse = newApp.getNewApplicationResponse()</div><div class="line">      appId = newAppResponse.getApplicationId()</div><div class="line">      reportLauncherState(<span class="type">SparkAppHandle</span>.<span class="type">State</span>.<span class="type">SUBMITTED</span>)</div><div class="line">      launcherBackend.setAppId(appId.toString)</div><div class="line"></div><div class="line">      <span class="comment">// Verify whether the cluster has enough resources for our AM</span></div><div class="line">      verifyClusterResources(newAppResponse)</div><div class="line"></div><div class="line">      <span class="comment">// Set up the appropriate contexts to launch our AM</span></div><div class="line">      <span class="keyword">val</span> containerContext = createContainerLaunchContext(newAppResponse)</div><div class="line">      <span class="keyword">val</span> appContext = createApplicationSubmissionContext(newApp, containerContext)</div><div class="line"></div><div class="line">      <span class="comment">// Finally, submit and monitor the application</span></div><div class="line">      logInfo(<span class="string">s"Submitting application <span class="subst">$appId</span> to ResourceManager"</span>)</div><div class="line">      yarnClient.submitApplication(appContext)</div><div class="line">      appId</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      ...</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">   * Set up a ContainerLaunchContext to launch our ApplicationMaster container.</div><div class="line">   * This sets up the launch environment, java options, and the command for launching the AM.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createContainerLaunchContext</span></span>(newAppResponse: <span class="type">GetNewApplicationResponse</span>)</div><div class="line">    : <span class="type">ContainerLaunchContext</span> = &#123;</div><div class="line">    logInfo(<span class="string">"Setting up container launch context for our AM"</span>)</div><div class="line">    <span class="keyword">val</span> appId = newAppResponse.getApplicationId</div><div class="line">    <span class="keyword">val</span> appStagingDirPath = <span class="keyword">new</span> <span class="type">Path</span>(appStagingBaseDir, getAppStagingDir(appId))</div><div class="line">    <span class="keyword">val</span> pySparkArchives =</div><div class="line">      <span class="keyword">if</span> (sparkConf.get(<span class="type">IS_PYTHON_APP</span>)) &#123;</div><div class="line">        findPySparkArchives()</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Nil</span></div><div class="line">      &#125;</div><div class="line">    <span class="keyword">val</span> launchEnv = setupLaunchEnv(appStagingDirPath, pySparkArchives)</div><div class="line">    <span class="keyword">val</span> localResources = prepareLocalResources(appStagingDirPath, pySparkArchives)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> amContainer = <span class="type">Records</span>.newRecord(classOf[<span class="type">ContainerLaunchContext</span>])</div><div class="line">    amContainer.setLocalResources(localResources.asJava)</div><div class="line">    amContainer.setEnvironment(launchEnv.asJava)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> javaOpts = <span class="type">ListBuffer</span>[<span class="type">String</span>]()</div><div class="line"></div><div class="line">    <span class="comment">// Set the environment variable through a command prefix</span></div><div class="line">    <span class="comment">// to append to the existing value of the variable</span></div><div class="line">    <span class="keyword">var</span> prefixEnv: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span></div><div class="line"></div><div class="line">    <span class="comment">// Add Xmx for AM memory</span></div><div class="line">    javaOpts += <span class="string">"-Xmx"</span> + amMemory + <span class="string">"m"</span></div><div class="line"></div><div class="line">    <span class="keyword">val</span> tmpDir = <span class="keyword">new</span> <span class="type">Path</span>(</div><div class="line">      <span class="type">YarnSparkHadoopUtil</span>.expandEnvironment(<span class="type">Environment</span>.<span class="type">PWD</span>),</div><div class="line">      <span class="type">YarnConfiguration</span>.<span class="type">DEFAULT_CONTAINER_TEMP_DIR</span></div><div class="line">    )</div><div class="line">    javaOpts += <span class="string">"-Djava.io.tmpdir="</span> + tmpDir</div><div class="line"></div><div class="line">    <span class="comment">// <span class="doctag">TODO:</span> Remove once cpuset version is pushed out.</span></div><div class="line">    <span class="comment">// The context is, default gc for server class machines ends up using all cores to do gc -</span></div><div class="line">    <span class="comment">// hence if there are multiple containers in same node, Spark GC affects all other containers'</span></div><div class="line">    <span class="comment">// performance (which can be that of other Spark containers)</span></div><div class="line">    <span class="comment">// Instead of using this, rely on cpusets by YARN to enforce "proper" Spark behavior in</span></div><div class="line">    <span class="comment">// multi-tenant environments. Not sure how default Java GC behaves if it is limited to subset</span></div><div class="line">    <span class="comment">// of cores on a node.</span></div><div class="line">    <span class="keyword">val</span> useConcurrentAndIncrementalGC = launchEnv.get(<span class="string">"SPARK_USE_CONC_INCR_GC"</span>).exists(_.toBoolean)</div><div class="line">    <span class="keyword">if</span> (useConcurrentAndIncrementalGC) &#123;</div><div class="line">      <span class="comment">// In our expts, using (default) throughput collector has severe perf ramifications in</span></div><div class="line">      <span class="comment">// multi-tenant machines</span></div><div class="line">      javaOpts += <span class="string">"-XX:+UseConcMarkSweepGC"</span></div><div class="line">      javaOpts += <span class="string">"-XX:MaxTenuringThreshold=31"</span></div><div class="line">      javaOpts += <span class="string">"-XX:SurvivorRatio=8"</span></div><div class="line">      javaOpts += <span class="string">"-XX:+CMSIncrementalMode"</span></div><div class="line">      javaOpts += <span class="string">"-XX:+CMSIncrementalPacing"</span></div><div class="line">      javaOpts += <span class="string">"-XX:CMSIncrementalDutyCycleMin=0"</span></div><div class="line">      javaOpts += <span class="string">"-XX:CMSIncrementalDutyCycle=10"</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Include driver-specific java options if we are launching a driver</span></div><div class="line">    <span class="keyword">if</span> (isClusterMode) &#123;</div><div class="line">      <span class="keyword">val</span> driverOpts = sparkConf.get(<span class="type">DRIVER_JAVA_OPTIONS</span>).orElse(sys.env.get(<span class="string">"SPARK_JAVA_OPTS"</span>))</div><div class="line">      driverOpts.foreach &#123; opts =&gt;</div><div class="line">        javaOpts ++= <span class="type">Utils</span>.splitCommandString(opts).map(<span class="type">YarnSparkHadoopUtil</span>.escapeForShell)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">val</span> libraryPaths = <span class="type">Seq</span>(sparkConf.get(<span class="type">DRIVER_LIBRARY_PATH</span>),</div><div class="line">        sys.props.get(<span class="string">"spark.driver.libraryPath"</span>)).flatten</div><div class="line">      <span class="keyword">if</span> (libraryPaths.nonEmpty) &#123;</div><div class="line">        prefixEnv = <span class="type">Some</span>(getClusterPath(sparkConf, <span class="type">Utils</span>.libraryPathEnvPrefix(libraryPaths)))</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (sparkConf.get(<span class="type">AM_JAVA_OPTIONS</span>).isDefined) &#123;</div><div class="line">        logWarning(<span class="string">s"<span class="subst">$&#123;AM_JAVA_OPTIONS.key&#125;</span> will not take effect in cluster mode"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// Validate and include yarn am specific java options in yarn-client mode.</span></div><div class="line">      sparkConf.get(<span class="type">AM_JAVA_OPTIONS</span>).foreach &#123; opts =&gt;</div><div class="line">        <span class="keyword">if</span> (opts.contains(<span class="string">"-Dspark"</span>)) &#123;</div><div class="line">          <span class="keyword">val</span> msg = <span class="string">s"<span class="subst">$&#123;AM_JAVA_OPTIONS.key&#125;</span> is not allowed to set Spark options (was '<span class="subst">$opts</span>')."</span></div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(msg)</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (opts.contains(<span class="string">"-Xmx"</span>)) &#123;</div><div class="line">          <span class="keyword">val</span> msg = <span class="string">s"<span class="subst">$&#123;AM_JAVA_OPTIONS.key&#125;</span> is not allowed to specify max heap memory settings "</span> +</div><div class="line">            <span class="string">s"(was '<span class="subst">$opts</span>'). Use spark.yarn.am.memory instead."</span></div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(msg)</div><div class="line">        &#125;</div><div class="line">        javaOpts ++= <span class="type">Utils</span>.splitCommandString(opts).map(<span class="type">YarnSparkHadoopUtil</span>.escapeForShell)</div><div class="line">      &#125;</div><div class="line">      sparkConf.get(<span class="type">AM_LIBRARY_PATH</span>).foreach &#123; paths =&gt;</div><div class="line">        prefixEnv = <span class="type">Some</span>(getClusterPath(sparkConf, <span class="type">Utils</span>.libraryPathEnvPrefix(<span class="type">Seq</span>(paths))))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// For log4j configuration to reference</span></div><div class="line">    javaOpts += (<span class="string">"-Dspark.yarn.app.container.log.dir="</span> + <span class="type">ApplicationConstants</span>.<span class="type">LOG_DIR_EXPANSION_VAR</span>)</div><div class="line">    <span class="type">YarnCommandBuilderUtils</span>.addPermGenSizeOpt(javaOpts)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> userClass =</div><div class="line">      <span class="keyword">if</span> (isClusterMode) &#123;</div><div class="line">        <span class="type">Seq</span>(<span class="string">"--class"</span>, <span class="type">YarnSparkHadoopUtil</span>.escapeForShell(args.userClass))</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Nil</span></div><div class="line">      &#125;</div><div class="line">    <span class="keyword">val</span> userJar =</div><div class="line">      <span class="keyword">if</span> (args.userJar != <span class="literal">null</span>) &#123;</div><div class="line">        <span class="type">Seq</span>(<span class="string">"--jar"</span>, args.userJar)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Nil</span></div><div class="line">      &#125;</div><div class="line">    <span class="keyword">val</span> primaryPyFile =</div><div class="line">      <span class="keyword">if</span> (isClusterMode &amp;&amp; args.primaryPyFile != <span class="literal">null</span>) &#123;</div><div class="line">        <span class="type">Seq</span>(<span class="string">"--primary-py-file"</span>, <span class="keyword">new</span> <span class="type">Path</span>(args.primaryPyFile).getName())</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Nil</span></div><div class="line">      &#125;</div><div class="line">    <span class="keyword">val</span> primaryRFile =</div><div class="line">      <span class="keyword">if</span> (args.primaryRFile != <span class="literal">null</span>) &#123;</div><div class="line">        <span class="type">Seq</span>(<span class="string">"--primary-r-file"</span>, args.primaryRFile)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Nil</span></div><div class="line">      &#125;</div><div class="line">    <span class="keyword">val</span> amClass =</div><div class="line">      <span class="keyword">if</span> (isClusterMode) &#123;</div><div class="line">        <span class="type">Utils</span>.classForName(<span class="string">"org.apache.spark.deploy.yarn.ApplicationMaster"</span>).getName</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Utils</span>.classForName(<span class="string">"org.apache.spark.deploy.yarn.ExecutorLauncher"</span>).getName</div><div class="line">      &#125;</div><div class="line">    <span class="keyword">if</span> (args.primaryRFile != <span class="literal">null</span> &amp;&amp; args.primaryRFile.endsWith(<span class="string">".R"</span>)) &#123;</div><div class="line">      args.userArgs = <span class="type">ArrayBuffer</span>(args.primaryRFile) ++ args.userArgs</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">val</span> userArgs = args.userArgs.flatMap &#123; arg =&gt;</div><div class="line">      <span class="type">Seq</span>(<span class="string">"--arg"</span>, <span class="type">YarnSparkHadoopUtil</span>.escapeForShell(arg))</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">val</span> amArgs =</div><div class="line">      <span class="type">Seq</span>(amClass) ++ userClass ++ userJar ++ primaryPyFile ++ primaryRFile ++</div><div class="line">        userArgs ++ <span class="type">Seq</span>(</div><div class="line">          <span class="string">"--properties-file"</span>, buildPath(<span class="type">YarnSparkHadoopUtil</span>.expandEnvironment(<span class="type">Environment</span>.<span class="type">PWD</span>),</div><div class="line">            <span class="type">LOCALIZED_CONF_DIR</span>, <span class="type">SPARK_CONF_FILE</span>))</div><div class="line"></div><div class="line">    <span class="comment">// Command for the ApplicationMaster</span></div><div class="line">    <span class="keyword">val</span> commands = prefixEnv ++ <span class="type">Seq</span>(</div><div class="line">        <span class="type">YarnSparkHadoopUtil</span>.expandEnvironment(<span class="type">Environment</span>.<span class="type">JAVA_HOME</span>) + <span class="string">"/bin/java"</span>, <span class="string">"-server"</span></div><div class="line">      ) ++</div><div class="line">      javaOpts ++ amArgs ++</div><div class="line">      <span class="type">Seq</span>(</div><div class="line">        <span class="string">"1&gt;"</span>, <span class="type">ApplicationConstants</span>.<span class="type">LOG_DIR_EXPANSION_VAR</span> + <span class="string">"/stdout"</span>,</div><div class="line">        <span class="string">"2&gt;"</span>, <span class="type">ApplicationConstants</span>.<span class="type">LOG_DIR_EXPANSION_VAR</span> + <span class="string">"/stderr"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// <span class="doctag">TODO:</span> it would be nicer to just make sure there are no null commands here</span></div><div class="line">    <span class="keyword">val</span> printableCommands = commands.map(s =&gt; <span class="keyword">if</span> (s == <span class="literal">null</span>) <span class="string">"null"</span> <span class="keyword">else</span> s).toList</div><div class="line">    amContainer.setCommands(printableCommands.asJava)</div><div class="line">    ...</div><div class="line">    <span class="comment">// send the acl settings into YARN to control who has access via YARN interfaces</span></div><div class="line">    <span class="keyword">val</span> securityManager = <span class="keyword">new</span> <span class="type">SecurityManager</span>(sparkConf)</div><div class="line">    amContainer.setApplicationACLs(</div><div class="line">      <span class="type">YarnSparkHadoopUtil</span>.getApplicationAclsForYarn(securityManager).asJava)</div><div class="line">    setupSecurityToken(amContainer)</div><div class="line"></div><div class="line">    amContainer</div><div class="line">  &#125;</div><div class="line">  </div><div class="line"><span class="comment">/**</span></div><div class="line">   * Set up the context for submitting our ApplicationMaster.</div><div class="line">   * This uses the YarnClientApplication not available in the Yarn alpha API.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createApplicationSubmissionContext</span></span>(</div><div class="line">      newApp: <span class="type">YarnClientApplication</span>,</div><div class="line">      containerContext: <span class="type">ContainerLaunchContext</span>): <span class="type">ApplicationSubmissionContext</span> = &#123;</div><div class="line">    <span class="keyword">val</span> appContext = newApp.getApplicationSubmissionContext</div><div class="line">    appContext.setApplicationName(sparkConf.get(<span class="string">"spark.app.name"</span>, <span class="string">"Spark"</span>))</div><div class="line">    appContext.setQueue(sparkConf.get(<span class="type">QUEUE_NAME</span>))</div><div class="line">    appContext.setAMContainerSpec(containerContext)</div><div class="line">    appContext.setApplicationType(<span class="string">"SPARK"</span>)</div><div class="line"></div><div class="line">    sparkConf.get(<span class="type">APPLICATION_TAGS</span>).foreach &#123; tags =&gt;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        <span class="comment">// The setApplicationTags method was only introduced in Hadoop 2.4+, so we need to use</span></div><div class="line">        <span class="comment">// reflection to set it, printing a warning if a tag was specified but the YARN version</span></div><div class="line">        <span class="comment">// doesn't support it.</span></div><div class="line">        <span class="keyword">val</span> method = appContext.getClass().getMethod(</div><div class="line">          <span class="string">"setApplicationTags"</span>, classOf[java.util.<span class="type">Set</span>[<span class="type">String</span>]])</div><div class="line">        method.invoke(appContext, <span class="keyword">new</span> java.util.<span class="type">HashSet</span>[<span class="type">String</span>](tags.asJava))</div><div class="line">      &#125; <span class="keyword">catch</span> &#123;</div><div class="line">        ...</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    sparkConf.get(<span class="type">MAX_APP_ATTEMPTS</span>) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(v) =&gt; appContext.setMaxAppAttempts(v)</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; logDebug(<span class="string">s"<span class="subst">$&#123;MAX_APP_ATTEMPTS.key&#125;</span> is not set. "</span> +</div><div class="line">          <span class="string">"Cluster's default value will be used."</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    sparkConf.get(<span class="type">AM_ATTEMPT_FAILURE_VALIDITY_INTERVAL_MS</span>).foreach &#123; interval =&gt;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">val</span> method = appContext.getClass().getMethod(</div><div class="line">          <span class="string">"setAttemptFailuresValidityInterval"</span>, classOf[<span class="type">Long</span>])</div><div class="line">        method.invoke(appContext, interval: java.lang.<span class="type">Long</span>)</div><div class="line">      &#125; <span class="keyword">catch</span> &#123;</div><div class="line">        ...</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> capability = <span class="type">Records</span>.newRecord(classOf[<span class="type">Resource</span>])</div><div class="line">    capability.setMemory(amMemory + amMemoryOverhead)</div><div class="line">    capability.setVirtualCores(amCores)</div><div class="line"></div><div class="line">    sparkConf.get(<span class="type">AM_NODE_LABEL_EXPRESSION</span>) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(expr) =&gt;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          <span class="keyword">val</span> amRequest = <span class="type">Records</span>.newRecord(classOf[<span class="type">ResourceRequest</span>])</div><div class="line">          amRequest.setResourceName(<span class="type">ResourceRequest</span>.<span class="type">ANY</span>)</div><div class="line">          amRequest.setPriority(<span class="type">Priority</span>.newInstance(<span class="number">0</span>))</div><div class="line">          amRequest.setCapability(capability)</div><div class="line">          amRequest.setNumContainers(<span class="number">1</span>)</div><div class="line">          <span class="keyword">val</span> method = amRequest.getClass.getMethod(<span class="string">"setNodeLabelExpression"</span>, classOf[<span class="type">String</span>])</div><div class="line">          method.invoke(amRequest, expr)</div><div class="line"></div><div class="line">          <span class="keyword">val</span> setResourceRequestMethod =</div><div class="line">            appContext.getClass.getMethod(<span class="string">"setAMContainerResourceRequest"</span>, classOf[<span class="type">ResourceRequest</span>])</div><div class="line">          setResourceRequestMethod.invoke(appContext, amRequest)</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          ...</div><div class="line">        &#125;</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        appContext.setResource(capability)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    appContext</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h2 id="yarn-client-api-impl-YarnClientImpl代码："><a href="#yarn-client-api-impl-YarnClientImpl代码：" class="headerlink" title="yarn.client.api.impl.YarnClientImpl代码："></a>yarn.client.api.impl.YarnClientImpl代码：</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div></pre></td><td class="code"><pre><div class="line">public <span class="type">YarnClientApplication</span> createApplication() <span class="keyword">throws</span> <span class="type">YarnException</span>, <span class="type">IOException</span> &#123;</div><div class="line">        <span class="type">ApplicationSubmissionContext</span> context = (<span class="type">ApplicationSubmissionContext</span>)<span class="type">Records</span>.newRecord(<span class="type">ApplicationSubmissionContext</span>.<span class="keyword">class</span>);</div><div class="line">        <span class="type">GetNewApplicationResponse</span> newApp = <span class="keyword">this</span>.getNewApplication();</div><div class="line">        <span class="type">ApplicationId</span> appId = newApp.getApplicationId();</div><div class="line">        context.setApplicationId(appId);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">YarnClientApplication</span>(newApp, context);</div><div class="line">    &#125;</div><div class="line"></div><div class="line"><span class="type">ApplicationId</span> getNewApplicationId() &#123;</div><div class="line">        <span class="type">ApplicationId</span> applicationId = <span class="type">BuilderUtils</span>.newApplicationId(<span class="keyword">this</span>.recordFactory, <span class="type">ResourceManager</span>.getClusterTimeStamp(), <span class="keyword">this</span>.applicationCounter.incrementAndGet());</div><div class="line">        <span class="type">LOG</span>.info(<span class="string">"Allocated new applicationId: "</span> + applicationId.getId());</div><div class="line">        <span class="keyword">return</span> applicationId;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">public <span class="type">ApplicationId</span> submitApplication(<span class="type">ApplicationSubmissionContext</span> appContext) <span class="keyword">throws</span> <span class="type">YarnException</span>, <span class="type">IOException</span> &#123;</div><div class="line">        <span class="type">ApplicationId</span> applicationId = appContext.getApplicationId();</div><div class="line">        <span class="keyword">if</span>(applicationId == <span class="literal">null</span>) &#123;</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ApplicationIdNotProvidedException</span>(<span class="string">"ApplicationId is not provided in ApplicationSubmissionContext"</span>);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="type">SubmitApplicationRequest</span> request = (<span class="type">SubmitApplicationRequest</span>)<span class="type">Records</span>.newRecord(<span class="type">SubmitApplicationRequest</span>.<span class="keyword">class</span>);</div><div class="line">            request.setApplicationSubmissionContext(appContext);</div><div class="line">            <span class="keyword">if</span>(<span class="keyword">this</span>.isSecurityEnabled() &amp;&amp; <span class="keyword">this</span>.timelineServiceEnabled) &#123;</div><div class="line">                <span class="keyword">this</span>.addTimelineDelegationToken(appContext.getAMContainerSpec());</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="keyword">this</span>.rmClient.submitApplication(request);</div><div class="line">            int pollCount = <span class="number">0</span>;</div><div class="line">            long startTime = <span class="type">System</span>.currentTimeMillis();</div><div class="line">            <span class="type">EnumSet</span> waitingStates = <span class="type">EnumSet</span>.of(<span class="type">YarnApplicationState</span>.<span class="type">NEW</span>, <span class="type">YarnApplicationState</span>.<span class="type">NEW_SAVING</span>, <span class="type">YarnApplicationState</span>.<span class="type">SUBMITTED</span>);</div><div class="line">            <span class="type">EnumSet</span> failToSubmitStates = <span class="type">EnumSet</span>.of(<span class="type">YarnApplicationState</span>.<span class="type">FAILED</span>, <span class="type">YarnApplicationState</span>.<span class="type">KILLED</span>);</div><div class="line"></div><div class="line">            <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</div><div class="line">                <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</div><div class="line">                    <span class="keyword">try</span> &#123;</div><div class="line">                        <span class="type">ApplicationReport</span> ex = <span class="keyword">this</span>.getApplicationReport(applicationId);</div><div class="line">                        <span class="type">YarnApplicationState</span> state = ex.getYarnApplicationState();</div><div class="line">                        <span class="keyword">if</span>(!waitingStates.contains(state)) &#123;</div><div class="line">                            <span class="keyword">if</span>(failToSubmitStates.contains(state)) &#123;</div><div class="line">                                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">YarnException</span>(<span class="string">"Failed to submit "</span> + applicationId + <span class="string">" to YARN : "</span> + ex.getDiagnostics());</div><div class="line">                            &#125;</div><div class="line"></div><div class="line">                            <span class="type">LOG</span>.info(<span class="string">"Submitted application "</span> + applicationId);</div><div class="line">                            <span class="keyword">return</span> applicationId;</div><div class="line">                        &#125;</div><div class="line"></div><div class="line">                        long elapsedMillis = <span class="type">System</span>.currentTimeMillis() - startTime;</div><div class="line">                        <span class="keyword">if</span>(<span class="keyword">this</span>.enforceAsyncAPITimeout() &amp;&amp; elapsedMillis &gt;= <span class="keyword">this</span>.asyncApiPollTimeoutMillis) &#123;</div><div class="line">                            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">YarnException</span>(<span class="string">"Timed out while waiting for application "</span> + applicationId + <span class="string">" to be submitted successfully"</span>);</div><div class="line">                        &#125;</div><div class="line"></div><div class="line">                        ++pollCount;</div><div class="line">                        <span class="keyword">if</span>(pollCount % <span class="number">10</span> == <span class="number">0</span>) &#123;</div><div class="line">                            <span class="type">LOG</span>.info(<span class="string">"Application submission is not finished, submitted application "</span> + applicationId + <span class="string">" is still in "</span> + state);</div><div class="line">                        &#125;</div><div class="line"></div><div class="line">                        <span class="keyword">try</span> &#123;</div><div class="line">                            <span class="type">Thread</span>.sleep(<span class="keyword">this</span>.submitPollIntervalMillis);</div><div class="line">                        &#125; <span class="keyword">catch</span> (<span class="type">InterruptedException</span> var14) &#123;</div><div class="line">                            <span class="type">LOG</span>.error(<span class="string">"Interrupted while waiting for application "</span> + applicationId + <span class="string">" to be successfully submitted."</span>);</div><div class="line">                        &#125;</div><div class="line">                    &#125; <span class="keyword">catch</span> (<span class="type">ApplicationNotFoundException</span> var15) &#123;</div><div class="line">                        <span class="type">LOG</span>.info(<span class="string">"Re-submit application "</span> + applicationId + <span class="string">"with the "</span> + <span class="string">"same ApplicationSubmissionContext"</span>);</div><div class="line">                        <span class="keyword">this</span>.rmClient.submitApplication(request);</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">public <span class="type">SubmitApplicationResponse</span> submitApplication(<span class="type">SubmitApplicationRequest</span> request) <span class="keyword">throws</span> <span class="type">YarnException</span> &#123;</div><div class="line">        <span class="type">ApplicationSubmissionContext</span> submissionContext = request.getApplicationSubmissionContext();</div><div class="line">        <span class="type">ApplicationId</span> applicationId = submissionContext.getApplicationId();</div><div class="line">        <span class="type">String</span> user = <span class="literal">null</span>;</div><div class="line"></div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            user = <span class="type">UserGroupInformation</span>.getCurrentUser().getShortUserName();</div><div class="line">        &#125; <span class="keyword">catch</span> (<span class="type">IOException</span> var7) &#123;</div><div class="line">            <span class="type">LOG</span>.warn(<span class="string">"Unable to get the current user."</span>, var7);</div><div class="line">            <span class="type">RMAuditLogger</span>.logFailure(user, <span class="string">"Submit Application Request"</span>, var7.getMessage(), <span class="string">"ClientRMService"</span>, <span class="string">"Exception in submitting application"</span>, applicationId);</div><div class="line">            <span class="keyword">throw</span> <span class="type">RPCUtil</span>.getRemoteException(var7);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span>(<span class="keyword">this</span>.rmContext.getRMApps().get(applicationId) != <span class="literal">null</span>) &#123;</div><div class="line">            <span class="type">LOG</span>.info(<span class="string">"This is an earlier submitted application: "</span> + applicationId);</div><div class="line">            <span class="keyword">return</span> <span class="type">SubmitApplicationResponse</span>.newInstance();</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">if</span>(submissionContext.getQueue() == <span class="literal">null</span>) &#123;</div><div class="line">                submissionContext.setQueue(<span class="string">"default"</span>);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="keyword">if</span>(submissionContext.getApplicationName() == <span class="literal">null</span>) &#123;</div><div class="line">                submissionContext.setApplicationName(<span class="string">"N/A"</span>);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="keyword">if</span>(submissionContext.getApplicationType() == <span class="literal">null</span>) &#123;</div><div class="line">                submissionContext.setApplicationType(<span class="string">"YARN"</span>);</div><div class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span>(submissionContext.getApplicationType().length() &gt; <span class="number">20</span>) &#123;</div><div class="line">                submissionContext.setApplicationType(submissionContext.getApplicationType().substring(<span class="number">0</span>, <span class="number">20</span>));</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                <span class="keyword">this</span>.rmAppManager.submitApplication(submissionContext, <span class="type">System</span>.currentTimeMillis(), user);</div><div class="line">                <span class="type">LOG</span>.info(<span class="string">"Application with id "</span> + applicationId.getId() + <span class="string">" submitted by user "</span> + user);</div><div class="line">                <span class="type">RMAuditLogger</span>.logSuccess(user, <span class="string">"Submit Application Request"</span>, <span class="string">"ClientRMService"</span>, applicationId);</div><div class="line">            &#125; <span class="keyword">catch</span> (<span class="type">YarnException</span> var6) &#123;</div><div class="line">                <span class="type">LOG</span>.info(<span class="string">"Exception in submitting application with id "</span> + applicationId.getId(), var6);</div><div class="line">                <span class="type">RMAuditLogger</span>.logFailure(user, <span class="string">"Submit Application Request"</span>, var6.getMessage(), <span class="string">"ClientRMService"</span>, <span class="string">"Exception in submitting application"</span>, applicationId);</div><div class="line">                <span class="keyword">throw</span> var6;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="type">SubmitApplicationResponse</span> response = (<span class="type">SubmitApplicationResponse</span>)<span class="keyword">this</span>.recordFactory.newRecordInstance(<span class="type">SubmitApplicationResponse</span>.<span class="keyword">class</span>);</div><div class="line">            <span class="keyword">return</span> response;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line"><span class="keyword">protected</span> void submitApplication(<span class="type">ApplicationSubmissionContext</span> submissionContext, long submitTime, <span class="type">String</span> user) <span class="keyword">throws</span> <span class="type">YarnException</span> &#123;</div><div class="line">        <span class="type">ApplicationId</span> applicationId = submissionContext.getApplicationId();</div><div class="line">        <span class="type">RMAppImpl</span> application = <span class="keyword">this</span>.createAndPopulateNewRMApp(submissionContext, submitTime, user, <span class="literal">false</span>);</div><div class="line">        <span class="type">ApplicationId</span> appId = submissionContext.getApplicationId();</div><div class="line">        <span class="keyword">if</span>(<span class="type">UserGroupInformation</span>.isSecurityEnabled()) &#123;</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                <span class="keyword">this</span>.rmContext.getDelegationTokenRenewer().addApplicationAsync(appId, <span class="keyword">this</span>.parseCredentials(submissionContext), submissionContext.getCancelTokensWhenComplete(), application.getUser());</div><div class="line">            &#125; <span class="keyword">catch</span> (<span class="type">Exception</span> var9) &#123;</div><div class="line">                <span class="type">LOG</span>.warn(<span class="string">"Unable to parse credentials."</span>, var9);</div><div class="line"></div><div class="line">                assert application.getState() == <span class="type">RMAppState</span>.<span class="type">NEW</span>;</div><div class="line"></div><div class="line">                <span class="keyword">this</span>.rmContext.getDispatcher().getEventHandler().handle(<span class="keyword">new</span> <span class="type">RMAppEvent</span>(applicationId, <span class="type">RMAppEventType</span>.<span class="type">APP_REJECTED</span>, var9.getMessage()));</div><div class="line">                <span class="keyword">throw</span> <span class="type">RPCUtil</span>.getRemoteException(var9);</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">this</span>.rmContext.getDispatcher().getEventHandler().handle(<span class="keyword">new</span> <span class="type">RMAppEvent</span>(applicationId, <span class="type">RMAppEventType</span>.<span class="type">START</span>));</div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<h2 id="deploy-yarn-ApplicationMaster代码："><a href="#deploy-yarn-ApplicationMaster代码：" class="headerlink" title="deploy.yarn.ApplicationMaster代码："></a>deploy.yarn.ApplicationMaster代码：</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="type">SignalUtils</span>.registerLogger(log)</div><div class="line">    <span class="keyword">val</span> amArgs = <span class="keyword">new</span> <span class="type">ApplicationMasterArguments</span>(args)</div><div class="line"></div><div class="line">    <span class="comment">// Load the properties file with the Spark configuration and set entries as system properties,</span></div><div class="line">    <span class="comment">// so that user code run inside the AM also has access to them.</span></div><div class="line">    <span class="comment">// Note: we must do this before SparkHadoopUtil instantiated</span></div><div class="line">    <span class="keyword">if</span> (amArgs.propertiesFile != <span class="literal">null</span>) &#123;</div><div class="line">      <span class="type">Utils</span>.getPropertiesFromFile(amArgs.propertiesFile).foreach &#123; <span class="keyword">case</span> (k, v) =&gt;</div><div class="line">        sys.props(k) = v</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="type">SparkHadoopUtil</span>.get.runAsSparkUser &#123; () =&gt;</div><div class="line">      master = <span class="keyword">new</span> <span class="type">ApplicationMaster</span>(amArgs, <span class="keyword">new</span> <span class="type">YarnRMClient</span>)</div><div class="line">      <span class="type">System</span>.exit(master.run())</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Int</span> = &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">val</span> appAttemptId = client.getAttemptId()</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (isClusterMode) &#123;</div><div class="line">        <span class="comment">// Set the web ui port to be ephemeral for yarn so we don't conflict with</span></div><div class="line">        <span class="comment">// other spark processes running on the same box</span></div><div class="line">        <span class="type">System</span>.setProperty(<span class="string">"spark.ui.port"</span>, <span class="string">"0"</span>)</div><div class="line"></div><div class="line">        <span class="comment">// Set the master and deploy mode property to match the requested mode.</span></div><div class="line">        <span class="type">System</span>.setProperty(<span class="string">"spark.master"</span>, <span class="string">"yarn"</span>)</div><div class="line">        <span class="type">System</span>.setProperty(<span class="string">"spark.submit.deployMode"</span>, <span class="string">"cluster"</span>)</div><div class="line"></div><div class="line">        <span class="comment">// Set this internal configuration if it is running on cluster mode, this</span></div><div class="line">        <span class="comment">// configuration will be checked in SparkContext to avoid misuse of yarn cluster mode.</span></div><div class="line">        <span class="type">System</span>.setProperty(<span class="string">"spark.yarn.app.id"</span>, appAttemptId.getApplicationId().toString())</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      logInfo(<span class="string">"ApplicationAttemptId: "</span> + appAttemptId)</div><div class="line"></div><div class="line">      <span class="keyword">val</span> fs = <span class="type">FileSystem</span>.get(yarnConf)</div><div class="line"></div><div class="line">      <span class="comment">// This shutdown hook should run *after* the SparkContext is shut down.</span></div><div class="line">      <span class="keyword">val</span> priority = <span class="type">ShutdownHookManager</span>.<span class="type">SPARK_CONTEXT_SHUTDOWN_PRIORITY</span> - <span class="number">1</span></div><div class="line">      <span class="type">ShutdownHookManager</span>.addShutdownHook(priority) &#123; () =&gt;</div><div class="line">        <span class="keyword">val</span> maxAppAttempts = client.getMaxRegAttempts(sparkConf, yarnConf)</div><div class="line">        <span class="keyword">val</span> isLastAttempt = client.getAttemptId().getAttemptId() &gt;= maxAppAttempts</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (!finished) &#123;</div><div class="line">          <span class="comment">// The default state of ApplicationMaster is failed if it is invoked by shut down hook.</span></div><div class="line">          <span class="comment">// This behavior is different compared to 1.x version.</span></div><div class="line">          <span class="comment">// If user application is exited ahead of time by calling System.exit(N), here mark</span></div><div class="line">          <span class="comment">// this application as failed with EXIT_EARLY. For a good shutdown, user shouldn't call</span></div><div class="line">          <span class="comment">// System.exit(0) to terminate the application.</span></div><div class="line">          finish(finalStatus,</div><div class="line">            <span class="type">ApplicationMaster</span>.<span class="type">EXIT_EARLY</span>,</div><div class="line">            <span class="string">"Shutdown hook called before final status was reported."</span>)</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (!unregistered) &#123;</div><div class="line">          <span class="comment">// we only want to unregister if we don't want the RM to retry</span></div><div class="line">          <span class="keyword">if</span> (finalStatus == <span class="type">FinalApplicationStatus</span>.<span class="type">SUCCEEDED</span> || isLastAttempt) &#123;</div><div class="line">            unregister(finalStatus, finalMsg)</div><div class="line">            cleanupStagingDir(fs)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// Call this to force generation of secret so it gets populated into the</span></div><div class="line">      <span class="comment">// Hadoop UGI. This has to happen before the startUserApplication which does a</span></div><div class="line">      <span class="comment">// doAs in order for the credentials to be passed on to the executor containers.</span></div><div class="line">      <span class="keyword">val</span> securityMgr = <span class="keyword">new</span> <span class="type">SecurityManager</span>(sparkConf)</div><div class="line"></div><div class="line">      <span class="comment">// If the credentials file config is present, we must periodically renew tokens. So create</span></div><div class="line">      <span class="comment">// a new AMDelegationTokenRenewer</span></div><div class="line">      <span class="keyword">if</span> (sparkConf.contains(<span class="type">CREDENTIALS_FILE_PATH</span>.key)) &#123;</div><div class="line">        delegationTokenRenewerOption = <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">AMDelegationTokenRenewer</span>(sparkConf, yarnConf))</div><div class="line">        <span class="comment">// If a principal and keytab have been set, use that to create new credentials for executors</span></div><div class="line">        <span class="comment">// periodically</span></div><div class="line">        delegationTokenRenewerOption.foreach(_.scheduleLoginFromKeytab())</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (isClusterMode) &#123;</div><div class="line">        runDriver(securityMgr)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        runExecutorLauncher(securityMgr)</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</div><div class="line">        <span class="comment">// catch everything else if not specifically handled</span></div><div class="line">        logError(<span class="string">"Uncaught exception: "</span>, e)</div><div class="line">        finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>,</div><div class="line">          <span class="type">ApplicationMaster</span>.<span class="type">EXIT_UNCAUGHT_EXCEPTION</span>,</div><div class="line">          <span class="string">"Uncaught exception: "</span> + e)</div><div class="line">    &#125;</div><div class="line">    exitCode</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  </div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runDriver</span></span>(securityMgr: <span class="type">SecurityManager</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    addAmIpFilter()</div><div class="line">    userClassThread = startUserApplication()</div><div class="line"></div><div class="line">    <span class="comment">// This a bit hacky, but we need to wait until the spark.driver.port property has</span></div><div class="line">    <span class="comment">// been set by the Thread executing the user class.</span></div><div class="line">    <span class="keyword">val</span> sc = waitForSparkContextInitialized()</div><div class="line"></div><div class="line">    <span class="comment">// If there is no SparkContext at this point, just fail the app.</span></div><div class="line">    <span class="keyword">if</span> (sc == <span class="literal">null</span>) &#123;</div><div class="line">      finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>,</div><div class="line">        <span class="type">ApplicationMaster</span>.<span class="type">EXIT_SC_NOT_INITED</span>,</div><div class="line">        <span class="string">"Timed out waiting for SparkContext."</span>)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      rpcEnv = sc.env.rpcEnv</div><div class="line">      <span class="keyword">val</span> driverRef = runAMEndpoint(</div><div class="line">        sc.getConf.get(<span class="string">"spark.driver.host"</span>),</div><div class="line">        sc.getConf.get(<span class="string">"spark.driver.port"</span>),</div><div class="line">        isClusterMode = <span class="literal">true</span>)</div><div class="line">      registerAM(rpcEnv, driverRef, sc.ui.map(_.appUIAddress).getOrElse(<span class="string">""</span>), securityMgr)</div><div class="line">      userClassThread.join()</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">   * Start the user class, which contains the spark driver, in a separate Thread.</div><div class="line">   * If the main routine exits cleanly or exits with System.exit(N) for any N</div><div class="line">   * we assume it was successful, for all other cases we assume failure.</div><div class="line">   *</div><div class="line">   * Returns the user thread that was started.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">startUserApplication</span></span>(): <span class="type">Thread</span> = &#123;</div><div class="line">    logInfo(<span class="string">"Starting the user application in a separate Thread"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> classpath = <span class="type">Client</span>.getUserClasspath(sparkConf)</div><div class="line">    <span class="keyword">val</span> urls = classpath.map &#123; entry =&gt;</div><div class="line">      <span class="keyword">new</span> <span class="type">URL</span>(<span class="string">"file:"</span> + <span class="keyword">new</span> <span class="type">File</span>(entry.getPath()).getAbsolutePath())</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">val</span> userClassLoader =</div><div class="line">      <span class="keyword">if</span> (<span class="type">Client</span>.isUserClassPathFirst(sparkConf, isDriver = <span class="literal">true</span>)) &#123;</div><div class="line">        <span class="keyword">new</span> <span class="type">ChildFirstURLClassLoader</span>(urls, <span class="type">Utils</span>.getContextOrSparkClassLoader)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">new</span> <span class="type">MutableURLClassLoader</span>(urls, <span class="type">Utils</span>.getContextOrSparkClassLoader)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">    <span class="keyword">var</span> userArgs = args.userArgs</div><div class="line">    <span class="keyword">if</span> (args.primaryPyFile != <span class="literal">null</span> &amp;&amp; args.primaryPyFile.endsWith(<span class="string">".py"</span>)) &#123;</div><div class="line">      <span class="comment">// When running pyspark, the app is run using PythonRunner. The second argument is the list</span></div><div class="line">      <span class="comment">// of files to add to PYTHONPATH, which Client.scala already handles, so it's empty.</span></div><div class="line">      userArgs = <span class="type">Seq</span>(args.primaryPyFile, <span class="string">""</span>) ++ userArgs</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (args.primaryRFile != <span class="literal">null</span> &amp;&amp; args.primaryRFile.endsWith(<span class="string">".R"</span>)) &#123;</div><div class="line">      <span class="comment">// TODO(davies): add R dependencies here</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">val</span> mainMethod = userClassLoader.loadClass(args.userClass)</div><div class="line">      .getMethod(<span class="string">"main"</span>, classOf[<span class="type">Array</span>[<span class="type">String</span>]])</div><div class="line"></div><div class="line">    <span class="keyword">val</span> userThread = <span class="keyword">new</span> <span class="type">Thread</span> &#123;</div><div class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          mainMethod.invoke(<span class="literal">null</span>, userArgs.toArray)</div><div class="line">          finish(<span class="type">FinalApplicationStatus</span>.<span class="type">SUCCEEDED</span>, <span class="type">ApplicationMaster</span>.<span class="type">EXIT_SUCCESS</span>)</div><div class="line">          logDebug(<span class="string">"Done running users class"</span>)</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          ...</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    userThread.setContextClassLoader(userClassLoader)</div><div class="line">    userThread.setName(<span class="string">"Driver"</span>)</div><div class="line">    userThread.start()</div><div class="line">    userThread</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">   * Create an [[RpcEndpoint]] that communicates with the driver.</div><div class="line">   *</div><div class="line">   * In cluster mode, the AM and the driver belong to same process</div><div class="line">   * so the AMEndpoint need not monitor lifecycle of the driver.</div><div class="line">   *</div><div class="line">   * @return A reference to the driver's RPC endpoint.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runAMEndpoint</span></span>(</div><div class="line">      host: <span class="type">String</span>,</div><div class="line">      port: <span class="type">String</span>,</div><div class="line">      isClusterMode: <span class="type">Boolean</span>): <span class="type">RpcEndpointRef</span> = &#123;</div><div class="line">    <span class="keyword">val</span> driverEndpoint = rpcEnv.setupEndpointRef(</div><div class="line">      <span class="type">RpcAddress</span>(host, port.toInt),</div><div class="line">      <span class="type">YarnSchedulerBackend</span>.<span class="type">ENDPOINT_NAME</span>)</div><div class="line">    amEndpoint =</div><div class="line">      rpcEnv.setupEndpoint(<span class="string">"YarnAM"</span>, <span class="keyword">new</span> <span class="type">AMEndpoint</span>(rpcEnv, driverEndpoint, isClusterMode))</div><div class="line">    driverEndpoint</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">registerAM</span></span>(</div><div class="line">      _rpcEnv: <span class="type">RpcEnv</span>,</div><div class="line">      driverRef: <span class="type">RpcEndpointRef</span>,</div><div class="line">      uiAddress: <span class="type">String</span>,</div><div class="line">      securityMgr: <span class="type">SecurityManager</span>) = &#123;</div><div class="line">    <span class="keyword">val</span> sc = sparkContextRef.get()</div><div class="line"></div><div class="line">    <span class="keyword">val</span> appId = client.getAttemptId().getApplicationId().toString()</div><div class="line">    <span class="keyword">val</span> attemptId = client.getAttemptId().getAttemptId().toString()</div><div class="line">    <span class="keyword">val</span> historyAddress =</div><div class="line">      sparkConf.get(<span class="type">HISTORY_SERVER_ADDRESS</span>)</div><div class="line">        .map &#123; text =&gt; <span class="type">SparkHadoopUtil</span>.get.substituteHadoopVariables(text, yarnConf) &#125;</div><div class="line">        .map &#123; address =&gt; <span class="string">s"<span class="subst">$&#123;address&#125;</span><span class="subst">$&#123;HistoryServer.UI_PATH_PREFIX&#125;</span>/<span class="subst">$&#123;appId&#125;</span>/<span class="subst">$&#123;attemptId&#125;</span>"</span> &#125;</div><div class="line">        .getOrElse(<span class="string">""</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> _sparkConf = <span class="keyword">if</span> (sc != <span class="literal">null</span>) sc.getConf <span class="keyword">else</span> sparkConf</div><div class="line">    <span class="keyword">val</span> driverUrl = <span class="type">RpcEndpointAddress</span>(</div><div class="line">      _sparkConf.get(<span class="string">"spark.driver.host"</span>),</div><div class="line">      _sparkConf.get(<span class="string">"spark.driver.port"</span>).toInt,</div><div class="line">      <span class="type">CoarseGrainedSchedulerBackend</span>.<span class="type">ENDPOINT_NAME</span>).toString</div><div class="line">    allocator = client.register(driverUrl,</div><div class="line">      driverRef,</div><div class="line">      yarnConf,</div><div class="line">      _sparkConf,</div><div class="line">      uiAddress,</div><div class="line">      historyAddress,</div><div class="line">      securityMgr,</div><div class="line">      localResources)</div><div class="line"></div><div class="line">    allocator.allocateResources()</div><div class="line">    reporterThread = launchReporterThread()</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runExecutorLauncher</span></span>(securityMgr: <span class="type">SecurityManager</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> port = sparkConf.getInt(<span class="string">"spark.yarn.am.port"</span>, <span class="number">0</span>)</div><div class="line">    rpcEnv = <span class="type">RpcEnv</span>.create(<span class="string">"sparkYarnAM"</span>, <span class="type">Utils</span>.localHostName, port, sparkConf, securityMgr,</div><div class="line">      clientMode = <span class="literal">true</span>)</div><div class="line">    <span class="keyword">val</span> driverRef = waitForSparkDriver()</div><div class="line">    addAmIpFilter()</div><div class="line">    registerAM(rpcEnv, driverRef, sparkConf.get(<span class="string">"spark.driver.appUIAddress"</span>, <span class="string">""</span>), securityMgr)</div><div class="line"></div><div class="line">    <span class="comment">// In client mode the actor will stop the reporter thread.</span></div><div class="line">    reporterThread.join()</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h2 id="YarnRMClient"><a href="#YarnRMClient" class="headerlink" title="YarnRMClient"></a>YarnRMClient</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * Registers the application master with the RM.</div><div class="line">   *</div><div class="line">   * @param conf The Yarn configuration.</div><div class="line">   * @param sparkConf The Spark configuration.</div><div class="line">   * @param uiAddress Address of the SparkUI.</div><div class="line">   * @param uiHistoryAddress Address of the application on the History Server.</div><div class="line">   * @param securityMgr The security manager.</div><div class="line">   * @param localResources Map with information about files distributed via YARN's cache.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">register</span></span>(</div><div class="line">      driverUrl: <span class="type">String</span>,</div><div class="line">      driverRef: <span class="type">RpcEndpointRef</span>,</div><div class="line">      conf: <span class="type">YarnConfiguration</span>,</div><div class="line">      sparkConf: <span class="type">SparkConf</span>,</div><div class="line">      uiAddress: <span class="type">String</span>,</div><div class="line">      uiHistoryAddress: <span class="type">String</span>,</div><div class="line">      securityMgr: <span class="type">SecurityManager</span>,</div><div class="line">      localResources: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">LocalResource</span>]</div><div class="line">    ): <span class="type">YarnAllocator</span> = &#123;</div><div class="line">    amClient = <span class="type">AMRMClient</span>.createAMRMClient()</div><div class="line">    amClient.init(conf)</div><div class="line">    amClient.start()</div><div class="line">    <span class="keyword">this</span>.uiHistoryAddress = uiHistoryAddress</div><div class="line"></div><div class="line">    logInfo(<span class="string">"Registering the ApplicationMaster"</span>)</div><div class="line">    synchronized &#123;</div><div class="line">      amClient.registerApplicationMaster(<span class="type">Utils</span>.localHostName(), <span class="number">0</span>, uiAddress)</div><div class="line">      registered = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">new</span> <span class="type">YarnAllocator</span>(driverUrl, driverRef, conf, sparkConf, amClient, getAttemptId(), securityMgr,</div><div class="line">      localResources)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h2 id="YarnAllocator"><a href="#YarnAllocator" class="headerlink" title="YarnAllocator"></a>YarnAllocator</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div><div class="line">336</div><div class="line">337</div><div class="line">338</div><div class="line">339</div><div class="line">340</div><div class="line">341</div><div class="line">342</div><div class="line">343</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * YarnAllocator is charged with requesting containers from the YARN ResourceManager and deciding</div><div class="line"> * what to do with containers when YARN fulfills these requests.</div><div class="line"> *</div><div class="line"> * This class makes use of YARN's AMRMClient APIs. We interact with the AMRMClient in three ways:</div><div class="line"> * * Making our resource needs known, which updates local bookkeeping about containers requested.</div><div class="line"> * * Calling "allocate", which syncs our local container requests with the RM, and returns any</div><div class="line"> *   containers that YARN has granted to us.  This also functions as a heartbeat.</div><div class="line"> * * Processing the containers granted to us to possibly launch executors inside of them.</div><div class="line"> *</div><div class="line"> * The public methods of this class are thread-safe.  All methods that mutate state are</div><div class="line"> * synchronized.</div><div class="line"> */</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">   * Request resources such that, if YARN gives us all we ask for, we'll have a number of containers</div><div class="line">   * equal to maxExecutors.</div><div class="line">   *</div><div class="line">   * Deal with any containers YARN has granted to us by possibly launching executors in them.</div><div class="line">   *</div><div class="line">   * This must be synchronized because variables read in this method are mutated by other methods.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">allocateResources</span></span>(): <span class="type">Unit</span> = synchronized &#123;</div><div class="line">    updateResourceRequests()</div><div class="line"></div><div class="line">    <span class="keyword">val</span> progressIndicator = <span class="number">0.1</span>f</div><div class="line">    <span class="comment">// Poll the ResourceManager. This doubles as a heartbeat if there are no pending container</span></div><div class="line">    <span class="comment">// requests.</span></div><div class="line">    <span class="keyword">val</span> allocateResponse = amClient.allocate(progressIndicator)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> allocatedContainers = allocateResponse.getAllocatedContainers()</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (allocatedContainers.size &gt; <span class="number">0</span>) &#123;</div><div class="line">      logDebug(<span class="string">"Allocated containers: %d. Current executor count: %d. Cluster resources: %s."</span></div><div class="line">        .format(</div><div class="line">          allocatedContainers.size,</div><div class="line">          numExecutorsRunning,</div><div class="line">          allocateResponse.getAvailableResources))</div><div class="line"></div><div class="line">      handleAllocatedContainers(allocatedContainers.asScala)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> completedContainers = allocateResponse.getCompletedContainersStatuses()</div><div class="line">    <span class="keyword">if</span> (completedContainers.size &gt; <span class="number">0</span>) &#123;</div><div class="line">      logDebug(<span class="string">"Completed %d containers"</span>.format(completedContainers.size))</div><div class="line">      processCompletedContainers(completedContainers.asScala)</div><div class="line">      logDebug(<span class="string">"Finished processing %d completed containers. Current running executor count: %d."</span></div><div class="line">        .format(completedContainers.size, numExecutorsRunning))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">   * Handle containers granted by the RM by launching executors on them.</div><div class="line">   *</div><div class="line">   * Due to the way the YARN allocation protocol works, certain healthy race conditions can result</div><div class="line">   * in YARN granting containers that we no longer need. In this case, we release them.</div><div class="line">   *</div><div class="line">   * Visible for testing.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handleAllocatedContainers</span></span>(allocatedContainers: <span class="type">Seq</span>[<span class="type">Container</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> containersToUse = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Container</span>](allocatedContainers.size)</div><div class="line"></div><div class="line">    <span class="comment">// Match incoming requests by host</span></div><div class="line">    <span class="keyword">val</span> remainingAfterHostMatches = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Container</span>]</div><div class="line">    <span class="keyword">for</span> (allocatedContainer &lt;- allocatedContainers) &#123;</div><div class="line">      matchContainerToRequest(allocatedContainer, allocatedContainer.getNodeId.getHost,</div><div class="line">        containersToUse, remainingAfterHostMatches)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Match remaining by rack</span></div><div class="line">    <span class="keyword">val</span> remainingAfterRackMatches = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Container</span>]</div><div class="line">    <span class="keyword">for</span> (allocatedContainer &lt;- remainingAfterHostMatches) &#123;</div><div class="line">      <span class="keyword">val</span> rack = <span class="type">RackResolver</span>.resolve(conf, allocatedContainer.getNodeId.getHost).getNetworkLocation</div><div class="line">      matchContainerToRequest(allocatedContainer, rack, containersToUse,</div><div class="line">        remainingAfterRackMatches)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Assign remaining that are neither node-local nor rack-local</span></div><div class="line">    <span class="keyword">val</span> remainingAfterOffRackMatches = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Container</span>]</div><div class="line">    <span class="keyword">for</span> (allocatedContainer &lt;- remainingAfterRackMatches) &#123;</div><div class="line">      matchContainerToRequest(allocatedContainer, <span class="type">ANY_HOST</span>, containersToUse,</div><div class="line">        remainingAfterOffRackMatches)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (!remainingAfterOffRackMatches.isEmpty) &#123;</div><div class="line">      logDebug(<span class="string">s"Releasing <span class="subst">$&#123;remainingAfterOffRackMatches.size&#125;</span> unneeded containers that were "</span> +</div><div class="line">        <span class="string">s"allocated to us"</span>)</div><div class="line">      <span class="keyword">for</span> (container &lt;- remainingAfterOffRackMatches) &#123;</div><div class="line">        internalReleaseContainer(container)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    runAllocatedContainers(containersToUse)</div><div class="line"></div><div class="line">    logInfo(<span class="string">"Received %d containers from YARN, launching executors on %d of them."</span></div><div class="line">      .format(allocatedContainers.size, containersToUse.size))</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="meta">@Override</span></div><div class="line">  public <span class="type">AllocateResponse</span> allocate(float progressIndicator) </div><div class="line">      <span class="keyword">throws</span> <span class="type">YarnException</span>, <span class="type">IOException</span> &#123;</div><div class="line">    <span class="type">Preconditions</span>.checkArgument(progressIndicator &gt;= <span class="number">0</span>,</div><div class="line">        <span class="string">"Progress indicator should not be negative"</span>);</div><div class="line">    <span class="type">AllocateResponse</span> allocateResponse = <span class="literal">null</span>;</div><div class="line">    <span class="type">List</span>&lt;<span class="type">ResourceRequest</span>&gt; askList = <span class="literal">null</span>;</div><div class="line">    <span class="type">List</span>&lt;<span class="type">ContainerId</span>&gt; releaseList = <span class="literal">null</span>;</div><div class="line">    <span class="type">AllocateRequest</span> allocateRequest = <span class="literal">null</span>;</div><div class="line">    <span class="type">List</span>&lt;<span class="type">String</span>&gt; blacklistToAdd = <span class="keyword">new</span> <span class="type">ArrayList</span>&lt;<span class="type">String</span>&gt;();</div><div class="line">    <span class="type">List</span>&lt;<span class="type">String</span>&gt; blacklistToRemove = <span class="keyword">new</span> <span class="type">ArrayList</span>&lt;<span class="type">String</span>&gt;();</div><div class="line">    </div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      synchronized (<span class="keyword">this</span>) &#123;</div><div class="line">        askList = <span class="keyword">new</span> <span class="type">ArrayList</span>&lt;<span class="type">ResourceRequest</span>&gt;(ask.size());</div><div class="line">        <span class="keyword">for</span>(<span class="type">ResourceRequest</span> r : ask) &#123;</div><div class="line">          <span class="comment">// create a copy of ResourceRequest as we might change it while the </span></div><div class="line">          <span class="comment">// RPC layer is using it to send info across</span></div><div class="line">          askList.add(<span class="type">ResourceRequest</span>.newInstance(r.getPriority(),</div><div class="line">              r.getResourceName(), r.getCapability(), r.getNumContainers(),</div><div class="line">              r.getRelaxLocality(), r.getNodeLabelExpression()));</div><div class="line">        &#125;</div><div class="line">        releaseList = <span class="keyword">new</span> <span class="type">ArrayList</span>&lt;<span class="type">ContainerId</span>&gt;(release);</div><div class="line">        <span class="comment">// optimistically clear this collection assuming no RPC failure</span></div><div class="line">        ask.clear();</div><div class="line">        release.clear();</div><div class="line"></div><div class="line">        blacklistToAdd.addAll(blacklistAdditions);</div><div class="line">        blacklistToRemove.addAll(blacklistRemovals);</div><div class="line">        </div><div class="line">        <span class="type">ResourceBlacklistRequest</span> blacklistRequest =</div><div class="line">            <span class="type">ResourceBlacklistRequest</span>.newInstance(blacklistToAdd,</div><div class="line">                blacklistToRemove);</div><div class="line">        </div><div class="line">        allocateRequest =</div><div class="line">            <span class="type">AllocateRequest</span>.newInstance(lastResponseId, progressIndicator,</div><div class="line">              askList, releaseList, blacklistRequest);</div><div class="line">        <span class="comment">// clear blacklistAdditions and blacklistRemovals before </span></div><div class="line">        <span class="comment">// unsynchronized part</span></div><div class="line">        blacklistAdditions.clear();</div><div class="line">        blacklistRemovals.clear();</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        allocateResponse = rmClient.allocate(allocateRequest);</div><div class="line">      &#125; <span class="keyword">catch</span> (<span class="type">ApplicationMasterNotRegisteredException</span> e) &#123;</div><div class="line">        <span class="type">LOG</span>.warn(<span class="string">"ApplicationMaster is out of sync with ResourceManager,"</span></div><div class="line">            + <span class="string">" hence resyncing."</span>);</div><div class="line">        synchronized (<span class="keyword">this</span>) &#123;</div><div class="line">          release.addAll(<span class="keyword">this</span>.pendingRelease);</div><div class="line">          blacklistAdditions.addAll(<span class="keyword">this</span>.blacklistedNodes);</div><div class="line">          <span class="keyword">for</span> (<span class="type">Map</span>&lt;<span class="type">String</span>, <span class="type">TreeMap</span>&lt;<span class="type">Resource</span>, <span class="type">ResourceRequestInfo</span>&gt;&gt; rr : remoteRequestsTable</div><div class="line">            .values()) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="type">Map</span>&lt;<span class="type">Resource</span>, <span class="type">ResourceRequestInfo</span>&gt; capabalities : rr.values()) &#123;</div><div class="line">              <span class="keyword">for</span> (<span class="type">ResourceRequestInfo</span> request : capabalities.values()) &#123;</div><div class="line">                addResourceRequestToAsk(request.remoteRequest);</div><div class="line">              &#125;</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// re register with RM</span></div><div class="line">        registerApplicationMaster();</div><div class="line">        allocateResponse = allocate(progressIndicator);</div><div class="line">        <span class="keyword">return</span> allocateResponse;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      synchronized (<span class="keyword">this</span>) &#123;</div><div class="line">        <span class="comment">// update these on successful RPC</span></div><div class="line">        clusterNodeCount = allocateResponse.getNumClusterNodes();</div><div class="line">        lastResponseId = allocateResponse.getResponseId();</div><div class="line">        clusterAvailableResources = allocateResponse.getAvailableResources();</div><div class="line">        <span class="keyword">if</span> (!allocateResponse.getNMTokens().isEmpty()) &#123;</div><div class="line">          populateNMTokens(allocateResponse.getNMTokens());</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (allocateResponse.getAMRMToken() != <span class="literal">null</span>) &#123;</div><div class="line">          updateAMRMToken(allocateResponse.getAMRMToken());</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (!pendingRelease.isEmpty()</div><div class="line">            &amp;&amp; !allocateResponse.getCompletedContainersStatuses().isEmpty()) &#123;</div><div class="line">          removePendingReleaseRequests(allocateResponse</div><div class="line">              .getCompletedContainersStatuses());</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      <span class="comment">// TODO how to differentiate remote yarn exception vs error in rpc</span></div><div class="line">      <span class="keyword">if</span>(allocateResponse == <span class="literal">null</span>) &#123;</div><div class="line">        <span class="comment">// we hit an exception in allocate()</span></div><div class="line">        <span class="comment">// preserve ask and release for next call to allocate()</span></div><div class="line">        synchronized (<span class="keyword">this</span>) &#123;</div><div class="line">          release.addAll(releaseList);</div><div class="line">          <span class="comment">// requests could have been added or deleted during call to allocate</span></div><div class="line">          <span class="comment">// If requests were added/removed then there is nothing to do since</span></div><div class="line">          <span class="comment">// the ResourceRequest object in ask would have the actual new value.</span></div><div class="line">          <span class="comment">// If ask does not have this ResourceRequest then it was unchanged and</span></div><div class="line">          <span class="comment">// so we can add the value back safely.</span></div><div class="line">          <span class="comment">// This assumes that there will no concurrent calls to allocate() and</span></div><div class="line">          <span class="comment">// so we dont have to worry about ask being changed in the</span></div><div class="line">          <span class="comment">// synchronized block at the beginning of this method.</span></div><div class="line">          <span class="keyword">for</span>(<span class="type">ResourceRequest</span> oldAsk : askList) &#123;</div><div class="line">            <span class="keyword">if</span>(!ask.contains(oldAsk)) &#123;</div><div class="line">              ask.add(oldAsk);</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">          </div><div class="line">          blacklistAdditions.addAll(blacklistToAdd);</div><div class="line">          blacklistRemovals.addAll(blacklistToRemove);</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> allocateResponse;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">public <span class="type">AllocateResponse</span> allocate(<span class="type">AllocateRequest</span> request) <span class="keyword">throws</span> <span class="type">YarnException</span>, <span class="type">IOException</span> &#123;</div><div class="line">        <span class="type">AMRMTokenIdentifier</span> amrmTokenIdentifier = <span class="keyword">this</span>.authorizeRequest();</div><div class="line">        <span class="type">ApplicationAttemptId</span> appAttemptId = amrmTokenIdentifier.getApplicationAttemptId();</div><div class="line">        <span class="type">ApplicationId</span> applicationId = appAttemptId.getApplicationId();</div><div class="line">        <span class="keyword">this</span>.amLivelinessMonitor.receivedPing(appAttemptId);</div><div class="line">        <span class="type">ApplicationMasterService</span>.<span class="type">AllocateResponseLock</span> lock = (<span class="type">ApplicationMasterService</span>.<span class="type">AllocateResponseLock</span>)<span class="keyword">this</span>.responseMap.get(appAttemptId);</div><div class="line">        <span class="keyword">if</span>(lock == <span class="literal">null</span>) &#123;</div><div class="line">            <span class="type">String</span> message = <span class="string">"Application attempt "</span> + appAttemptId + <span class="string">" doesn\'t exist in ApplicationMasterService cache."</span>;</div><div class="line">            <span class="type">LOG</span>.error(message);</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ApplicationAttemptNotFoundException</span>(message);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            synchronized(lock) &#123;</div><div class="line">                <span class="type">AllocateResponse</span> lastResponse = lock.getAllocateResponse();</div><div class="line">                <span class="type">String</span> filteredProgress1;</div><div class="line">                <span class="keyword">if</span>(!<span class="keyword">this</span>.hasApplicationMasterRegistered(appAttemptId)) &#123;</div><div class="line">                    filteredProgress1 = <span class="string">"AM is not registered for known application attempt: "</span> + appAttemptId + <span class="string">" or RM had restarted after AM registered . AM should re-register."</span>;</div><div class="line">                    <span class="type">LOG</span>.info(filteredProgress1);</div><div class="line">                    <span class="type">RMAuditLogger</span>.logFailure(((<span class="type">RMApp</span>)<span class="keyword">this</span>.rmContext.getRMApps().get(appAttemptId.getApplicationId())).getUser(), <span class="string">"App Master Heartbeats"</span>, <span class="string">""</span>, <span class="string">"ApplicationMasterService"</span>, filteredProgress1, applicationId, appAttemptId);</div><div class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">ApplicationMasterNotRegisteredException</span>(filteredProgress1);</div><div class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span>(request.getResponseId() + <span class="number">1</span> == lastResponse.getResponseId()) &#123;</div><div class="line">                    <span class="keyword">return</span> lastResponse;</div><div class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span>(request.getResponseId() + <span class="number">1</span> &lt; lastResponse.getResponseId()) &#123;</div><div class="line">                    filteredProgress1 = <span class="string">"Invalid responseId in AllocateRequest from application attempt: "</span> + appAttemptId + <span class="string">", expect responseId to be "</span> + (lastResponse.getResponseId() + <span class="number">1</span>);</div><div class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">InvalidApplicationMasterRequestException</span>(filteredProgress1);</div><div class="line">                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                    float filteredProgress = request.getProgress();</div><div class="line">                    <span class="keyword">if</span>(!<span class="type">Float</span>.isNaN(filteredProgress) &amp;&amp; filteredProgress != <span class="number">-1.0</span>F / <span class="number">0.0</span> &amp;&amp; filteredProgress &gt;= <span class="number">0.0</span>F) &#123;</div><div class="line">                        <span class="keyword">if</span>(filteredProgress &gt; <span class="number">1.0</span>F || filteredProgress == <span class="number">1.0</span>F / <span class="number">0.0</span>) &#123;</div><div class="line">                            request.setProgress(<span class="number">1.0</span>F);</div><div class="line">                        &#125;</div><div class="line">                    &#125; <span class="keyword">else</span> &#123;</div><div class="line">                        request.setProgress(<span class="number">0.0</span>F);</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    <span class="keyword">this</span>.rmContext.getDispatcher().getEventHandler().handle(<span class="keyword">new</span> <span class="type">RMAppAttemptStatusupdateEvent</span>(appAttemptId, request.getProgress()));</div><div class="line">                    <span class="type">List</span> ask = request.getAskList();</div><div class="line">                    <span class="type">List</span> release = request.getReleaseList();</div><div class="line">                    <span class="type">ResourceBlacklistRequest</span> blacklistRequest = request.getResourceBlacklistRequest();</div><div class="line">                    <span class="type">List</span> blacklistAdditions = blacklistRequest != <span class="literal">null</span>?blacklistRequest.getBlacklistAdditions():<span class="type">Collections</span>.<span class="type">EMPTY_LIST</span>;</div><div class="line">                    <span class="type">List</span> blacklistRemovals = blacklistRequest != <span class="literal">null</span>?blacklistRequest.getBlacklistRemovals():<span class="type">Collections</span>.<span class="type">EMPTY_LIST</span>;</div><div class="line">                    <span class="type">RMApp</span> app = (<span class="type">RMApp</span>)<span class="keyword">this</span>.rmContext.getRMApps().get(applicationId);</div><div class="line">                    <span class="type">ApplicationSubmissionContext</span> asc = app.getApplicationSubmissionContext();</div><div class="line">                    <span class="type">Iterator</span> allocation = ask.iterator();</div><div class="line"></div><div class="line">                    <span class="keyword">while</span>(allocation.hasNext()) &#123;</div><div class="line">                        <span class="type">ResourceRequest</span> appAttempt = (<span class="type">ResourceRequest</span>)allocation.next();</div><div class="line">                        <span class="keyword">if</span>(<span class="literal">null</span> == appAttempt.getNodeLabelExpression() &amp;&amp; <span class="string">"*"</span>.equals(appAttempt.getResourceName())) &#123;</div><div class="line">                            appAttempt.setNodeLabelExpression(asc.getNodeLabelExpression());</div><div class="line">                        &#125;</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    <span class="keyword">try</span> &#123;</div><div class="line">                        <span class="type">RMServerUtils</span>.normalizeAndValidateRequests(ask, <span class="keyword">this</span>.rScheduler.getMaximumResourceCapability(), app.getQueue(), <span class="keyword">this</span>.rScheduler, <span class="keyword">this</span>.rmContext);</div><div class="line">                    &#125; <span class="keyword">catch</span> (<span class="type">InvalidResourceRequestException</span> var31) &#123;</div><div class="line">                        <span class="type">LOG</span>.warn(<span class="string">"Invalid resource ask by application "</span> + appAttemptId, var31);</div><div class="line">                        <span class="keyword">throw</span> var31;</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    <span class="keyword">try</span> &#123;</div><div class="line">                        <span class="type">RMServerUtils</span>.validateBlacklistRequest(blacklistRequest);</div><div class="line">                    &#125; <span class="keyword">catch</span> (<span class="type">InvalidResourceBlacklistRequestException</span> var30) &#123;</div><div class="line">                        <span class="type">LOG</span>.warn(<span class="string">"Invalid blacklist request by application "</span> + appAttemptId, var30);</div><div class="line">                        <span class="keyword">throw</span> var30;</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    <span class="keyword">if</span>(!app.getApplicationSubmissionContext().getKeepContainersAcrossApplicationAttempts()) &#123;</div><div class="line">                        <span class="keyword">try</span> &#123;</div><div class="line">                            <span class="type">RMServerUtils</span>.validateContainerReleaseRequest(release, appAttemptId);</div><div class="line">                        &#125; <span class="keyword">catch</span> (<span class="type">InvalidContainerReleaseException</span> var29) &#123;</div><div class="line">                            <span class="type">LOG</span>.warn(<span class="string">"Invalid container release by application "</span> + appAttemptId, var29);</div><div class="line">                            <span class="keyword">throw</span> var29;</div><div class="line">                        &#125;</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    <span class="type">Allocation</span> allocation1 = <span class="keyword">this</span>.rScheduler.allocate(appAttemptId, ask, release, blacklistAdditions, blacklistRemovals);</div><div class="line">                    <span class="keyword">if</span>(!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) &#123;</div><div class="line">                        <span class="type">LOG</span>.info(<span class="string">"blacklist are updated in Scheduler.blacklistAdditions: "</span> + blacklistAdditions + <span class="string">", "</span> + <span class="string">"blacklistRemovals: "</span> + blacklistRemovals);</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    <span class="type">RMAppAttempt</span> appAttempt1 = app.getRMAppAttempt(appAttemptId);</div><div class="line">                    <span class="type">AllocateResponse</span> allocateResponse = (<span class="type">AllocateResponse</span>)<span class="keyword">this</span>.recordFactory.newRecordInstance(<span class="type">AllocateResponse</span>.<span class="keyword">class</span>);</div><div class="line">                    <span class="keyword">if</span>(!allocation1.getContainers().isEmpty()) &#123;</div><div class="line">                        allocateResponse.setNMTokens(allocation1.getNMTokens());</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    <span class="type">ArrayList</span> updatedNodes = <span class="keyword">new</span> <span class="type">ArrayList</span>();</div><div class="line">                    <span class="keyword">if</span>(app.pullRMNodeUpdates(updatedNodes) &gt; <span class="number">0</span>) &#123;</div><div class="line">                        <span class="type">ArrayList</span> nextMasterKey = <span class="keyword">new</span> <span class="type">ArrayList</span>();</div><div class="line">                        <span class="type">Iterator</span> appAttemptImpl = updatedNodes.iterator();</div><div class="line"></div><div class="line">                        <span class="keyword">while</span>(appAttemptImpl.hasNext()) &#123;</div><div class="line">                            <span class="type">RMNode</span> amrmToken = (<span class="type">RMNode</span>)appAttemptImpl.next();</div><div class="line">                            <span class="type">SchedulerNodeReport</span> schedulerNodeReport = <span class="keyword">this</span>.rScheduler.getNodeReport(amrmToken.getNodeID());</div><div class="line">                            <span class="type">Resource</span> used = <span class="type">BuilderUtils</span>.newResource(<span class="number">0</span>, <span class="number">0</span>);</div><div class="line">                            int numContainers = <span class="number">0</span>;</div><div class="line">                            <span class="keyword">if</span>(schedulerNodeReport != <span class="literal">null</span>) &#123;</div><div class="line">                                used = schedulerNodeReport.getUsedResource();</div><div class="line">                                numContainers = schedulerNodeReport.getNumContainers();</div><div class="line">                            &#125;</div><div class="line"></div><div class="line">                            <span class="type">NodeId</span> nodeId = amrmToken.getNodeID();</div><div class="line">                            <span class="type">NodeReport</span> report = <span class="type">BuilderUtils</span>.newNodeReport(nodeId, amrmToken.getState(), amrmToken.getHttpAddress(), amrmToken.getRackName(), used, amrmToken.getTotalCapability(), numContainers, amrmToken.getHealthReport(), amrmToken.getLastHealthReportTime(), amrmToken.getNodeLabels());</div><div class="line">                            nextMasterKey.add(report);</div><div class="line">                        &#125;</div><div class="line"></div><div class="line">                        allocateResponse.setUpdatedNodes(nextMasterKey);</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    allocateResponse.setAllocatedContainers(allocation1.getContainers());</div><div class="line">                    allocateResponse.setCompletedContainersStatuses(appAttempt1.pullJustFinishedContainers());</div><div class="line">                    allocateResponse.setResponseId(lastResponse.getResponseId() + <span class="number">1</span>);</div><div class="line">                    allocateResponse.setAvailableResources(allocation1.getResourceLimit());</div><div class="line">                    allocateResponse.setNumClusterNodes(<span class="keyword">this</span>.rScheduler.getNumClusterNodes());</div><div class="line">                    allocateResponse.setPreemptionMessage(<span class="keyword">this</span>.generatePreemptionMessage(allocation1));</div><div class="line">                    <span class="type">MasterKeyData</span> nextMasterKey1 = <span class="keyword">this</span>.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();</div><div class="line">                    <span class="keyword">if</span>(nextMasterKey1 != <span class="literal">null</span> &amp;&amp; nextMasterKey1.getMasterKey().getKeyId() != amrmTokenIdentifier.getKeyId()) &#123;</div><div class="line">                        <span class="type">RMAppAttemptImpl</span> appAttemptImpl1 = (<span class="type">RMAppAttemptImpl</span>)appAttempt1;</div><div class="line">                        <span class="type">Token</span> amrmToken1 = appAttempt1.getAMRMToken();</div><div class="line">                        <span class="keyword">if</span>(nextMasterKey1.getMasterKey().getKeyId() != appAttemptImpl1.getAMRMTokenKeyId()) &#123;</div><div class="line">                            <span class="type">LOG</span>.info(<span class="string">"The AMRMToken has been rolled-over. Send new AMRMToken back to application: "</span> + applicationId);</div><div class="line">                            amrmToken1 = <span class="keyword">this</span>.rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(appAttemptId);</div><div class="line">                            appAttemptImpl1.setAMRMToken(amrmToken1);</div><div class="line">                        &#125;</div><div class="line"></div><div class="line">                        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.<span class="type">Token</span>.newInstance(amrmToken1.getIdentifier(), amrmToken1.getKind().toString(), amrmToken1.getPassword(), amrmToken1.getService().toString()));</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                    lock.setAllocateResponse(allocateResponse);</div><div class="line">                    <span class="keyword">return</span> allocateResponse;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="Yarn-Cluster模式"><a href="#Yarn-Cluster模式" class="headerlink" title="Yarn-Cluster模式"></a>Yarn-Cluster模式</h3><p><strong> 客户端操作：</strong></p>
<ol>
<li>SparkSubmit中根据yarnConf来初始化yarnClient，并启动yarnClient </li>
<li>创建客户端Application，并获取Application的ID，进一步判断集群中的资源是否满足executor和ApplicationMaster申请的资源，如果不满足则抛出IllegalArgumentException； </li>
<li>设置资源、环境变量：其中包括了设置Application的Staging目录、准备本地资源（jar文件、log4j.properties）、设置Application其中的环境变量、创建Container启动的Context等； </li>
<li>设置Application提交的Context，包括设置应用的名字、队列、AM的申请的Container、标记该作业的类型为spark； </li>
<li>申请Memory，最终通过submitApplication方法向ResourceManager提交该Application。当作业提交到YARN上之后，客户端就没事了，会关闭此进程，因为整个作业运行在YARN集群上进行，运行的结果将会保存到HDFS或者日志中。</li>
</ol>
<p><strong> Yarn操作：</strong></p>
<ol>
<li>运行ApplicationMaster的run方法； </li>
<li>设置好相关的环境变量； </li>
<li>创建amClient，并启动； </li>
<li>在Spark UI启动之前设置Spark UI的AmIpFilter； </li>
<li>在startUserClass函数专门启动了一个线程（名称为Driver的线程）来启动用户提交的Application，也就是启动了Driver。在Driver中将会初始化SparkContext； </li>
<li>等待SparkContext初始化完成，最多等待spark.yarn.applicationMaster.waitTries次数（默认为10），如果等待了的次数超过了配置的，程序将会退出；否则用SparkContext初始化yarnAllocator；<br> 6.1. <strong>怎么知道SparkContext初始化完成?</strong><br> 其实在5步骤中启动Application的过程中会初始化SparkContext，在初始化SparkContext的时候将会创建YarnClusterScheduler，在SparkContext初始化完成的时候，会调用YarnClusterScheduler类中的postStartHook方法，而该方法会通知ApplicationMaster已经初始化好了SparkContext<br> 6.2. <strong>为何要等待SparkContext初始化完成？</strong><br> CoarseGrainedExecutorBackend启动后需要向CoarseGrainedSchedulerBackend注册  </li>
<li>当SparkContext初始化完成的时候，通过amClient向ResourceManager注册ApplicationMaster  </li>
<li>分配并启动Executeors。在启动Executeors之前，先要通过yarnAllocator获取到numExecutors个Container，然后在Container中启动Executeors。如果在启动Executeors的过程中失败的次数达到了maxNumExecutorFailures的次数，那么这个Application将失败，将Application Status标明为FAILED，并将关闭SparkContext。其实，启动Executeors是通过ExecutorRunnable实现的，而ExecutorRunnable内部是启动CoarseGrainedExecutorBackend的，CoarseGrainedExecutorBackend启动后会向SchedulerBackend注册。<br> (resourceManager是如何决定该分配几个container？  在shell提交时跟参数 默认启动两个executor)  </li>
<li>最后，Task将在CoarseGrainedExecutorBackend里面运行，然后运行状况会通过Akka通知CoarseGrainedScheduler，直到作业运行完成。</li>
</ol>
<h3 id="Client模式"><a href="#Client模式" class="headerlink" title="Client模式:"></a>Client模式:</h3><p><strong> 客户端操作：</strong></p>
<ol>
<li>通过SparkSubmit类的launch的函数直接调用作业的main函数（通过反射机制实现），如果是集群模式就会调用Client的main函数。 </li>
<li>而应用程序的main函数一定都有个SparkContent，并对其进行初始化； </li>
<li>在SparkContent初始化中将会依次做如下的事情：设置相关的配置、注册MapOutputTracker、BlockManagerMaster、BlockManager，创建taskScheduler和dagScheduler；其中比较重要的是创建taskScheduler和dagScheduler。在创建taskScheduler的时候会根据我们传进来的master来选择Scheduler和SchedulerBackend。由于我们选择的是yarn-client模式，程序会选择YarnClientClusterScheduler和YarnClientSchedulerBackend，并将YarnClientSchedulerBackend的实例初始化YarnClientClusterScheduler，上面两个实例的获取都是通过反射机制实现的，YarnClientSchedulerBackend类是CoarseGrainedSchedulerBackend类的子类，YarnClientClusterScheduler是TaskSchedulerImpl的子类，仅仅重写了TaskSchedulerImpl中的getRackForHost方法。 </li>
<li>初始化完taskScheduler后，将创建dagScheduler，然后通过taskScheduler.start()启动taskScheduler，而在taskScheduler启动的过程中也会调用SchedulerBackend的start方法。在SchedulerBackend启动的过程中将会初始化一些参数，封装在ClientArguments中，并将封装好的ClientArguments传进Client类中，并client.submitApplication()方法获取Application ID。</li>
</ol>
<p><strong> Yarn操作：</strong></p>
<ol>
<li>运行ApplicationMaster的run方法（runExecutorLauncher）； </li>
<li>无需等待SparkContext初始化完成（因为YarnClientClusterScheduler已启动完成），向sparkYarnAM注册该Application </li>
<li>分配Executors，这里面的分配逻辑和yarn-cluster里面类似，就不再说了。 </li>
<li>最后，Task将在CoarseGrainedExecutorBackend里面运行，然后运行状况会通过Akka通知CoarseGrainedScheduler，直到作业运行完成。 </li>
<li>在作业运行的时候，YarnClientSchedulerBackend会每隔1秒通过client获取到作业的运行状况，并打印出相应的运行信息，当Application的状态是FINISHED、FAILED和KILLED中的一种，那么程序将退出等待。 </li>
<li>最后有个线程会再次确认Application的状态，当Application的状态是FINISHED、FAILED和KILLED中的一种，程序就运行完成，并停止SparkContext。整个过程就结束了。</li>
</ol>
<h3 id="Yarn的ApplicationMaster管理"><a href="#Yarn的ApplicationMaster管理" class="headerlink" title="Yarn的ApplicationMaster管理"></a>Yarn的ApplicationMaster管理</h3><ol>
<li>client向RM提交程序(包含AM程序， AM启动命令，用户程序)；</li>
<li>RM向资源调度器去申请资源，一旦申请的AM需要的资源，AM Laucher 便与对应的NodeManager联系启动</li>
<li>AM同时向AM LivenessMonitor添加进监控列表，启动对AM的监控</li>
<li>AM启动后，向AM Service注册报告自己的端口号，ip，track url等,之后AM会定期向AM Service发送心跳，执行allocate，AM Service会向AM LivenessMonitor更新AM的心跳时间</li>
<li>当用户程序执行完毕，AM向AM Service报告完成，AM Service通知AM LivenessMonitor从监控列表中删除AM，释放资源。</li>
</ol>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h3><ol>
<li><a href="http://blog.itpub.net/29754888/viewspace-1815323/" target="_blank" rel="external">Spark on Yarn 任务提交流程源码分析</a></li>
<li><a href="http://www.tuicool.com/articles/UBfqqaE" target="_blank" rel="external">Yarn的ApplicationMaster管理</a></li>
<li><a href="http://blog.csdn.net/suifeng3051/article/details/49486927" target="_blank" rel="external">Hadoop Yarn详解</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=&quot;330&quot; height=&quot;86&quot; src=&quot;http://music.163.com/outchain/player?ty
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>spark常见问题解决方法</title>
    <link href="http://yoursite.com/2016/09/24/spark-common-problems-solutions/"/>
    <id>http://yoursite.com/2016/09/24/spark-common-problems-solutions/</id>
    <published>2016-09-24T02:20:00.000Z</published>
    <updated>2017-06-18T08:25:49.696Z</updated>
    
    <content type="html"><![CDATA[<p>对于Spark程序优化，应从如下几点进行：<br>&nbsp;&nbsp;<code>1.</code> 通过监控CPU、内存、网络、IO、GC、应用指标等数据，切实找到系统的瓶颈点。<br>&nbsp;&nbsp;<code>2.</code> 统筹全局，制定相应的解决方案，解决问题的思路是否清晰准确很重要，切勿『头疼医头，脚疼医脚』，应总体考虑把握。<br>&nbsp;&nbsp;<code>3.</code> 了解一些技术的背景知识，对于每次优化尽量做得彻底些，多进行总结。<br>&nbsp;&nbsp;<code>4.</code> 程序优化通常从Stage/Cache/Partition、资源、内存/GC的优化。</p>
<p><strong>1.</strong> spark运行时报错：Shutdown hook called before final status was reported.<br>解决方法：程序存在错误，将日志down下来查看具体原因！down日志命令：<code>yarn logs -applicationId app_id</code></p>
<p><strong>2.</strong> Spark性能优化的9大问题及其解决方案<a href="http://book.51cto.com/art/201409/453045.htm" target="_blank" rel="external">http://book.51cto.com/art/201409/453045.htm</a><br>Spark程序优化所需要关注的几个关键点——最主要的是数据序列化和内存优化  </p>
<p><code>*问题1</code>：reduce task数目不合适<br><code>解决方法</code>：需根据实际情况调节默认配置，调整方式是修改参数spark.default.parallelism。通常，reduce数目设置为core数目的2到3倍。数量太大，造成很多小任务，增加启动任务的开销；数目太少，*任务运行缓慢。</p>
<p><code>*问题2</code>：shuffle磁盘IO时间长<br><code>解决方法</code>：设置spark.local.dir为多个磁盘，并设置磁盘为IO速度快的磁盘，通过增加IO来优化shuffle性能；</p>
<p><code>*问题3</code>：map|reduce数量大，造成shuffle小文件数目多<br><code>解决方法</code>：默认情况下shuffle文件数目为map tasks * reduce tasks. 通过设置spark.shuffle.consolidateFiles为true，来合并shuffle中间文件，此时文件数为reduce tasks数目；</p>
<p><code>*问题4</code>：序列化时间长、结果大<br><code>解决方法</code>：Spark默认使.用JDK.自带的ObjectOutputStream，这种方式产生的结果大、CPU处理时间长，可以通过设置spark.serializer为org.apache.spark.serializer.KryoSerializer。另外如果结果已经很大，可以使用广播变量；</p>
<p><code>*问题5</code>：单条记录消耗大<br><code>解决方法</code>：使用mapPartition替换map，mapPartition是对每个Partition进行计算，而map是对partition中的每条记录进行计算；</p>
<p><code>*问题6</code>: collect输出大量结果时速度慢<br><code>解决方式</code>：collect源码中是把所有的结果以一个Array的方式放在内存中，可以直接输出到分布式?文件系统，然后查看文件系统中的内容；</p>
<p><code>*问题7</code>: 任务执行速度倾斜<br><code>解决方式</code>：如果是数据倾斜，一般是partition key取的不好，可以考虑其它的并行处理方式 ，并在中间加上aggregation操作；如果是Worker倾斜，例如在某些worker上的executor执行缓慢，可以通过设置spark.speculation=true 把那些持续慢的节点去掉；</p>
<p><code>*问题8</code>: 通过多步骤的RDD操作后有很多空任务或者小任务产生<br><code>解决方式</code>：使用coalesce或repartition去减少RDD中partition数量；</p>
<p><code>*问题9</code>：Spark Streaming吞吐量不高<br><code>解决方式</code>：可以设置spark.streaming.concurrentJobs</p>
<p><strong>3.</strong> intellij idea直接编译spark源码及问题解决:<br><code>*</code> <a href="http://blog.csdn.net/tanglizhe1105/article/details/50530104" target="_blank" rel="external">http://blog.csdn.net/tanglizhe1105/article/details/50530104</a><br><code>*</code> <a href="http://stackoverflow.com/questions/18920334/output-path-is-shared-between-the-same-module-error" target="_blank" rel="external">http://stackoverflow.com/questions/18920334/output-path-is-shared-between-the-same-module-error</a><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="type">Spark</span>编译：clean <span class="keyword">package</span> -<span class="type">Dmaven</span>.test.skip=<span class="literal">true</span></div><div class="line">参数：-<span class="type">Xmx2g</span> -<span class="type">XX</span>:<span class="type">MaxPermSize</span>=<span class="number">512</span>M -<span class="type">XX</span>:<span class="type">ReservedCodeCacheSize</span>=<span class="number">512</span>m</div></pre></td></tr></table></figure></p>
<p><strong>4.</strong> import Spark source code into intellj, build Error: not found: type SparkFlumeProtocol and EventBatch<br><a href="http://stackoverflow.com/questions/33311794/import-spark-source-code-into-intellj-build-error-not-found-type-sparkflumepr" target="_blank" rel="external">http://stackoverflow.com/questions/33311794/import-spark-source-code-into-intellj-build-error-not-found-type-sparkflumepr</a> </p>
<div align="center"><img src="/uploads/spark/spark_complie_config.png" width="1000" height="500" alt="1.1" align="center"></div>

<p><strong>5.</strong> 整理对Spark SQL的理解：<a href="http://www.aboutyun.com/thread-8575-1-1.html" target="_blank" rel="external">http://www.aboutyun.com/thread-8575-1-1.html</a></p>
<p><strong>6.</strong> Spark GBDT实现方式：spark gbdt的实现基于：J.H. Friedman.  “Stochastic Gradient Boosting.” 1999.spark。<br>&nbsp;&nbsp;<code>1)</code> gbdt使用一般的残差更新方式，利用残差（梯度方向）更新样本数据集，做为下棵树模型训练的样本<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data = input.<span class="built_in">map</span>(<span class="built_in">point</span> =&gt; LabeledPoint(-loss.gradient(partialModel, <span class="built_in">point</span>),<span class="built_in">point</span>.features))</div></pre></td></tr></table></figure></p>
<p>&nbsp;&nbsp;<code>2)</code> 建树过程用variance作为split准则, xgboost对目标函数进行变换，每轮建树的过程用gradient和hessian计算gain作为split准则<br>&nbsp;&nbsp;<code>3)</code> 算法性能（效率、支持数据量）<br>&nbsp;&nbsp;<code>4)</code> 算法结果的一致性</p>
<p><strong>7.</strong> UDAF（User- Defined Aggregation Funcation）：<a href="http://p-x1984.iteye.com/blog/1156392" target="_blank" rel="external">http://p-x1984.iteye.com/blog/1156392</a><br>Hive自定义UDF和聚合函数UDAF：<a href="http://computerdragon.blog.51cto.com/6235984/1288567" target="_blank" rel="external">http://computerdragon.blog.51cto.com/6235984/1288567</a><br>Hive自定义UDF和聚合函数UDAF：<a href="http://www.tuicool.com/articles/mYZ7R3" target="_blank" rel="external">http://www.tuicool.com/articles/mYZ7R3</a></p>
<p><strong>8.</strong> java.lang.NoSuchMethodException: java.util.Set.<init>()<br><a href="&#109;&#x61;&#105;&#108;&#116;&#x6f;&#58;&#104;&#116;&#116;&#x70;&#58;&#47;&#47;&#109;&#97;&#x69;&#x6c;&#45;&#97;&#114;&#x63;&#104;&#105;&#x76;&#x65;&#115;&#46;&#97;&#112;&#x61;&#99;&#104;&#101;&#46;&#111;&#x72;&#x67;&#47;&#109;&#x6f;&#x64;&#95;&#109;&#x62;&#111;&#x78;&#47;&#x68;&#105;&#x76;&#101;&#x2d;&#x75;&#115;&#x65;&#x72;&#x2f;&#50;&#48;&#49;&#51;&#x30;&#55;&#46;&#109;&#98;&#x6f;&#120;&#x2f;&#37;&#x33;&#67;&#67;&#x45;&#49;&#67;&#65;&#x34;&#49;&#x43;&#x2e;&#49;&#49;&#x37;&#54;&#x45;&#x25;&#x32;&#53;&#114;&#x64;&#109;&#x40;&#98;&#97;&#121;&#x6e;&#111;&#116;&#x65;&#46;&#x63;&#x6f;&#x6d;&#x25;&#51;&#69;">&#104;&#116;&#116;&#x70;&#58;&#47;&#47;&#109;&#97;&#x69;&#x6c;&#45;&#97;&#114;&#x63;&#104;&#105;&#x76;&#x65;&#115;&#46;&#97;&#112;&#x61;&#99;&#104;&#101;&#46;&#111;&#x72;&#x67;&#47;&#109;&#x6f;&#x64;&#95;&#109;&#x62;&#111;&#x78;&#47;&#x68;&#105;&#x76;&#101;&#x2d;&#x75;&#115;&#x65;&#x72;&#x2f;&#50;&#48;&#49;&#51;&#x30;&#55;&#46;&#109;&#98;&#x6f;&#120;&#x2f;&#37;&#x33;&#67;&#67;&#x45;&#49;&#67;&#65;&#x34;&#49;&#x43;&#x2e;&#49;&#49;&#x37;&#54;&#x45;&#x25;&#x32;&#53;&#114;&#x64;&#109;&#x40;&#98;&#97;&#121;&#x6e;&#111;&#116;&#x65;&#46;&#x63;&#x6f;&#x6d;&#x25;&#51;&#69;</a></init></p>
<p><strong>9.</strong> Hive可以允许用户编写自己定义的函数UDF，来在查询中使用。Hive中有3种UDF：<br>&nbsp;&nbsp;<code>* UDF</code>：操作单个数据行，产生单个数据行;<br>&nbsp;&nbsp;<code>* UDAF</code>：操作多个数据行，产生一个数据行。<br>&nbsp;&nbsp;<code>* UDTF</code>：操作一个数据行，产生多个数据行一个表作为输出。  </p>
<p><strong>10.</strong> Hive查询数据时，有些聚类函数在HQL没有自带，需要用户自定义实现UDTF。<br>实现用户自定义聚合函数: Sum, Average…… n – 1<br>&nbsp;&nbsp;<code>10.1.</code> 必须import org.apache.hadoop.hive.ql.exec.UDAF和org.apache.hadoop.hive.ql.exec.UDAFEvaluator。<br>&nbsp;&nbsp;<code>10.2.</code> 函数类需要继承UDAF类，内部类Evaluator实UDAFEvaluator接口。<br>&nbsp;&nbsp;<code>10.3.</code> Evaluator需要实现init、iterate、terminatePartial、merge、terminate这几个函数。<br>&nbsp;&nbsp;<code>10.3.1.</code> init函数实现接口UDAFEvaluator的init函数。<br>&nbsp;&nbsp;<code>10.3.2.</code> iterate接收传入的参数，并进行内部的轮转。其返回类型为boolean。<br>&nbsp;&nbsp;<code>10.3.3.</code> terminatePartial无参数，其为iterate函数轮转结束后，返回轮转数据，terminatePartial类于hadoop的Combiner。<br>&nbsp;&nbsp;<code>10.3.4.</code> merge接收terminatePartial的返回结果，进行数据merge操作，其返回类型为boolean。<br>&nbsp;&nbsp;<code>10.3.5.</code> terminate返回最终的聚集函数结果。</p>
<p><strong>11.</strong> Apache Zeppelin编译安装：<a href="http://www.iteblog.com/archives/1573" target="_blank" rel="external">http://www.iteblog.com/archives/1573</a><br>Apache Zeppelin installation grunt build error：<a href="http://stackoverflow.com/questions/33352309/apache-zeppelin-installation-grunt-build-error?rq=1" target="_blank" rel="external">http://stackoverflow.com/questions/33352309/apache-zeppelin-installation-grunt-build-error?rq=1</a><br><code>解决方案</code>：进入web模块npm install</p>
<p><strong>12.</strong> Spark源码编译遇到的问题解决：<a href="http://www.tuicool.com/articles/NBVvai" target="_blank" rel="external">http://www.tuicool.com/articles/NBVvai</a><br>内存不够，这个错误是因为编译的时候内存不够导致的，可以在编译的时候加大内存。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[ERROR] PermGen space -&gt; [Help 1]</div><div class="line">[ERROR] </div><div class="line">[ERROR] To see the full stack trace of the errors,re-run Maven with the -e switch.</div><div class="line">[ERROR] Re-run Maven using the -X switch to enable full debug logging.</div><div class="line">[ERROR] </div><div class="line">[ERROR] For more information about the errors and possible solutions, </div><div class="line">please read the following articles:</div><div class="line">[ERROR] [Help 1]http://cwiki.apache.org/confluence/display/MAVEN/OutOfMemoryError</div><div class="line"></div><div class="line">export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m"</div></pre></td></tr></table></figure></p>
<p><strong>13.</strong> Exception in thread “main” java.lang.UnsatisfiedLinkError: no jnind4j in java.library.path<br>I’m using a 64-Bit Java on Windows and still get the no jnind4j in java.library.path error<br>It may be that you have incompatible DLLs on your PATH. In order to tell DL4J to ignore those you have to add the following as a VM parameter (Run -&gt; Edit Configurations -&gt; VM Options in IntelliJ): <code>-Djava.library.path=&quot;&quot;</code></p>
<p><strong>14.</strong> <code>spark2.0</code>本地运行源码报错解决办法：<br>&nbsp;&nbsp;<code>14.1.</code> 修改对应pom中的依赖jar包，将scope级别由<code>provided</code>改为<code>compile</code><br>&nbsp;&nbsp;<code>14.2.</code> 运行类之前，去掉make选项；在运行vm设置中增加<code>-Dspark.master=local</code><br>&nbsp;&nbsp;<code>14.3.</code> Win7下运行spark example代码报错：</p>
<pre><code>java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: file:D:/SourceCode/spark-2.0.0/spark-warehouse`修改SQLConf类中WAREHOUSE_PATH变量，将file:前缀改为file:/或file:///
createWithDefault(&quot;file:/${system:user.dir}/spark-warehouse&quot;)
</code></pre><p>&nbsp;&nbsp;<code>14.4.</code> local模式运行：<code>-Dspark.master=local</code></p>
<p><strong>15.</strong> Spark底层运行原理疑问？<br>&nbsp;&nbsp;<code>*</code> SparkSession、SparkContext、SQLContext、HiveContext之间的关系与实现机制？<br>&nbsp;&nbsp;<code>*</code> RDD、DataFrame、DataSet之间的区别与联系，实现原理？<br>&nbsp;&nbsp;<code>*</code> Spark执行原理？<br>&nbsp;&nbsp;<code>*</code> Spark SQL执行原理？<br>&nbsp;&nbsp;<code>*</code> Spark中的常见设计模式？<br>&nbsp;&nbsp;<code>*</code> Spark主要包括  调度与任务分配、I/O模块、通信控制模块、容错模块、Shuffle模块。<br>&nbsp;&nbsp;<code>*</code> Spark 按照   ①应用  application  ②作业 job   ③ stage  ④ task 四个层次进行调度，采用经典的FIFO和FAIR等调度算法。</p>
<p><strong>16.</strong> 解决<code>Task not serializable Exception</code>错误<br>方法1：将RDD中的所有数据通过JDBC连接写入数据库，若使用map函数，可能要为每个元素都创建connection，这样开销很大，如果使用mapPartitions，那么只需要针对每个分区建立connection；mapPartitions处理后返回的是Iterator。<br>方法2：对未序列化的对象加@transisent引用，在进行网络通信时不对对象中的属性进行序列化</p>
<p><strong>17.</strong> 使用LZO过程会发现它有两种压缩编码可以使用，即LzoCodec和LzopCodec，下面说说它们区别：<br>&nbsp;&nbsp;<code>17.1.</code> LzoCodec比LzopCodec更快， LzopCodec为了兼容LZOP程序添加了如 bytes signature, header等信息<br>&nbsp;&nbsp;<code>17.2.</code> 如果使用 LzoCodec作为Reduce输出，则输出文件扩展名为”.lzo_deflate”，它无法被lzop读取；如果使用LzopCodec作为Reduce输出，则扩展名为”.lzo”，它可以被lzop读取<br>&nbsp;&nbsp;<code>17.3.</code> 生成lzo index job的”DistributedLzoIndexer“无法为 LzoCodec，即 “.lzo_deflate”扩展名的文件创建index<br>&nbsp;&nbsp;<code>17.4.</code> ”.lzo_deflate“文件无法作为MapReduce输入，”.LZO”文件则可以。<br>&nbsp;&nbsp;<code>17.5.</code> 综上所述得出最佳实践：map输出的中间数据使用 LzoCodec，reduce输出使用 LzopCodec</p>
<p><strong>18.</strong> JVM线程池发展趋势：<a href="http://www.importnew.com/15082.html" target="_blank" rel="external">http://www.importnew.com/15082.html</a><br>对于传统线程池机制，一个强大的替代方案就是基于事件模型。这种基于事件的线程轮询/线程池/线程调度机制在函数式编程中很常见。关于这个概念的一个非常流行的实现是基于actor的系统（译者注：Scala的并发系统），Akka已成为其实际上的标准。（译者注：Akka，一种善于处理进程间通信的框架）</p>
<p><strong>19.</strong> 这个函数在func(“11”)调用时候正常,但是在执行func(11)或func(1.1)时候就会报error: type mismatch的错误.<br><code>*</code> 针对特定的参数类型, 重载多个func函数,这个不难, 传统JAVA中的思路, 但是需要定义多个函数<br><code>*</code> 使用超类型, 比如使用AnyVal,Any;这样的话比较麻烦,需要在函数中针对特定的逻辑做类型转化,从而进一步处理上面两个方法使用的是传统JAVA思路,虽然都可以解决该问题,但是缺点是不够简洁;在充满了语法糖的Scala中,针对类型转换提供了特有的implicit隐式转化的功能;</p>
<p><strong>20.</strong> org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle<br><code>解决方案</code>：这种问题一般发生在有大量shuffle操作的时候,task不断的failed,然后又重执行，一直循环下去，直到application失败。一般遇到这种问题提高executor内存即可,同时增加每个executor的cpu,这样不会减少task并行度。</p>
<p><strong>21.</strong> Spark ML PipeLine GBT/RF预测时报错，java.util.NoSuchElementException: key not found: 8.0<br><code>错误原因</code>：由于GBT/RF模型输入setFeaturesCol，setLabelCol参数列名不一致导致。<br><code>解决方案</code>：只保存训练算法模型，不保存PipeLineModel</p>
<p><strong>22.</strong> linux删除乱码文件，find . -inum 54263996 -exec rm {} -rf \;</p>
<p><strong>23.</strong> org.apache.spark.SparkException: Exception thrown in awaitResult<br><code>set &quot;spark.sql.broadcastTimeout&quot; to increase the timeout</code></p>
<p><strong>24.</strong> Caused by: java.lang.RuntimeException: Failed to commit task<br>Caused by: org.apache.spark.executor.CommitDeniedException: attempt_201603251514_0218_m_000245_0: Not committed because the driver did not authorize commit<br>如果你比较了解spark中的stage是如何划分的，这个问题就比较简单了。一个Stage中包含的task过大，一般由于你的transform过程太长，因此driver给executor分发的task就会变的很大。所以解决这个问题我们可以通过拆分stage解决。也就是在执行过程中调用cache.count缓存一些中间数据从而切断过长的stage。</p>
<p><strong>25.</strong> Spark Streaming性能调优：<a href="https://www.iteblog.com/archives/1333" target="_blank" rel="external">https://www.iteblog.com/archives/1333</a><br><strong>优化运行时间</strong><br>| <code>增加并行度</code> 确保使用整个集群的资源，而不是把任务集中在几个特定的节点上。对于包含shuffle的操作，增加其并行度以确保更为充分地使用集群资源；<br>| <code>减少数据序列化</code> 反序列化的负担 Spark Streaming默认将接受到的数据序列化后存储，以减少内存的使用。但是序列化和反序列话需要更多的CPU时间，因此更加高效的序列化方式（Kryo）和自定义的系列化接口可以更高效地使用CPU；<br>| <code>设置合理的batch duration（批处理时间间隔）</code> 在Spark Streaming中，Spark会每隔batchDuration间隔时间提交一次job，Job之间有可能存在依赖关系，后面的Job必须确保前面的作业执行结束后才能提交。若前面的Job执行的时间超出了批处理时间间隔，那么后面的Job就无法按时提交，这样就会进一步拖延接下来的Job，造成后续Job的阻塞。因此设置一个合理的批处理间隔以确保作业能够在这个批处理间隔内结束时必须的；<br>| <code>减少因任务提交和分发所带来的负担</code> 通常情况下，Akka框架能够高效地确保任务及时分发，但是当批处理间隔非常小（500ms）时，提交和分发任务的延迟就变得不可接受了。使用Standalone和Coarse-grained Mesos模式通常会比使用Fine-grained   Mesos模式有更小的延迟。<br>| <code>缓存需要经常使用的数据</code> 调用rdd.cache()来缓存数据，加快数据处理  </p>
<p><strong>优化内存使用</strong><br>| <code>控制batch size（批处理间隔内的数据量）</code> Spark Streaming会把批处理间隔内接收到的所有数据存放在Spark内部的可用内存区域中，因此必须确保当前节点Spark的可用内存中少能容纳这个批处理时间间隔内的所有数据，否则必须增加新的资源以提高集群的处理能力；<br>| <code>及时清理不再使用的数据</code> 前面讲到Spark Streaming会将接受的数据全部存储到内部可用内存区域中，因此对于处理过的不再需要的数据应及时清理，以确保Spark Streaming有富余的可用内存空间。通过设置合理的spark.cleaner.ttl【Deprecated】时长来及时清理超时的无用数据，这个参数需要小心设置以免后续操作中所需要的数据被超时错误处理，还可以配置选项spark.streaming.unpersist=true来更智能的持久化(unpersist)RDD，该配置使系统找出那些不需要经常保存的RDD，然后去持久化它们，这样可以减少spark rdd的内存使用，还可以改善垃圾回收行为；<br>| <code>观察及适当调整GC策略</code> GC会影响Job的正常运行，可能延长Job的执行时间，引起一系列不可预料的问题。观察GC的运行情况，采用不同的GC策略以进一步减小内存回收对Job运行的影响。<br>| <code>设备合理的CPU资源数</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于Spark程序优化，应从如下几点进行：&lt;br&gt;&amp;nbsp;&amp;nbsp;&lt;code&gt;1.&lt;/code&gt; 通过监控CPU、内存、网络、IO、GC、应用指标等数据，切实找到系统的瓶颈点。&lt;br&gt;&amp;nbsp;&amp;nbsp;&lt;code&gt;2.&lt;/code&gt; 统筹全局，制定相应的解决方
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark 学习笔记</title>
    <link href="http://yoursite.com/2016/09/11/spark-notices/"/>
    <id>http://yoursite.com/2016/09/11/spark-notices/</id>
    <published>2016-09-11T14:00:00.000Z</published>
    <updated>2017-06-18T07:26:07.906Z</updated>
    
    <content type="html"><![CDATA[<p>以下是在学习和使用spark过程中遇到的一些问题，记录下来。</p>
<p><strong>1. </strong>  首先来说说spark任务运行完后查错最常用的一个命令，那就是把任务运行日志down下来。 程序存在错误，将日志down下来查看具体原因！down日志命令：<code>yarn logs -applicationId app_id</code> </p>
<p><strong>2. </strong>  Spark性能优化的9大问题及其解决方案：<a href="http://book.51cto.com/art/201409/453045.htm" target="_blank" rel="external">http://book.51cto.com/art/201409/453045.htm</a><br>Spark程序优化所需要关注的几个关键点——最主要的是数据序列化和内存优化  </p>
<p><code>*问题1</code>：reduce task数目不合适<br><code>解决方法</code>：需根据实际情况调节默认配置，调整方式是修改参数spark.default.parallelism。通常，reduce数目设置为core数目的2到3倍。数量太大，造成很多小任务，增加启动任务的开销；数目太少，*任务运行缓慢。</p>
<p><code>*问题2</code>：shuffle磁盘IO时间长<br><code>解决方法</code>：设置spark.local.dir为多个磁盘，并设置磁盘为IO速度快的磁盘，通过增加IO来优化shuffle性能；</p>
<p><code>*问题3</code>：map|reduce数量大，造成shuffle小文件数目多<br><code>解决方法</code>：默认情况下shuffle文件数目为map tasks * reduce tasks. 通过设置spark.shuffle.consolidateFiles为true，来合并shuffle中间文件，此时文件数为reduce tasks数目；</p>
<p><code>*问题4</code>：序列化时间长、结果大<br><code>解决方法</code>：Spark默认使.用JDK.自带的ObjectOutputStream，这种方式产生的结果大、CPU处理时间长，可以通过设置spark.serializer为org.apache.spark.serializer.KryoSerializer。另外如果结果已经很大，可以使用广播变量；<br><code>*问题5</code>：单条记录消耗大<br><code>解决方法</code>：使用mapPartition替换map，mapPartition是对每个Partition进行计算，而map是对partition中的每条记录进行计算；</p>
<p><code>*问题6</code>：collect输出大量结果时速度慢<br><code>解决方法</code>：collect源码中是把所有的结果以一个Array的方式放在内存中，可以直接输出到分布式?文件系统，然后查看文件系统中的内容；</p>
<p><code>*问题7</code>：任务执行速度倾斜<br><code>解决方法</code>：如果是数据倾斜，一般是partition key取的不好，可以考虑其它的并行处理方式 ，并在中间加上aggregation操作；如果是Worker倾斜，例如在某些worker上的executor执行缓慢，可以通过设置spark.speculation=true 把那些持续慢的节点去掉；</p>
<p><code>*问题8</code>：通过多步骤的RDD操作后有很多空任务或者小任务产生<br><code>解决方法</code>：使用coalesce或repartition去减少RDD中partition数量 </p>
<p><code>*问题9</code>：Spark Streaming吞吐量不高<br><code>解决方法</code>：可以设置spark.streaming.concurrentJobs </p>
<p><strong>3. </strong>  intellij idea直接编译spark源码及问题解决:<br><code>*</code> <a href="http://blog.csdn.net/tanglizhe1105/article/details/50530104" target="_blank" rel="external">http://blog.csdn.net/tanglizhe1105/article/details/50530104</a><br><code>*</code> <a href="http://stackoverflow.com/questions/18920334/output-path-is-shared-between-the-same-module-error" target="_blank" rel="external">http://stackoverflow.com/questions/18920334/output-path-is-shared-between-the-same-module-error</a><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="type">Spark</span>编译：clean <span class="keyword">package</span> -<span class="type">Dmaven</span>.test.skip=<span class="literal">true</span></div><div class="line">参数：-<span class="type">Xmx2g</span> -<span class="type">XX</span>:<span class="type">MaxPermSize</span>=<span class="number">512</span>M -<span class="type">XX</span>:<span class="type">ReservedCodeCacheSize</span>=<span class="number">512</span>m</div></pre></td></tr></table></figure></p>
<p><strong>4. </strong>  import Spark source code into intellj, build Error: not found: type SparkFlumeProtocol and EventBatch<br><a href="http://stackoverflow.com/questions/33311794/import-spark-source-code-into-intellj-build-error-not-found-type-sparkflumepr" target="_blank" rel="external">http://stackoverflow.com/questions/33311794/import-spark-source-code-into-intellj-build-error-not-found-type-sparkflumepr</a>  </p>
<div align="center"><img src="/uploads/spark/spark_complie_config.png" width="1000" height="500" alt="1.1" align="center"></div>

<p><strong>5. </strong>  java.lang.NoSuchMethodException: java.util.Set.<init>()<br><a href="&#109;&#97;&#x69;&#x6c;&#x74;&#x6f;&#x3a;&#104;&#x74;&#x74;&#112;&#x3a;&#47;&#x2f;&#109;&#97;&#x69;&#x6c;&#45;&#x61;&#x72;&#x63;&#104;&#x69;&#118;&#101;&#115;&#46;&#x61;&#112;&#97;&#99;&#104;&#x65;&#46;&#111;&#114;&#103;&#47;&#x6d;&#x6f;&#x64;&#95;&#x6d;&#x62;&#111;&#x78;&#x2f;&#x68;&#105;&#x76;&#x65;&#45;&#117;&#115;&#101;&#x72;&#47;&#50;&#x30;&#49;&#x33;&#x30;&#x37;&#x2e;&#109;&#x62;&#111;&#x78;&#x2f;&#x25;&#51;&#x43;&#67;&#69;&#49;&#67;&#x41;&#52;&#x31;&#67;&#x2e;&#x31;&#49;&#x37;&#54;&#69;&#x25;&#50;&#53;&#114;&#100;&#109;&#64;&#98;&#x61;&#x79;&#110;&#111;&#x74;&#101;&#46;&#x63;&#x6f;&#109;&#x25;&#51;&#69;">&#104;&#x74;&#x74;&#112;&#x3a;&#47;&#x2f;&#109;&#97;&#x69;&#x6c;&#45;&#x61;&#x72;&#x63;&#104;&#x69;&#118;&#101;&#115;&#46;&#x61;&#112;&#97;&#99;&#104;&#x65;&#46;&#111;&#114;&#103;&#47;&#x6d;&#x6f;&#x64;&#95;&#x6d;&#x62;&#111;&#x78;&#x2f;&#x68;&#105;&#x76;&#x65;&#45;&#117;&#115;&#101;&#x72;&#47;&#50;&#x30;&#49;&#x33;&#x30;&#x37;&#x2e;&#109;&#x62;&#111;&#x78;&#x2f;&#x25;&#51;&#x43;&#67;&#69;&#49;&#67;&#x41;&#52;&#x31;&#67;&#x2e;&#x31;&#49;&#x37;&#54;&#69;&#x25;&#50;&#53;&#114;&#100;&#109;&#64;&#98;&#x61;&#x79;&#110;&#111;&#x74;&#101;&#46;&#x63;&#x6f;&#109;&#x25;&#51;&#69;</a> </init></p>
<p><strong>6. </strong>  Apache Zeppelin编译安装：<a href="http://www.iteblog.com/archives/1573" target="_blank" rel="external">http://www.iteblog.com/archives/1573</a><br>Apache Zeppelin installation grunt build error：<a href="http://stackoverflow.com/questions/33352309/apache-zeppelin-installation-grunt-build-error?rq=1" target="_blank" rel="external">http://stackoverflow.com/questions/33352309/apache-zeppelin-installation-grunt-build-error?rq=1</a><br><code>解决方法</code>：进入web模块npm install</p>
<p><strong>7. </strong>  Spark源码编译遇到的问题解决：<a href="http://www.tuicool.com/articles/NBVvai" target="_blank" rel="external">http://www.tuicool.com/articles/NBVvai</a><br><code>解决方法</code>：内存不够，这个错误是因为编译的时候内存不够导致的，可以在编译的时候加大内存。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[ERROR] PermGen space -&gt; [Help 1]</div><div class="line">[ERROR] </div><div class="line">[ERROR] To see the full stack trace of the errors,re-run Maven with the -e switch.</div><div class="line">[ERROR] Re-run Maven using the -X switch to enable full debug logging.</div><div class="line">[ERROR] </div><div class="line">[ERROR] For more information about the errors and possible solutions, </div><div class="line">please read the following articles:</div><div class="line">[ERROR] [Help 1]http://cwiki.apache.org/confluence/display/MAVEN/OutOfMemoryError</div><div class="line"></div><div class="line">export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m"</div></pre></td></tr></table></figure></p>
<p><strong>8. </strong>  Exception in thread “main” java.lang.UnsatisfiedLinkError: no jnind4j in java.library.path<br>I’m using a 64-Bit Java on Windows and still get the no jnind4j in java.library.path error<br>It may be that you have incompatible DLLs on your PATH. In order to tell DL4J to ignore those you have to add the following as a VM parameter (Run -&gt; Edit Configurations -&gt; VM Options in IntelliJ): <code>-Djava.library.path=&quot;&quot;</code></p>
<p><strong>9. </strong>  <code>spark2.0</code>本地运行源码报错解决办法：</p>
<p><code>1.</code> 修改对应pom中的依赖jar包，将scope级别由<code>provided</code>改为<code>compile</code><br><code>2.</code> 运行类之前，去掉make选项；在运行vm设置中增加<code>-Dspark.master=local</code><br><code>3.</code> Win7下运行spark example代码报错：<br><code>java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: file:D:/SourceCode/spark-2.0.0/spark-warehouse</code>修改SQLConf类中WAREHOUSE_PATH变量，将file:前缀改为file:/或file:///<br>createWithDefault(“file:/${system:user.dir}/spark-warehouse”)<br><code>4.</code> local模式运行：<code>-Dspark.master=local</code></p>
<p><strong>10. </strong>  解决<code>Task not serializable Exception</code>错误<br>方法1：将RDD中的所有数据通过JDBC连接写入数据库，若使用map函数，可能要为每个元素都创建connection，这样开销很大，如果使用mapPartitions，那么只需要针对每个分区建立connection；mapPartitions处理后返回的是Iterator。<br>方法2：对未序列化的对象加@transisent引用，在进行网络通信时不对对象中的属性进行序列化</p>
<p><strong>11. </strong>  这个函数在func(“11”)调用时候正常,但是在执行func(11)或func(1.1)时候就会报error: type mismatch的错误. 这个问题很好解决</p>
<p><code>-</code> 针对特定的参数类型, 重载多个func函数,这个不难, 传统JAVA中的思路, 但是需要定义多个函数<br><code>-</code> 使用超类型, 比如使用AnyVal,Any;这样的话比较麻烦,需要在函数中针对特定的逻辑做类型转化,从而进一步处理上面两个方法使用的是传统JAVA思路,虽然都可以解决该问题,但是缺点是不够简洁;在充满了语法糖的Scala中,针对类型转换提供了特有的implicit隐式转化的功能;</p>
<p><strong>12. </strong>  org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle<br><code>解决方法</code>：这种问题一般发生在有大量shuffle操作的时候,task不断的failed,然后又重执行，一直循环下去，直到application失败。一般遇到这种问题提高executor内存即可,同时增加每个executor的cpu,这样不会减少task并行度。</p>
<p><strong>13. </strong>  Spark ML PipeLine GBT/RF预测时报错，java.util.NoSuchElementException: key not found: 8.0<br><code>错误原因</code>：由于GBT/RF模型输入setFeaturesCol，setLabelCol参数列名不一致导致。<br><code>解决方法</code>：只保存训练算法模型，不保存PipeLineModel</p>
<p><strong>14. </strong>  linux删除乱码文件，find . -inum 54263996 -exec rm {} -rf \;</p>
<p><strong>15. </strong>  org.apache.spark.SparkException: Exception thrown in awaitResult<br><code>set &quot;spark.sql.broadcastTimeout&quot; to increase the timeout</code></p>
<p><strong>16. </strong>  Caused by: java.lang.RuntimeException: Failed to commit task<br>Caused by: org.apache.spark.executor.CommitDeniedException: attempt_201603251514_0218_m_000245_0: Not committed because the driver did not authorize commit<br>如果你比较了解spark中的stage是如何划分的，这个问题就比较简单了。一个Stage中包含的task过大，一般由于你的transform过程太长，因此driver给executor分发的task就会变的很大。所以解决这个问题我们可以通过拆分stage解决。也就是在执行过程中调用cache.count缓存一些中间数据从而切断过长的stage。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;以下是在学习和使用spark过程中遇到的一些问题，记录下来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. &lt;/strong&gt;  首先来说说spark任务运行完后查错最常用的一个命令，那就是把任务运行日志down下来。 程序存在错误，将日志down下来查看具体原因！down日志命令：
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark资料链接汇总</title>
    <link href="http://yoursite.com/2016/09/10/spark-doc-index/"/>
    <id>http://yoursite.com/2016/09/10/spark-doc-index/</id>
    <published>2016-09-10T14:00:00.000Z</published>
    <updated>2017-06-18T07:32:02.028Z</updated>
    
    <content type="html"><![CDATA[<h3 id="【SparkX】"><a href="#【SparkX】" class="headerlink" title="【SparkX】"></a>【SparkX】</h3><ol>
<li><a href="http://wenku.baidu.com/view/d2cfcb430066f5335a812186.html?from=search" target="_blank" rel="external">基于Spark Graphx的大规模用户图计算和应用</a></li>
<li><a href="http://www.csdn.net/article/2014-08-07/2821097" target="_blank" rel="external">快刀初试：Spark GraphX在淘宝的实践</a></li>
<li><a href="http://www.aboutyun.com/thread-11601-1-1.html" target="_blank" rel="external">Spark中文手册9：Spark GraphX编程指南</a></li>
<li><a href="http://dataunion.org/7566.html" target="_blank" rel="external">Spark Graphx:构建graph和聚合消息</a></li>
<li><a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html" target="_blank" rel="external">GraphX Programming Guide</a></li>
<li><a href="http://www.ithao123.cn/content-3510265.html" target="_blank" rel="external">Spark的Graphx学习笔记–Pregel</a></li>
<li><a href="http://www.tuicool.com/articles/Bry6Vn" target="_blank" rel="external">Apache Spark源码走读之14 – Graphx实现剖析 - 徽沪一郎</a></li>
<li><a href="http://book.51cto.com/art/201408/450049.htm" target="_blank" rel="external">Spark+GraphX大规模图计算和图挖掘（V3.0）王家林</a></li>
<li><a href="http://ampcamp.berkeley.edu/big-data-mini-course/graph-analytics-with-graphx.html" target="_blank" rel="external">Graph analytics with Graphx</a></li>
</ol>
<h3 id="【Spark】"><a href="#【Spark】" class="headerlink" title="【Spark】"></a>【Spark】</h3><ol>
<li><a href="http://wenku.baidu.com/view/831cdc0102768e9951e73886.html?from=search" target="_blank" rel="external">Spark的成功案例</a></li>
<li><a href="http://wenku.baidu.com/view/d8907c4d31126edb6e1a1012.html?from=search" target="_blank" rel="external">Spark实时流处理编程指南</a></li>
<li><a href="https://datarus.wordpress.com/2015/05/04/fighting-the-skew-in-spark/" target="_blank" rel="external">Skewed Join Solutions</a></li>
<li><a href="http://blog.csdn.net/macyang/article/details/7671500" target="_blank" rel="external">Skewed Join Optimization</a></li>
<li><a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="external">Spark Programming Guide</a></li>
<li><a href="http://stanford.edu/~rezab/slides/" target="_blank" rel="external">Reza Zadeh spark ppt资料</a></li>
<li><a href="http://mail-archives.apache.org/mod_mbox/spark-commits/" target="_blank" rel="external">spark mail list</a></li>
<li><a href="http://dataunion.org/3435.html" target="_blank" rel="external">一个 KCore 算法引发的 StackOverflow 奇案</a></li>
<li><a href="http://dataunion.org/category/article/tech/spark-tech" target="_blank" rel="external">数盟DataUnion Spark-tech</a></li>
<li><a href="https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/" target="_blank" rel="external">Databricks Spark Knowledge Base</a></li>
<li><a href="http://www.cnblogs.com/jacksu-tencent/p/4526535.html" target="_blank" rel="external">解决Task not serializable Exception错误</a></li>
<li><a href="http://mmicky.blog.163.com/blog/static/1502901542014312101657612/" target="_blank" rel="external">Spark的四种编译方法</a></li>
<li><a href="http://www.cnblogs.com/shishanyuan/archive/2015/08/19/4721326.html" target="_blank" rel="external">Spark运行架构</a></li>
<li><a href="http://www.iteblog.com/archives/1223" target="_blank" rel="external">Yarn-cluster和Yarn-client区别与联系</a></li>
<li><a href="http://www.iteblog.com/archives/1657" target="_blank" rel="external">Spark性能优化——开发调优篇</a></li>
<li><a href="http://tech.meituan.com/spark-tuning-basic.html" target="_blank" rel="external">Spark性能优化指南——基础篇</a></li>
<li><a href="http://www.jianshu.com/users/59d5607f1400/latest_articles" target="_blank" rel="external">祝威廉Spark-Streaming</a></li>
<li><a href="http://shiyanjun.cn/archives/1097.html" target="_blank" rel="external">Kafka+Spark Streaming+Redis实时计算整合实践</a></li>
<li><a href="http://www.oschina.net/translate/spark-tuning?print" target="_blank" rel="external">Spark 调优</a></li>
</ol>
<h3 id="【Spark2-0新特性】"><a href="#【Spark2-0新特性】" class="headerlink" title="【Spark2.0新特性】"></a>【Spark2.0新特性】</h3><ol>
<li><a href="http://www.iteblog.com/archives/1682" target="_blank" rel="external">SparkSession</a></li>
<li><a href="http://www.jianshu.com/p/c0181667daa0" target="_blank" rel="external">RDD、DataFrame和DataSet的区别</a></li>
<li><a href="http://blog.csdn.net/wo334499/article/details/51689549" target="_blank" rel="external">Spark RDD. DataFrame和DataSet的区别</a></li>
<li><a href="http://www.cnblogs.com/jiaan-geng/p/5385993.html" target="_blank" rel="external">深入理解Spark核心思想与源码分析</a></li>
<li><a href="https://github.com/ColZer/DigAndBuried/tree/master/spark" target="_blank" rel="external">Spark Network 模块分析</a></li>
</ol>
<h3 id="【Machine-Learning-amp-Deep-Learning】"><a href="#【Machine-Learning-amp-Deep-Learning】" class="headerlink" title="【Machine Learning &amp; Deep Learning】"></a>【Machine Learning &amp; Deep Learning】</h3><ol>
<li><a href="http://36kr.com/p/533832.html" target="_blank" rel="external">深度学习三十年创新路</a></li>
<li><a href="http://blog.jobbole.com/85408/" target="_blank" rel="external">如何在MLlib中实现随机森林和梯度提升树（GBTs）</a></li>
<li><a href="http://www.csdn.net/article/2015-06-01/2824811" target="_blank" rel="external">深度学习-LeCun. Bengio和Hinton的联合综述</a></li>
<li><a href="http://colah.github.io/" target="_blank" rel="external">C.Olah Neural Networks (General) Blog</a></li>
<li><a href="http://www.afenxi.com/post/4853" target="_blank" rel="external">数据夜话：机器学习的七嘴八舌</a></li>
<li><a href="https://deepmind.com/publications.html" target="_blank" rel="external">Google DeepMind</a></li>
<li><a href="http://www.iteblog.com/archives/1385" target="_blank" rel="external">SparkR(R on Spark)编程指南</a></li>
<li><a href="http://mlworks.cn/posts/introduction-to-l-bfgs/" target="_blank" rel="external">理解L-BFGS算法</a></li>
</ol>
<h3 id="【架构-分享】"><a href="#【架构-分享】" class="headerlink" title="【架构/分享】"></a>【架构/分享】</h3><ol>
<li><a href="http://blog.sciencenet.cn/blog-64458-691159.html" target="_blank" rel="external">大数据时代抽样的是是非非</a></li>
<li><a href="http://www.huxiu.com/article/16854/1.html" target="_blank" rel="external">把小样本经验用在海量样本筛选上，才是大数据的价值</a></li>
<li><a href="http://www.itongji.cn/article/041119352013.html" target="_blank" rel="external">大数据是否需要抽样？</a></li>
<li><a href="http://36kr.com/p/5038062.html" target="_blank" rel="external">互联网金融时代下机器学习与大数据风控系统</a></li>
<li><a href="http://www.csdn.net/article/2015-10-06/2825849" target="_blank" rel="external">量化派基于Hadoop. Spark. Storm的大数据风控架构</a></li>
<li><a href="http://blog.jobbole.com/60809/" target="_blank" rel="external">机器学习算法之旅</a></li>
<li><a href="http://www.36dsj.com/archives/20627" target="_blank" rel="external">广点通背后的大数据技术秘密</a></li>
<li><a href="http://www.csdn.net/article/2015-08-27/2825557" target="_blank" rel="external">广点通DMP定向功能技术体系解析</a></li>
<li><a href="http://www.36dsj.com/archives/19393" target="_blank" rel="external">腾讯社交网络的大数据建模框架探索报告</a></li>
<li><a href="http://www.csdn.net/article/2015-01-12/2823526/2" target="_blank" rel="external">Spark技术解析及其在百度最大千台单集群的应用实践</a></li>
<li><a href="http://www.docin.com/p-757468351.html" target="_blank" rel="external">百度知识图谱中的NLP技术</a></li>
</ol>
<h3 id="【Others】"><a href="#【Others】" class="headerlink" title="【Others】"></a>【Others】</h3><ol>
<li><a href="http://www.ppvke.com/Blog/archives/6334" target="_blank" rel="external">Gephi的设计理念及Gephi可视化需要什么样的数据</a></li>
<li><a href="http://www.tuicool.com/articles/MZJ3ya" target="_blank" rel="external">scala macro-使case copy易读</a></li>
<li><a href="http://eed3si9n.com/treehugger/if.html" target="_blank" rel="external">treehugger.scala</a></li>
<li><a href="http://yefremov.net/blog/scala-code-generation/" target="_blank" rel="external">3 approaches to Scala code generation</a></li>
<li><a href="http://eng.kifi.com/scala-macro-annotations-real-world-example/" target="_blank" rel="external">Scala macro annotations: a real-world example</a></li>
<li><a href="http://www.sjsjw.com/103/005844MYM031811/" target="_blank" rel="external">SparkTask未序列化(Tasknotserializable)问题分析</a></li>
<li><a href="http://baike.baidu.com/item/Zeppelin/17544169#viewPageContent" target="_blank" rel="external">Apache Zeppelin 1</a></li>
<li><a href="http://zeppelin.incubator.apache.org/" target="_blank" rel="external">Apache Zeppelin 2</a></li>
<li><a href="https://segmentfault.com/a/1190000004428222" target="_blank" rel="external">Apache Zeppelin 2</a></li>
<li><a href="http://www.open-open.com/lib/view/open1455324923917.html" target="_blank" rel="external">基于Apache Zeppelin Notebook和R的交互式数据科学</a></li>
</ol>
<h3 id="【Scala】"><a href="#【Scala】" class="headerlink" title="【Scala】"></a>【Scala】</h3><p><a href="http://twitter.github.io/effectivescala/index-cn.html" target="_blank" rel="external">Effective Scala</a><br><a href="http://twitter.github.io/scala_school/zh_cn/index.html" target="_blank" rel="external">Scala 课堂!</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;【SparkX】&quot;&gt;&lt;a href=&quot;#【SparkX】&quot; class=&quot;headerlink&quot; title=&quot;【SparkX】&quot;&gt;&lt;/a&gt;【SparkX】&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://wenku.baidu.com/view/d2c
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Pelican环境搭建&amp;Markdown学习小记</title>
    <link href="http://yoursite.com/2016/09/09/pelican-notes/"/>
    <id>http://yoursite.com/2016/09/09/pelican-notes/</id>
    <published>2016-09-09T02:20:00.000Z</published>
    <updated>2016-12-28T09:56:01.605Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Pelican环境搭建笔记"><a href="#Pelican环境搭建笔记" class="headerlink" title="Pelican环境搭建笔记"></a>Pelican环境搭建笔记</h2><ul>
<li>将md文档编译为html,并输出到output目录命令：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pelican content</div></pre></td></tr></table></figure>
<ul>
<li>在命令行里面切换到output目录下面，启动Pelican的本地web服务命令：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python -m SimpleHTTPServer</div></pre></td></tr></table></figure>
<ul>
<li><p>pelican所有插件安装均在pelicanconf.py文件中配置参数</p>
</li>
<li><p>代码块theme设置，直接修改flex theme base.html中代码块默认主题为monokai，然后再在pelicanconf.py文件中配置参数：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">MD_EXTENSIONS = [<span class="string">'codehilite(pygments_style=monokai,css_class=highlight,linenums=True)'</span>, <span class="string">'extra'</span>]</div></pre></td></tr></table></figure>
<h2 id="Markdown常用语法笔记"><a href="#Markdown常用语法笔记" class="headerlink" title="Markdown常用语法笔记"></a>Markdown常用语法笔记</h2><ol>
<li><strong>引用</strong>：如果你需要引用一小段别处的句子，那么就要用引用的格式。只需要在文本前加入 &gt; 这种尖括号（大于号）即可</li>
<li><strong>图片与链接</strong>：插入链接与插入图片的语法很像，区别在一个 !号。<br>图片为：<img src="https://msjbear.github.com/pages/frontend/img/IMG_0681.JPG" alt="熊二"><br>链接为：<a href="https://msjbear.github.com" target="_blank" rel="external">msjbear</a></li>
<li><strong>粗体与斜体</strong>：Markdown的粗体和斜体也非常简单，用两个<em>包含一段文本就是粗体的语法，用一个</em>包含一段文本就是斜体的语法。</li>
<li><strong>代码框</strong>：如果你是个程序猿，需要在文章里优雅的引用代码框，在 Markdown下实现也非常简单，只需要用两个 ` 把中间的代码包裹起来。使用 tab 键即可缩进。</li>
<li><strong>分割线</strong>：分割线的语法只需要三个 * 号</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Pelican环境搭建笔记&quot;&gt;&lt;a href=&quot;#Pelican环境搭建笔记&quot; class=&quot;headerlink&quot; title=&quot;Pelican环境搭建笔记&quot;&gt;&lt;/a&gt;Pelican环境搭建笔记&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;将md文档编译为html,并输出到out
    
    </summary>
    
      <category term="Notes" scheme="http://yoursite.com/categories/Notes/"/>
    
    
      <category term="pelican" scheme="http://yoursite.com/tags/pelican/"/>
    
      <category term="markdown" scheme="http://yoursite.com/tags/markdown/"/>
    
  </entry>
  
</feed>
